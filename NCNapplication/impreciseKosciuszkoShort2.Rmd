---
title: "\\large Epistemological challenges to imprecise probabilism \\newline  A higher-order Bayesian approach"
author: "Rafal Urbaniak"
output:
  pdf_document:
    number_sections: true
    df_print: kable 
    keep_tex: true
    includes:
      in_header:
        - Rafal_latex6.sty
fontsize: 10pt
bibliography: munich2.bib
csl: transactions-on-computational-logic.csl
documentclass: scrartcl
---



\normalsize

\thispagestyle{empty}


\vspace{-1cm}

\begin{center}\footnotesize word count (excluding references): 451 \normalsize
\end{center}

<!-- Imprecise probabilism (IP) employs sets of probability measures or ranges of probabilities instead of a single probability measure to model uncertainty. Modeling epistemic states from this perspective, however, runs into certain epistemological difficulties: (i) it is hard to use imprecise probabilities to express the weight of evidence, (ii) obtaining new information in certain cases makes one more uncertain even about seemingly unrelated propositions, (iii) if one starts in a state of complete uncertainty, no new information can make them change this state, (iv) it is unclear how to measure the accuracy of imprecise beliefs. My goal is to use second-order probabilities (probabilities of probabilities) instead to model uncertainty in the cases used to motivate IP.  I conjecture that this view better handles such challenges while still being responsive to considerations that motivate IP. -->



\vspace{1cm}

\textbf{Goal.} To use higher-order probabilities to tackle the philosophical difficulties encountered by imprecise probabilism. 

\textbf{Imprecise probabilism (IP).}
Imprecise Probabilism (IP) denies the view that a rational agent's (RA) degrees of belief are to be represented by a single probability measure: on many occasions the available evidence seems to warrant only imprecise degrees of belief  [@Levi1974;@Grdenfors1982;@Jeffrey1983-JEFBWA-2;@walley1991statistical;@Kaplan1996;@Joyce2005;@Grove2009;@elkin2017imprecise]. What's your precise credence in \emph{It will snow in Boston on July 1, 2030}? According to IP, RA's imprecise graded beliefs are  to be represented as a set of probability measures.


\textbf{Challenges to IP.}  I focus on epistemological difficultes with the view.  The key problems are: 

-  \textbf{Weight of evidence.} Compare two situations: (a) you've seen a coin tossed 100 times with roughly 50 heads, and (b) the coin has unknown bias which you know nothing about. The evidence carries more weight in (a). But how  is IP supposed to represent this aspect in terms of sets of probability measures and their properties [@Kaplan1996;@Joyce2005;@Sturgeon2008-STURAT]?


-  \textbf{Dilation}. There are known cases in which ---  following IP --- obtaining new evidence extends the range of credences one should rationally consider (even for seemingly unrelated propositions), and so in result the agent becomes more uncertain by learning.   Should we revise learning methods for IP? If yes, how [@walley1991statistical;@seidenfeld1993;@White2009-WHIESA;@Topey2012;@pedersen2014demystifying;@Hart2015;@Bradley2016]?  



-  \textbf{Belief inertia.} Known results entail that if one starts with the full range of probabilities --- $[0,1]$ --- for a hypothesis $H$, and uses standard bayesian learning methods in IP, no amount of evidence can shift this belief. How is IP to model learning to avoid
this [@Joyce2010,@Dodd2012;@Rinard2013;@Bradley2014;@Vallinder2017;@Moss2020]?
  

-  \textbf{Accuracy.} Scoring rules for measuring the accuracy of a single probability measure are available. These are used in the  accuracy-first epistemology to evaluate various elements of the classical Bayesian toolkit [@Pettigrew2011Epistemic-Utili;@pettigrew2016accuracy]. Unfortunately,  as far as we know, no analogous accuracy measure for IP  would entail that imprecise credences are sometimes indeed recommended over precise ones. What  truth-oriented criteria would ever recommend going imprecise and why [@Seidenfeld2012forecasting;@MayoWilson2016;@schoenfield2017AccuracyRationalityImprecise]?


\textbf{My approach.} Instead of using sets of probabilities I propose to  use second-order probabilities (probabilities of probabilities)   [@Kruschke2015;@McElreath2020] and model uncertainty in the cases used to motivate IP. For instance, in a typical  mystery coin scenario, some probability is assigned to the claim \emph{the real chance is 0.3}, and some to \emph{the real chance is 0.7}. My conjecture is that this view, properly formulated, while still being responsive to considerations that motivate IP,  better handles the challenges listed above, despite its own challenges. 



\newpage 

\footnotesize

# References {-}

\noindent 


<!-- \bibliography{PAPERS2020_2} -->
