---
title: ""
author: ""
output:
  pdf_document:
    number_sections: true
    df_print: kable 
    keep_tex: true
    includes:
      in_header:
        - Rafal_latex6.sty
classoption: dvipsnames,enabledeprecatedfontcommands
fontsize: 11pt
documentclass: scrartcl
urlcolor: blue
bibliography: [LP-SEP-FINAL6.bib, munich4.bib]
csl: apa-5th-edition.csl
---






```{r setup, include=FALSE}
library(ggplot2)
library(ggthemes)
knitr::opts_chunk$set(echo = TRUE)
```




\begin{center}
\Large {\sc \textbf{Rethinking Legal Probabilism}}

\large Rafa\l\, Urbaniak
\end{center}


\vspace{2mm}

\thispagestyle{empty}

\noindent \Large \textbf{1. Scientific goal} \normalsize

\vspace{1mm}



The \textbf{goal of this project} is to  \textbf{develop  a probabilistic  modelling method of handling the multiplicity of evidence,  hypotheses and theories of what happened, and the resulting decisions in the court of law}. In light of the current criticism of the probabilistic approach to such issues, such a method  should (1) be \textbf{sensitive to the argumentative structure} involved, and (2) capture the idea that in a legal context we are dealing with a \textbf{class of competing narrations}. 

The point of departure is to represent narrations  as bayesian networks enriched with additional layer of information as to which nodes correspond to evidence, and which are binary narration nodes. \textbf{The key idea is that with such bayesian networks as building material, various features requested by the critics (such as coherence, resiliency, missing evidence,  explaining evidence, or ways to handle a multiplicity of proposed narrations) can be explicated in terms of corresponding properties of,  operations on, and relations between bayesian networks.}   

The output will be a \textbf{unifying extended probabilistic model embracing key aspects of the narrative and argumentative approaches, with  implementation in the programming language \textbf{\textsf{R}}.}   What the project will  uniquely bring to the table is joining the  familiarity with epistemological debates, familiarity with the details of evidence assessment in legal cases  and technical skill to programmatically implement, simulate and test various theoretical moves. 



\vspace{2mm}


\noindent \Large \textbf{2. Significance} \normalsize

\vspace{1mm}

\noindent \large \textbf{2.1. State of the art}

\normalsize 

\vspace{1mm}


\textbf{Legal probabilism (LP)}  comprises two core tenets:  (1) the evidence presented at trial can be assessed, weighed and combined by means of probability theory; and (2) legal decision rules,  such as proof beyond a reasonable doubt in criminal cases, can be explicated in probabilistic terms.  LP gained popularity amidst the law and economics movement [@Calabresi1961; @becker1968crime; @Posner1973; @Finkelstein1970A; @lempert1977modeling; @Lempert1986]. These developments faced \textbf{criticism}  [@tribe71; @Underwood1977The-thumb-on-th; @cohen86; @brilmayer1986;  @dant1988gambling; @Allen1986A-Reconceptuali]. The negative trend has been somewhat mitigated by  the discovery of DNA fingerprinting in the eighties and progress in forensic science in general, with the increasing role  of  quantitative evidence  in the court of law [@kaye1986admissibility; @NRCI1992; @Robertson1995evidence;  @Koehler1996On-Conveying-th; @Kaye2010The-Double-Heli].

Skepticism about wider mathematical and quantitative models of legal evidence is still widespread among prominent legal scholars and practitioners,  partially in light of \textbf{conceptual difficulties} extensively discussed in the literature, which arise when one wants to formulate a probabilistic decision criterion for the court of law   [@allen2007problematic]. For instance, the threshold view has it that sufficiently high probability of guilt is sufficient for conviction [@Dekay1996; @kaye79; @laudan2006truth]. The threshold view is blocked by  the so-called paradoxes of legal proof or puzzles of naked statistical evidence [@Nesson1979Reasonable-doub;  @Cohen81;  @Thomson86]. Another conceptual problem  is the so-called difficulty about conjunction. It  arises, because intuitively   there should be no difference between the trierâ€™s acceptance of   $A$ and  $B$
 separately, and her acceptance of their conjunction, $A\wedge B$. On the threshold view, such a difference might arise.  
 
 How to define the \textbf{standards of proof}, or whether they should be even defined in the first place, remains  contentious [@diamond90; @newman1993;  @Horowitz1996; @laudan2006truth; @walen2015; @redmayne2008exploring;  @gardiner2018].  Various informal notions  have been claimed to be essential for  a proper explication of judiciary decision standards [@wells1992naked; @haack2011legal; @enoch2015sense; @Smith_conviction_mind_2017].   A legal probabilist needs either to show that these notions are  unnecessary or inadequate for the purpose at hand, or to indicate how they can be explicated in probabilistic terms. 


\textbf{Alternative frameworks} for modeling evidential reasoning and decision-making at trial have been proposed. They are based on inference  to the best explanation [@Pardo2008judicial; @Allen2010No-Plausible-Al; @schwartz2019WhatRelativePlausibility; @hastie2019CaseRelativePlausibilitya; @lai2019HowPlausibleRelative; @nance2019LimitationsRelativePlausibility], narratives and stories [@Pennington1991;
@Allen1986A-Reconceptuali; @allen2001naturalized; @Allen2010No-Plausible-Al; @clermont2015TrialTraditionalProbability; @pardo2018], 
and argumentation theory [@gordon2007; @Walton2002; @bex2011ArgumentsStoriesCriminal].   Preliminary sketches of hybrid theories [@verheij2014catch; @urbaniak2018narration] are also available. 


The main point of criticism of LP raised by the alternative approaches is that  legal proceedings are back-and-forth between opposing parties in which  cross-examination and the argumentative structure are of crucial importance,  reasoning goes not only evidence-to-hypothesis, but also hypotheses-to-evidence  in a way that seems analogous to inference to the best explanation, which notoriously is claimed to not be susceptible to probabilistic analysis [@wells1992naked; @allen2007problematic; @dant1988gambling; @Lipton2004-LIPITT].  

An informal philosophical account inspired by such considerations---The \textbf{No Plausible Alternative Story (NPAS)} theory---is that the courtroom is a confrontation of competing narrations offered by the sides, and  the narrative to be selected should be the most plausible one  [@Allen2010No-Plausible-Al; @wagenaar1993anchored; @ho2008philosophy]. The view is conceptually plausible [@di2013statistics], and  finds  support  in psychological evidence [@pennington1991cognitive; @pennington1992explaining].  It would be a great advantage of LP  if it could  model such phenomena and by doing so resolve  the already mentioned  conceptual challenges.



The idea that \textbf{Bayesian networks} can be used for probabilistic reasoning in legal fact-finding started gaining traction in late eighties and early nineties
[@Edwards1991Influence-diagr].   A Bayesian network comprises two components:  a directed acyclic graph of relations of dependence (represented by arrows) between variables (represented by nodes) and  conditional probability tables corresponding to these relations.  Fairly simple graphical patterns (called \emph{idioms}) often appear while modeling the relationships between evidence and hypotheses. Complex graphical models can be constructed by combining these basic patters 
in a modular way [@taroni2006bayesian; @Fenton2018risk; @neil2000BuildingLargescaleBayesian; @hepler2007ObjectorientedGraphicalRepresentations; @bovens2004bayesian; @friedman1974; @fenton2013GeneralStructureLegal]. 


Some attempts have been made to use Bayesian networks to weigh and assess complex bodies of evidence consisting of multiple components.  @kadane2011probabilistic
made one the first attempts to model an \textbf{entire criminal case}, Sacco \& Vanzetti from 1920, using probabilistic graphs.  Similarly, @Fenton2018Risk  constructed a Bayesian network for the famous Sally Clark case. The literature contains also a general approach the use of BNs for modeling whole cases.  The main idea is that once all the pieces of evidence and claims are represented as nodes, one should use the \textbf{scenario idiom} to  model  complex hypotheses, consisting of a sequence of events organized in space and time: a scenario [@vlek2014building].^[A discussion
of modelling crime scenarios by means of  graphical devices mixed with probabilities can be also found in the work of @shen2007ScenariodrivenDecisionSupporta}, @bex2011ArgumentsStoriesCriminal, @bex2015IntegratedTheoryCausal, @dawid2018graphical and
@verheijproof2017. See also the survey by @di2018evidential.]  A BN that uses the scenario idiom would consist of the following components: first, nodes for the states and events in the scenario, with each node linked to the supporting evidence; second, a separate scenario node that has all states and events as its children; finally, a node corresponding to the ultimate hypothesis as a child of the scenario node. The scenario node in a sense unifies the different events and states.   Because of this unifying role, changing the probability of one part of the scenario  will also usually change the probability of the other parts. This is intended to  capture the idea that  the different components   of a scenario form an interconnected sequence of events.

This strategy is supposed to  make sense of the notion of the \textbf{coherence of a scenario} as different from its probability given the evidence. On this approach   [@vlek2013modeling; @vlek2014building; @vlek2015; @vlek2016stories],  coherence is identified with the prior probability of the scenario node.  The approach  is also supposed to model reasoning multiple scenarios. Given a class of narrations, all the nodes used in some of the separate BNs that correspond to them are to be used to build one large BN, and all separate scenario nodes are to be included in the final large BN.


An \textbf{alternative approach} to representation of and reasoning with multiple scenarios has been developed by @Fenton2019Modelling.  They criticize [@urbaniak2018narration] by pointing out that it  makes no connection to BNs and  so it  "fails to offer a convincing and operational means to structure and compare competing narratives."  This is a fair assessment of the limits of what I have achieved so far. They  represent separate narrations in terms of separate BNs, and  deploy bayesian model comparison and averaging (linear pooling) as a tool for reasoning with multiple scenarios.

\vspace{1mm}

\noindent \large \textbf{2.2. Pioneering nature of the project}

\vspace{1mm}  \normalsize

Here are the key reasons why I am convinced \textbf{the scenario node approach is not satisfactory}. (A)  Adding a parent node by \emph{fiat} without any good reasons to think the nodes are connected other than being  a part of a single story,  introduces probabilistic dependencies between the elements of a narration. (B)  Another problem is the identification of prior probability with coherence.  This does not add up intuitively: there are coherent but unlikely stories. (C)  In general, the legal probabilistic approach to coherence is very simple and fails to engage with rich philosophical literature exactly on this topic [@shogenji1999; @olsson2001;  @glass2002; @fitelson2003ProbabilisticTheoryCoherence; @fitelson2003comments; @meijs2007; @Douven2007measuring].^[This appraoch also fails to include a long list of counterexamples to the existing proposals and desiderata that a probabilistic coherence measure should satisfy [@Merricks1995; @shogenji1999; @Akiba2000Shogenjis; @Shogenji2001Reply; @bovens2004bayesian; @Siebel2004On-Fitelsons-me;  @siebel2006against; @Shogenji2006Why; @crupi2007BayesianMeasuresEvidential; @koscholke2016evaluating; @Schippers2019General].]
(D)  The merging procedure with scenario nodes assumes that for the nodes that are common to the networks to be merged, both the directions of the arrows in the DAGs and the conditional probability tables are the same across different narrations. This is unrealistic.
  

Here are the key \textbf{limitations of the model selection and averaging approach}. (E)  The use equal priors is highly debatable. This approach would render prior probabilities quite sensitive to the choice of hypotheses and thus potentially arbitrary.  Also, this approach seems particularly unsuitable for criminal cases. If the only two hypotheses/models on the table  ultimately say "the defendant is guilty" and "the defendant is innocent",  the prior probability  of each would be 50\%. But  defendants in criminal cases, however, should be presumed innocent until proven guilty. A 50\% prior probability of guilt seems excessive.^[Some [@williamson2010defence] try to defend a variant of the principle of indifference by reference to informational entropy, and a proposal along this line has been used in practical recommendation by expert committees [@ENFSI2006entropy]. However, this attempt has been  sensibly criticized  by @Biedermann2007equal. The question remains, what should the proper application of informational entropy in the context of BN selection and averaging  look like, given that information entropy considerations independently are in epistemologically decent standing?]  Some take the presumption to mean  that the prior probability of guilt should be set to a small value [@friedmanEtAl1995; @Friedman2000], but it is not clear whether this interpretation can be justified on epistemological or decision-theoretic grounds.  (F)  More recent models rely on relevant background information   about people's opportunities to commit crimes [@fenton2019OpportunityPriorProofbased]. 
 But even if these models are successful in giving well-informed assessments of prior probabilities any evidence-based assessment of prior probabilities, they are likely  to violate existing normative requirements of the trial system [@dahlman2017; @engel2012NeglectBaseRate; @schweizer2013LawDoesnSay].  People who belong to certain demographic groups will be regarded as having a higher prior probability of committing a wrong than others, and this outcome can be seen as unfair  [@DiBelloONeil2020].  (G) Model selection based on likelihood (given equal priors) or posterior model probabilities in general (if priors are not assumed to be equal) boils down to a variant of the threshold view, and so all the difficulties with the threshold view apply. (H) There is a rich literature on the difficulties that linear pooling runs into [see the surveys in @Dietrich2016Probabilistic; @dietrich2017probabilistic1; @dietrich2017probabilistic2]. One problem is that the method satisfies the unanimity assumption: whenever all models share a degree of belief in a claim, this is exactly the output degree for that belief. Another problem is that linear pooling does not preserve probabilistic independence  [@List2011Group]: even if all models agree that certain nodes are independent, they might end up being dependent in the output. There is also a variety of impossibility theorems in the neighborhood [@Gallow2018No].



\vspace{2mm}

\noindent \textbf{The key steps in my proposal are as follows}: 

\vspace{1mm}

\noindent
\textbf{Representation.}  Use BNs taken separately without scenario nodes to represent various narrations. without assuming the conditional probability tables or directions of edges are the same across the BNs, adding another layer of information, dividing nodes into evidence and narration nodes.



\noindent \textbf{Dynamic BNs.} Averaging does not seem to be the right way to model cross-examination. To take the argumentative approach seriously and to be able to model  relations such as "undercutting" and "rebutting" I will consider another dimension: BNs changing through time in light of other BNs.

\noindent
 \textbf{BN-based coherence.} I have formulated a BN-based coherence measure that is not a function of a probabilistic measure and a set of propositions alone, because it is also sensitive to the selection and direction of arrows in a Bayesian Network representing an agent's credal state. Now, it needs to be deployed (implemented in \textbf{\textsf{R}} for BNs) and properly tested on real-life cases discussed in the LP literature.
 
 


\noindent
 \textbf{Divide and conquer.} I propose that ensemble methods should be deployed for multiple narration variants available from one side (as in when, say, the prosecution story comes with uncertainty about the direction of an arrow or about a particular probability table), but selection methods should be used when final decision is to be made between narrations proposed by the opposing sides. 

 \noindent
\textbf{Ensemble methods.} One question that arises is whether the general concerns about linear pooling arise for such limited applications. If not, the remaining concern is what priors should be used. In light of the controversial nature of equal priors, I plan to study the consequences of rescaling coherence scores (already mentioned) to constitute model priors. The idea is that given that narrations are to be developed by the sides themselves, taking coherence of their narration as determining the prior might be more fair than using equal priors or relying on geographical or population statistics. If yes, perhaps some other methods boiling down to a variant of sensitivity analysis can be deployed: look at all BNs corresponding to some variant of the narration of one of the sides, find the ones that give  strongest (and the weakest) support to the final conclusion, and these give you a range of possible outcomes. 

\noindent
 \textbf{Selection criteria.} The so-called New Legal Probabilism  (NLP)   is an attempt to improve on the  underspecificity of NPAS [@di2013statistics]. While still being at most semi-formal, the approach is more specific about the conditions that a successful accusing narration is to satisfy for the conviction beyond reasonable doubt to be justified. Di Bello works out the philosophical details of requirements such as evidential support and completeness, resiliency, and narrativity. It is far from obvious that such conditions are susceptible  to a Bayesian networks explication. I plan to rely on   a more expressive probabilistic framework [@Urbaniak2017Narration-in-ju;@urbaniak2018narration], that is  capable of expressing such features  within a formalized higher-order language. The key hypothesis is that they can be recast  in terms of properties of BNs and that the existing BN programming tools can be extended to implement testing for these criteria. This will make them susceptible to programmatic implementation and further study by means of computational methods. The hope is that on one hand, they will do better than the existing proposals, and where they fail, further insights can be gained by studying the reasons behind such failures.   








\vspace{1mm}

\noindent \Large \textbf{3. Work plan}

\vspace{1mm}  \normalsize


 Throughout the  whole project I plan to cooperate with Marcello Di Bello (Arizona State University). Over the last year we co-authored the Stanford Encyclopedia of Philosophy entry on Legal Probabilism. We decided to continue our fruitful cooperation. For over two months we have been working on a book proposal to be submitted to Oxford University Press exactly on the issues to be studied in this research project. Marcello Di Bello is an excellent philsopher with extensive research experience in the philosophy of legal evidence, and he would bring his expertise to the table when working both on the book and on the papers, whereas I would be focused on the technical aspects and the underlying  formal philosophy. During the last year of the research \textbf{I plan a six months' stay at Arizona State University}, to work in person with Di Bello on finalizing the book that presents the results of the project.




 Apart from publications, the results will be presented at various conferences devoted to legal reasoning. These include the yearly conferences of the \emph{International Association for Artificial Intelligence and Law} and of the \emph{Foundation for Legal Knowledge Based Systems (JURIX)}, and more general conferences gathering formal philosophers, so that the research is inspired by interaction not only with legal evidence scholars, computer scientists, but also philosophers. I am also already an invited speaker at the upcoming "Probability and Proof" conference that will  be part of an international conference on the philosophy of legal evidence ("The Michele Taruffo Girona Evidence Week") in Girona (Spain) May 23-27 2022.


\vspace{1mm}
\begin{center}
\begin{tabular}{p{2.3cm}|p{13.8cm}}
\footnotesize \textbf{$\mathtt{Stage  \,\, 1}$} \newline  \tiny Philosophical \&  formal \newline  unification & 
Obtain a unifying extended  probabilistic framework by incorporating further insights  from philosophical and psychological accounts of legal narrations, and from the argumentation approach. Defend its philosophical plausibility. \scriptsize (6 months)
\\ 
& \footnotesize A philosophical paper published in an  academic journal such as \emph{Synthese}, \emph{Mind} or \emph{Ratio Juris}. Working title: \emph{Why care about narration selection principles?}\\ \\
\footnotesize \textbf{$\mathtt{Stage \,\, 2}$} \newline  \tiny AI implementation 
 & Develop Bayesian Network Methods for the obtained formal framework, so that the insights from the argumentation approach and informal epistemology, mediated through it, can be incorporated in AI tools. \scriptsize (12 months)
\\ & \footnotesize A   technical paper  published in a journal such as \emph{IfCoLog Journal of Logics and their Applications}, \emph{Law, Probability and Risk} or \emph{Artificial Intelligence and Law}. Working title: \emph{Implementation of narration assessment criteria in Bayesian Networks with \textbf{\textsf{R}}}.
\\ \\
\footnotesize \textbf{$\mathtt{Stage  \,\, 3}$} \newline  \tiny    Case studies & 
Evaluate the developed framework and AI tools  by conducting case studies from its perspective.    \scriptsize (6 months)  \\
& \footnotesize One paper  on  how the formal framework handles case studies and  one paper  on how the developed AI tools handle real-life situations in   journals such as \emph{Artificial Intelligence} or \emph{Argument \& Computation}. Working titles: \emph{Rethinking the famous BN-modeled cases within the narration framework} and \emph{BNarr, an \textbf{\textsf{R}} package to model narrations with Bayesian Networks}.
\\ \\
\footnotesize \textbf{$\mathtt{Stage  \,\, 4}$} \newline  \tiny    Back to challenges \& output & 
Investigate the extent to which the new framework helps to handle the issues raised in points A-H. \scriptsize (12 months) \\ 
& \footnotesize Completion of the planned book.
\end{tabular}
\end{center}



\vspace{2mm}



\pagebreak 

\noindent \Large \textbf{4. Methodology}

\vspace{1mm}  \normalsize

 
Standard arguments for the legitimacy of Bayesianism^[See for example [@earman1992bayes; @Urbach1993-HOWSRT] for an early yet fairly comprehensive survey, or [@Pettigrew2011Epistemic-Utili] for a discussion of more recent contributions. See also [@Swinburne2001-SWIEJ; @bovens2004bayesian; @bradley2015critical].]   deploy usually rather  abstract pieces of reasoning to the effect that if one's degrees of beliefs satisfy certain  conditions, they also have to satisfy the probabilistic requirements.  My approach to thinking about the plausibility of Bayesian epistemology is rather unlike such approaches. Instead, I prefer the \emph{proof-of-the-pudding}  methodology.  I am convinced that an important part of the philosophical assessment of the Bayesian research program has to do with  its achievements or failures in contributing to debates in philosophy which are not themselves debates about the status of Bayesianism itself. In particular, it would be great news if insights from Bayesian epistemology could be used to further development of forensic AI and deepening our understanding of judiciary decision making.








I will be using four methods: (a) informal conceptual analysis; (b) formal conceptual analysis; (c) computational metods (R simulations, etc.); and (d) case studies. I will rethink and model the existing impliementations of whole-case-scale-BNs in legal evidence from the perspective of the new framework and reconstruct cases which extensively use probabilistic reasoning, but for which BNs have not been yet proposed. Both the literature already listed and many textbooks on quantitative evidence in forensics are great sources of such cases. 


What the project will  uniquely bring to the table is joining the  familiarity with epistemological debates on the nature of coherence (which legal probabilists like Vlek or Fenton ignore or are unaware of),   familiarity with the details of evidence assessment in legal cases (which formal epistemologists such as Fitelson ignore) and technical skill to programmatically implement, simulate and test various theoretical moves. 

A larger initiative involving reconstructing various cases using different representation methods and comparing the representations, called \emph{Probability and statistics in forensic science}, took place at the Isaac Newton Institute for Mathematical Sciences. My approach will be in the same vein.  

I have extensive experience in analytic philosophy, conceptual analysis, philosophical logic  and probabilistic and decision-theoretic methods as deployed in philosophical contexts. I also have teaching and publishing record that involves statistical programming in the \textsf{\textbf{R}} language (my sample programming projects can be visited at [https://rfl-urbaniak.github.io/menu/projects.html](https://rfl-urbaniak.github.io/menu/projects.html)), and so am also competent to develop AI implementations and tests of the ideas to be developed. 






One research risk is that it will turn out that some of the informal requirements cannot be spelled out in probabilistic terms, or expressed in terms of properties of Bayesian networks. In such an event, I will  study the reasons for this negative result. It might happen that there are independent reasons to abandon a given condition, or it might be the case that probabilistic inexplicability of a given condition is an argument against the probabilistic approach. Either way, finding out which option holds and why would also lead to a deeper understanding of the framework and lead to a publication in academic journals. Another research risk is that the case studies will show that other methods are more efficient or transparent. This would itself constitute a result that could be used to further modify the framework so that its best aspects could be preserved, while the disadvantages discovered during case studies avoided. 




 
 
 






















\pagebreak 








# References {-}

\footnotesize 
