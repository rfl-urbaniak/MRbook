---
title: '\Large Many roads to higher-order probability'
author: Rafal  Urbaniak \footnotesize \newline (LoPSE research
  group, University of  Gdansk)
date: "Boston, Northeastern Ethics & Epistemology Workshop 2022"
output:
  beamer_presentation:
    theme: Rafal_beamerSly1
    keep_tex: yes
    slide_level: 2
  slidy_presentation: default
fontsize: 10pt
classoption: x11names, dvipsnames, bibspacing,natbib, table
urlcolor: blue
bibliography: [../references/imprecise1.bib,../references/referencesMRbook.bib]
csl: ../references/apa-6th-edition.csl
link-citations: yes
toc: yes
---



```{r setup, include=FALSE}
library(tidyverse)
library(gridExtra)
library(kableExtra)
library(magrittr)
library(ggplot2)
library(ggpubr)
library(ggExtra)
library(ggthemes)
library(ggforce)
library(latex2exp)
library(forcats)
library(dagitty)
library(rethinking)
library(reshape2)
library(philentropy)
library(plot3D)
th <- theme_tufte(base_size = 20)
options(kableExtra.latex.load_packages = FALSE)
```



# Motivations for imprecise probabilism




##  Imprecision and evidence responsiveness


### Precise probabilism (PP)

\justify A rational agent's (RA)  degrees of belief are to be represented by means of a single probability measure defined over every proposition she entertains

\pause

### Example: fair coin

\begin{center}
\begin{tabular}{lp{9cm}}
(H) & The outcome of the next toss will be heads\\
(Fair coin) & RA is about to toss a fair coin
\end{tabular}
\end{center}

\vspace{-6mm}

\begin{align*}
\mathsf{P}(H) & = \mathsf{P}(\neg H)=.5
\end{align*}


\pause

### Example: Unknown bias

\begin{center}
\begin{tabular}{lp{9cm}}
(Unknown bias) & RA is about to toss a coin whose bias is unknown
\end{tabular}
\end{center}

\pause

\vspace{-6mm}

\begin{align}
\tag{PIE} \mathsf{P}(H) & = \mathsf{P}(\neg H)=.5
\end{align}





##  Imprecision and evidence responsiveness


### Locality
\justify RA's credal stance (in a wide, non-technical sense) about a proposition is to be captured by whatever probability (or probabilities) she assigns to it, and does not depend on what probabilities RA assigns to logically independent  propositions

\pause

### Trouble with evidence responsiveness

\justify PP can't distinguish between (Fair coin) and (Unknown bias)

\pause


### Trouble with sweetening

\justify If RA doesn't know what the bias of the coin is, learning that it now  has increased  by .001, might still leave RA undecided




## Imprecise probabilism (IP)


### Representors

RA's credal stance towards $H$ is to be represented by means of a set of those probability measures $\mathbb{P}$, which   are \textbf{compatible with evidence}



\flushright \tiny [@keynes1921treatise;@Levi1974ideterminate; @Gardenfors1982unreliable; @Kaplan1968decision;  @joyce2005probabilities; @VanFraassen2006vague; @Sturgeon2008grain; @walley1991statistical; @bradley2019imprecise] 

\normalsize

\pause

### Evidence responsiveness

- Fair coin: as PP

- Unknown bias: all possible probability measures


\pause

### Indifference and indecision

-  Indifference: $A$ and $B$ are equally likely

-  Indecision:  no comparison, no such determination
 
\flushright  \tiny [@Kaplan1968decision]



## Probabilistic opinion pooling

### Independence preservation

If every member agrees that $X$ and $Y$ are probabilistically independent, the aggregated credence should respect this

\pause

### Independence preservation fails on linear pooling and PP

\vspace{-4mm}

\begin{align*}
p(X)  & = p(Y)  = p(X\vert Y) = 1/3\\
q(X) &  =  q(Y) = q(X\vert Y) = 2/3 
\end{align*}
\pause

\vspace{-10mm}

\begin{align*}
r& =p/2+q/2\\
r(X\cap Y) & = 5/18 \neq r(X)r(Y)=1/4
\end{align*}

\flushright  \tiny  [@Dietrich2016pooling]


## Gallow's limitation result

### Al and Bert 

\begin{align} \label{eq:gal1}
\pr{A=B} & <1\\
\label{eq:gal2}
\pr{r\vert A=a}  = a  &  \,\,\,\, \pr{r\vert B=b}  = b\\
\label{eq:gal3}
\forall a,b \, \pr{r \vert A =a, B = b} & =  \alpha a + \beta b
\end{align}

\flushright  \tiny For reflection see: [@gaifman1988higherOrder; @vanFraassen1984beliefandWill; @Lewis1980subjectivist; @Elga2007reflection]

\pause

### The hard truth

\justify For any proposition $r$, if $A$ and $B$ are random variables taking  values in the unit interval,  there is no  probability measure  $\mathsf{P}$ such that \eqref{eq:gal1}, \eqref{eq:gal2},  and \eqref{eq:gal3} all hold

\vspace{1mm}

\flushright  \tiny [@Gallow2018masters]

\pause

### The IP approach to pooling

Bundle them up into a set of measures!

\vspace{1mm}

\flushright \tiny [@Elkin2018resolving,@Stewart2018pooling] 




## Some caveats


\pause

### Learning and imprecision

RA's representor should be updated point-wise: 
\begin{align*} \label{eq:updateRepresentor}
\mathbb{P}_{t_1} = \{\mathsf{P}_{t_1}\vert \exists\, {\mathsf{P}_{t_0} \!\in  \mathbb{P}_{t_0}}\,\, \forall\, {H}\,\, \left[\mathsf{P}_{t_1}(H)=\mathsf{P}_{t_0}(H \vert E)\right] \}.
\end{align*}


\pause

### MaxEnt as our guide

Start learning with a distribution that---given the evidence available---is maximally noncommittal with regard to missing information

\vspace{1mm}

\flushright  \tiny [@jaynes2003probability; @williamson2010defence]

\pause

### Supervaluationist comparison

RA is more confident of $A$ than $B$ just in case all members of RA's representor prefer $A$


# Challenges to IP



## More evidence responsiveness

\pause

### Two biases

\begin{center}
\begin{tabular}{lp{9cm}}
(Two biases) & The bias is either .4 or .6
\end{tabular}
\end{center}

\pause

$\mathsf{P}_1, \mathsf{P}_2$ such that $\mathsf{P}_1(H)=.4$ and $\mathsf{P}_2(H)=.6$?

\pause

### Two unbalanced biases?

\begin{center}
\begin{tabular}{lp{5.5cm}}
(Two unbalanced biases) & The bias is either .4 or .6, and  .4 is three times  more likely than .6
\end{tabular}
\end{center}


## Comparison revisited: Rinard's mysteru urns

 - \textsf{GREEN} contains only green marbles 

 - no information about \textsf{MYSTERY}
 

 
\pause
 

### Intuitions here
 
-  RA should be certain that the marble drawn from \textsf{GREEN}  will be green ($G$),
 
- RA should be more confident  about $G$ than that the marble from \textsf{MYSTERY} will be green ($M$)
 
\pause
 
### The trouble for IP
 
- For each $r\in [0,1]$ RA's representor contains a $\mathsf{P}$ with $\pr{M}=r$

\pause

-  Including the one with $\pr{M}=1$

\pause 

- So it is not the case that for any of RA's representor $\mathsf{P}$, $\mathsf{P}(G) > \mathsf{P}(M)$

- So---on IP---RA does not prefer $G$ over $M$


\flushright \tiny  [@Rinard2013against]


\vspace{1mm}




## Belief inertia

### Setup and intuition

\vspace{-2mm}

\begin{description}
\item[Stage 0] Coin bias is in $[0,1]$ 

\pause

\item[Stage 1]  Five heads in ten tosses,  evidence for  bias  around .5 
\end{description}

\pause

### Trouble for PP

 By (PIE),  $\mathsf{P}_0(H)=.5$ in Stage 0 updates to   $\mathsf{P}_1(H)=.5$ in Stage 1


## Belief inertia


### Trouble for IP

```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "60%", warning=FALSE, message = FALSE, dpi = 800}
p <- ggplot(data = data.frame(value = 1:7), 
            mapping = aes(x = value))+ theme_tufte(base_size = 24)+
  theme(axis.line.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.x=element_blank(),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank())+
  ylab("probability")+xlim(c(1.8,6.2))


p1 <- p + geom_segment(aes(x = 2, y = 0, xend = 2, yend = 1), 
                 lineend = "square")+
  geom_segment(aes(x = 6, y = 0, xend = 6, yend = 1), 
               lineend = "square")+ 
  annotate("text", x = 1.8, y = .4, label = TeX("$p_{1}$"), size = 7)+
  annotate("text", x = 1.8, y = .6, label = TeX("$p_{2}$"), size = 7)+
  geom_segment(aes(x = 1.95, y = 0, xend = 2.05, yend = 0), 
               lineend = "square")+
  geom_segment(aes(x = 1.95, y = 0.4, xend = 2.05, yend = 0.4), 
               lineend = "square")+
  geom_segment(aes(x = 1.95, y = 0.6, xend = 2.05, yend = 0.6), 
               lineend = "square")+
  geom_segment(aes(x = 1.95, y = 1, xend = 2.05, yend = 1), 
               lineend = "square")+
  annotate("text", x = 6.2, y = .45, label = TeX("$p_{1}'$"), size = 7)+
  annotate("text", x = 6.2, y = .55, label = TeX("$p_{2}'$"), size = 7)+
  geom_segment(aes(x = 5.95, y = 0.45, xend = 6.05, yend = 0.45), 
  lineend = "square")+
  geom_segment(aes(x = 5.95, y = 0.55, xend = 6.05, yend = 0.55), 
               lineend = "square")+
  geom_segment(aes(x = 2.1, xend = 5.9, y = 0.4, yend = .45), arrow = arrow(length = unit(0.08, "inches")),
  color = "red", size = 0.6)+ 
  geom_segment(aes(x = 2.1, xend = 5.9, y = 0.6,
                   yend = .55), arrow = arrow(length = unit(0.08, "inches")),
               color = "red", size = 0.6)

p2 <-  p1+
  annotate("text", x = 1.8, y = 0, label = TeX("$p_F$"), size = 7 )+
  annotate("text", x = 1.8, y = 1, label = TeX("$p_T$"), size = 7) +
  annotate("text", x = 6.2, y = 0, label = TeX("$p_F'$"), size = 7)+
  annotate("text", x = 6.2, y = 1, label = TeX("$p_T'$"), size = 7) +
   geom_segment(aes(x = 5.95, y = 0, xend = 6.05, yend = 0), 
               lineend = "square")+
  geom_segment(aes(x = 5.95, y = 1, xend = 6.05, yend = 1), 
               lineend = "square")+ 
  geom_segment(aes(x = 2.1, xend = 5.9, y = 0,
              yend = 0), arrow = arrow(length = unit(0.08, "inches")),
               color = "red", size = 0.6)+ 
  geom_segment(aes(x = 2.1, xend = 5.9, y = 1,
                   yend = 1), arrow = arrow(length = unit(0.08, "inches")),
               color = "red", size = 0.6) 


p3 <- p2 + 
  geom_segment(aes(x = 2.2, xend = 5.8, y = 0.35, yend = 0.4), arrow = arrow(length = unit(0.06, "inches")),
               color = "skyblue", size = 0.3)+ 
  geom_segment(aes(x = 2.2, xend = 5.8, y = 0.65, yend = 0.6), arrow = arrow(length = unit(0.06, "inches")),
               color = "skyblue", size = 0.3)

p1
```


\flushright \tiny [@Levi1980enterprise]




















## Belief inertia


### Trouble for IP

```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "60%", warning=FALSE, message = FALSE, dpi = 800}
p2
```


\flushright \tiny [@Levi1980enterprise]






## Belief inertia


### Trouble for IP

```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "60%", warning=FALSE, message = FALSE, dpi = 800}
p3
```



\flushright \tiny [@Levi1980enterprise]









## Belief inertia

### Rinard's version

\begin{description}

\item[H1] All the marbles in the urn are green

\item[H2] Exactly one tenth of the marbles are green

\item[E] The marble drawn at random from the urn is green
\end{description}
Starting with $[0,1]$ RA has exactly the same spread of values for $H_1$, and 
this does not depend on how many marbles are sample from the urn and found to be green


## Weight of evidence


\pause

### Set up: the bias lies within $(.4, .6)$  

\begin{description}
\item[Version 1] One fairly reliable witness tells RA the actual bias is .5


\item[Version 2] Two equally reliable witnesses: one tells RA that the real bias is .4 and the other one tells them the real bias is .6

\end{description}

\pause

### Concentration increase and IP

@walley1991statistical suggests narrowing envelopes

@joyce2005probabilities proposes:


\vspace{-4mm}

\footnotesize
\begin{align*}
w_p (H,D) & = \int_{0}^{1} \vert 
f(B = x) \times (x - p(H))^2 - f_D(B - x) \times (x - p_{D}(H))^2
\vert \, dx
\end{align*}

\pause

\normalsize

- abandoning locality

- works for unimodal distros

- parasitic on chances




## Accuracy

### Priopriety

- Any agent will score her own credence function to be more inaccurate than every other credence function

\pause

- no proper scoring rules are available for representors, and so no accuracy-oriented foundations for IP have been developed

\flushright \tiny [@seidenfeld2012forecasting; @Mayo-Wilson2016scoring; @Schoenfield2017accuracy; @CampbellMoore2020accuracy]


\pause

### No recommendation


\begin{center}
\begin{tabular}{lp{6.5cm}}
 (EMC)  & The opponent will  produce two coins with the objective chances of Heads  $.3$ and $.5$, randomly pick one of these coins and then toss it
\end{tabular}
\end{center}

\vspace{-4mm}

\pause

\justify If an accuracy measure for imprecise credences satisfies certain fairly straightforward constraints, for any imprecise credal state one might have there is a precise one with at least the same accuracy

\flushright \tiny [@Schoenfield2017accuracy]





## Synergy

### The reasonable range assumption

\centering 
\begin{tabular}{lp{8cm}}
On PP &  For any group of peers whose credences in a proposition $X$ range from $x$ to $y$, the aggregated  credence is within  $[x, y]$ \\
On IP &   The upper and lower envelopes with respect to $X$ after aggregation will be simply the maximum and the minimum of the individual expert's envelopes
\end{tabular}


\pause

### Example of synergy

\justify   A doctor  is fairly confident that a treatment dosage for a patient is correct (.97) and considers the opinion of a colleague, whose credence  is   0.96


\flushright \tiny  [@Christensen2009disagreement]




# Rethinking imprecision

## Rethinking imprecision

### Can't run away from false precision

Why $[.2-.8]$  rather than, say $[.2,.80001]$?

\flushright \tiny   [@Carr2020impreciseEvidence]


\pause

### Evidential constraints beyond testimonial evidence

\begin{description}
\item[evidence of chances] $\{ \mathsf{P}(X) = x\}$ or $\mathsf{P}(X) \in [x,y]$
\item[structural constraints]  "$X$ and $Y$ are independent", or \linebreak  "$X$ is more likely than $Y$." 
\end{description}

 \flushright \tiny [@bradley2012uncertaintyPhD]

\pause

### How can  non-testimonial evidence result in those?

- extreme cases

- finite sets with known real frequencies

What else?


## Rethinking imprecision

### Statistical evidence?

"statistical evidence might inform [evidential] constraints [\dots  evidence] of causes might inform structural constraints"

\flushright \tiny [@bradley2012uncertaintyPhD] 

\pause

### Unrealistic

- Far cry from a clear account

- Real statistical analysis or causal inference almost never leads to such strong claims

- Meta-analysis leads to even more careful claims


## Dropping (Locality)

\pause

### Joyce

- uses density over chance hypotheses  to account for the notion of evidential weight

- still insists that  RA's stance  should be represented as the expected value of this density

\pause

### Bradley 

\begin{itemize}
\item  In a discussion of belief inertia:
\begin{quote}
\dots the committee members are "bunching up". Whatever measure you put over the set of probability functions---whatever "second order probability" you use---the "mass" of this measure gets more and more concentrated around the true chance hypothesis  \mbox{[p. 157]}
\end{quote}
\pause
\item   In a discussion of decision theory:
\begin{quote} \dots there is no justification for saying that there is more of your representor here or there \mbox{~[p.~195]}
\end{quote}
\end{itemize}



## Dropping (Locality)

### Towards HOP

- imprecise evidence requires uncertainty about what credences to have

-  vague credences, assigning various weights to probabilities, which are sometimes to be interpreted as  RA's credence in propositions about what credences the evidence supports, and sometimes as RA's uncertainty about objective chances

\flushright \tiny  [@Carr2020impreciseEvidence]

\pause

### What's lacking?

- not a full-fledged proposal

- no  formal explication

- no explanation of how exactly this helps with the problems we discussed


## The positive proposal 

### Bayesian statistical practice

Use  Bayesian statistical methods from this perspective to explain away most of the difficulties that either motivate or undermine IP

\pause

### Key insights

-  uncertainty is not a single-dimensional thing to be mapped on a single one-dimensional scale like a real line 

-  the shape of the whole distribution over parameter values is a more adequate representation

- summaries are just that







## Evidence responsiveness revisited


```{r evidenceResponse1,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
p <- seq(from=0 , to=1 , by = 0.001)
FairDensity <- ifelse(p == .5, 1, 0)
FairDF <- data.frame(p,FairDensity)
FairPlot <- ggplot(FairDF, aes(x = p, y = FairDensity))+geom_line()+theme_tufte()+
  xlab("parameter value")+ylim(c(0,1))+ylab("probability")+ggtitle("Fair coin")+
  theme(plot.title.position = "plot")

UniformPlot <- ggplot()+xlim(c(0,1))+stat_function(fun = dunif, args = list(min = 0, max = 1))+
  ylim(0,1)+
  theme_tufte()+
  xlab("parameter value")+
  ylab("probability density")+theme(plot.title.position = "plot")+ggtitle("Unknown bias")


p <- seq(from=0 , to=1 , by = 0.001)
TwoDensity <- ifelse(p == .4 | p == .6, .5, 0)
TwoDF <- data.frame(p,TwoDensity)
TwoPlot <- ggplot(TwoDF, aes(x = p, y = TwoDensity))+geom_line()+theme_tufte()+
  xlab("parameter value")+ylim(c(0,1))+ylab("probability")+ggtitle("Two biases with PIE")+
  theme(plot.title.position = "plot")+scale_x_continuous(breaks = c(.4,.6), labels = c(.4, .6))




p <- seq(from=0 , to=1 , by = 0.001)
TwoUnbalancedDensity <- ifelse(p == .4, .75, ifelse(p ==  .6, .25, 0))
TwoUnbalancedDF <- data.frame(p,TwoUnbalancedDensity)
TwoUnbalancedDensity
TwoUnbalancedPlot <- ggplot(TwoUnbalancedDF, aes(x = p, y = TwoUnbalancedDensity))+geom_line()+theme_tufte()+
  xlab("parameter value")+ylim(c(0,1))+ylab("probability")+ggtitle("Two unbalanced biases")+
  theme(plot.title.position = "plot")+scale_x_continuous(breaks = c(.4,.6), labels = c(.4, .6))

evidenceResponse <- ggarrange(FairPlot,UniformPlot, TwoPlot, TwoUnbalancedPlot)
```







```{r fig:evidenceResponse,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%"}
evidenceResponse
```



## Qualitative considerations and HDIs


```{r buildHPDIplot,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
p_grid <- seq( from=0 , to=1 , length.out=1000 )
prior <- rep(1,1000)
likelihood <- dbinom( 5 , size=5 , prob=p_grid )
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
samples <- sample( p_grid , size=1e4 , replace=TRUE , prob=posterior )
#PI( samples , prob=0.5 )
#HPDI(samples, prob = .5)

df <- data.frame(p_grid, posterior)

ciPlot <- ggplot(df,aes(x = p_grid, y = posterior))+geom_line()+theme_tufte(base_size = 7)+
  ggtitle(".5 credible interval: (.79-.95)  \n (posterior of 5 heads in 5 tosses with uniform prior)")+
  theme(plot.title.position = "plot")+ylab("posterior")+xlab("parameter value")+
  geom_area(data = subset(df, p_grid > .7937 & p_grid < .955),
           aes(x=p_grid, y = posterior), fill="skyblue", alpha = 0.4)


hpdiPlot <- ggplot(df,aes(x = p_grid, y = posterior))+geom_line()+theme_tufte(base_size = 7)+
  ggtitle(".5 highest posterior density interval: (.89-1)  \n (posterior of  5 heads in 5 tosses with uniform prior)")+
  theme(plot.title.position = "plot")+ylab("posterior")+xlab("parameter value")+
  geom_area(data = subset(df, p_grid > .892 & p_grid <= 1),
            aes(x=p_grid, y = posterior), fill="skyblue", alpha = 0.4)




p_grid <- seq( from=0 , to=1 , length.out=1000 )
A <- dnorm(p_grid, .4, .05)
B <- dnorm(p_grid, .6, .05)
C <- ifelse( p_grid <= .5, A, B) 
prior <- rep(1,1000)
likelihood <- C
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
samples <- sample( p_grid , size=1e4 , replace=TRUE , prob=posterior )
density <- ggplot()+geom_density(aes(x=samples))+theme_tufte()+
  xlab("parameter value")
d <- ggplot_build(density)$data[[1]]
#mean(d$y >=1.58)
bimodalPlot <- ggplot(d,aes(x = x, y = y))+geom_line()+theme_tufte(base_size = 7)+
  geom_area(data = subset(d, y > 1.58 & x < .5),aes(x=x, y = y), fill="skyblue", alpha = 0.4)+
  geom_area(data = subset(d, y > 1.58 & x > .5),aes(x=x, y = y), fill="skyblue", alpha = 0.4)+
  ggtitle(".5 highest posterior density intervals: (.33-.47) and  (.52-.67)  \n (bimodal distribution with modes at .4 and .5)")+
  theme(plot.title.position = "plot")+ylab("density")+xlab("parameter value")


#subset(d, y > 1.58 & x < .5)[1,]
#tail(subset(d, y > 1.58 & x < .5),1)
#.33-.47
#subset(d, y > 1.58 & x > .5)[1,]
#tail(subset(d, y > 1.58 & x > .5),1)
#.52-.67


bimodalCIPlot <- ggplot(d,aes(x = x, y = y))+geom_line()+theme_tufte(base_size = 7)+
  geom_area(data = subset(d, x > .33 & x < .66),aes(x=x, y = y), fill="skyblue", alpha = 0.4)+
  ggtitle(".5 credible interval: (.33-.66)  \n (bimodal distribution with modes at .4 and .5)")+
  theme(plot.title.position = "plot")+ylab("density")+xlab("parameter value")

HPDIplot <- ggarrange(ciPlot, hpdiPlot, bimodalCIPlot, bimodalPlot)
```



```{r fig:HPDIplot,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE}
HPDIplot
```











## HDI and the green-mystery challenge

### Qualitative comparisons  with HDI

\noindent Suppose HDIs for $A, B$ have limits respectively 
$a_l, a_h, b_l, b_h$

\pause

-  RA definitely considers $A$ at least as likely as $B$
($A\geq B$) just in case $a_l\geq b_l$ and $a_h \geq b_h$

-  $A>B$ iff $A\geq B$ but not $B \geq A$

- RA considers $A$ plausible just in case $a_l>t$ for some sensibly high threshold
$t$

\pause

### Back to Rinard's green mystery

- For the GREEN urn, the HDI is just $g=[1,1]$
-  HDI for MYSTERY is $m = [0,1]$
\pause

\noindent  $g_l> m_l$ and $g_h \geq m_h$, and so $G\geq M$, but not
$M\geq G$, and therefore $G>M$, as desired


# Intermezzo: entropy and divergence

## Shannon information


\pause 

```{r label,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "70%",   message = FALSE, warning = FALSE, results = FALSE}

entDAG <- dagitty("
    dag{
        A -> B
        A -> x
        B -> C
        B -> y
        C -> D
        C -> z
      }")


coordinates(entDAG) <- list( x=c(A = 1, B = 2, x = 2, C = 3, y = 3, D = 4, z = 4),
                            y=c(A = 2, B = 3, x = 1, C = 2, y = 3, D = 2, z = 3) )
drawdag(entDAG, shapes =  list(A = "c", B = "c", C = "c", D = "c"), cex = 1.5, radius = 6)
```

\pause 

-  The right path is:  011. 

- There are $m=8$ possible
destinations that could be reached by making decisions at
$\log_2(8)=3$ forks



## Shannon information

### Surprise at first step

- Initially you thought the probability that it is the
right one was .5

- Now you know it is the right one. Surprise: $\nicefrac{1}{.5}=2$


\pause

### Additive surprise 

- One \emph{bit} of information: $\log_2(\nicefrac{1}{.5})=1$ 

- Complete instruction:  $\log_2(\nicefrac{1}{.5^3})=3$

\pause

### The official definition

Notice that $\log_2(\frac{1}{a})= - \log_2(a)$, so:
\begin{align*}
h(x) & = - \log_2 \mathsf{\pr{x}}
\end{align*} 


## Entropy

### Average Shannon information

\begin{align*}
H(X)  & = \sum \mathsf{P}(x_i) \log_2 \frac{1}{\mathsf{P}(x_i)} =
- \sum \mathsf{P}(x_i) \log_2 \mathsf{P}(x_i)
\end{align*}

\pause

### Conceptualization

- Not a measure of
information contained in a distribution

- the expected amount of information you receive once you learn what the value of $X$ is


\pause

### Caveat

\begin{align*}
H(X) & = \left[\int_{-\infty}^\infty p(x) \log_2 \frac{1}{p(x)}\, dx  \right] + \overbrace{\infty}^{
\lim_{\Delta \to  0 }\log_2\frac{1}{\Delta}} \\
H_{diff}(X) & = \left[\int_{-\infty}^\infty p(x) \log_2 \frac{1}{p(x)}\, dx  \right]
\end{align*}


## Divergence


### Two distributions

Events arise according to  $\mathsf{P}$,    we predict them using  $\mathsf{Q}$

\pause

### Cross-entropy

\vspace{-2mm}

 \begin{align*}
H(\mathsf{P}, \mathsf{Q}) & = \sum \mathsf{P}_i \log_2(\mathsf{Q}_i)
\end{align*} 

\noindent Higher than  $H(\mathsf{P})$ if distributions differ.

\pause

### Kullback-Leibler divergence

\vspace{-2mm}

\footnotesize
\begin{align*}
DKL(\mathsf{P}, \mathsf{Q}) & = H(\mathsf{P}, \mathsf{Q}) - H(\mathsf{P})\\
&= - \sum \mathsf{P}_i \log_2(\mathsf{Q}_i)  - \left(   - \sum \mathsf{P}_i \log_2 \mathsf{P}_i\right) \\
& = - \sum \mathsf{P}_i\left( \log_2 \mathsf{Q}_i - \log_2\mathsf{P}_i\right)\\
& =  \sum \mathsf{P}_i\left( \log_2 \mathsf{P}_i - \log_2\mathsf{Q}_i\right)\\
& = \sum \mathsf{P}_i \log_2 \left( \frac{\mathsf{P}_i}{\mathsf{Q_i}}\right)
\end{align*}



## Divergence

### KL-divergence

\begin{align*}
DKL(\mathsf{P}, \mathsf{Q})  & = \sum \mathsf{P}_i \log_2 \left( \frac{\mathsf{P}_i}{\mathsf{Q_i}}\right)
\end{align*}

### Conceptualizations

-  The additional entropy introduced by
using $\mathsf{Q}$ instead of $\mathsf{P}$

-  The expected
difference in log probabilities

\pause

### Sanity check

If $\mathsf{P}=\mathsf{Q}$ we get:
\begin{align*}
DKL(\mathsf{P},\mathsf{P}) = \sum \mathsf{P}_i (\log_2 \mathsf{P}_i - \log_2 \mathsf{P}_i) = 0
\end{align*}



# Weight of evidence

## Weight of evidence

### Basic intuitions

\begin{enumerate}
\item Items of evidence leading to different expected values should be able to have the same weight

\pause

\item Items of evidence leading to the same value should be able to have different weights

\pause

\item In simple set up, such as Bernoulli trials, weight should increase with the number of observations

\pause

\item For unimodal distributions, the wider the distribution associated with a given piece of evidence, the less weight this evidence has
\end{enumerate}

\pause

### Modular approach

-  weights as associated with distributions 

- application to likelihoods, which don't have to sum (integrate) to 1

## Weight of evidence: explication

### Weight of a distribution

The more informative a piece of evidence is, as compared to the uniform distribution, the more weight it
has, on scale 0 to 1.
\begin{align*}
\mathsf{w(P_i)} & = 1 - \left( \frac{H(\mathsf{P})}{H(\mathsf{uniform})}\right)
\end{align*}
\pause
The entropy of a uniform distribution is  straightforward, simplify:
\begin{align*}
H(\mathsf{uniform}) & = \sum_{i=1}^n \nicefrac{1}{n} \log_2 \frac{1}{\nicefrac{1}{n}} \\
& = \log_2(n) \\
\mathsf{w(P_i)} & = 1 - \left( \frac{H(\mathsf{P})}{\log_2(n)}\right)
\end{align*}






## Weight of evidence: distributions

```{r fig:betas,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
n <- 1000 #parameters 
s <- 1e5  #sample size
ps <- seq(from=0 , to=1 , length.out=n)
a <- seq(1,100,1)
b <- seq(1,100,1)
abs <- expand.grid(a=a,b=b)
densitiesBeta <- list()

for(i in 1:nrow(abs)){
densitiesBeta[[i]] <- dbeta(ps,abs[i,1], abs[i,2])
densitiesBeta[[i]] <- densitiesBeta[[i]]/sum(densitiesBeta[[i]])
abs$entropy[i] <- H(densitiesBeta[[i]])
}



kld <- function(p,q) kullback_leibler_distance(p,q, testNA = TRUE, unit = "log2",
                                               epsilon = 0.00001)
klds <- numeric(length(densitiesBeta))
for (i in 1:length(densitiesBeta)){
  klds[i] <-   kld(densitiesBeta[[1]],densitiesBeta[[i]])
}
abs$klds <- klds


eucs <- numeric(length(densitiesBeta))
for (i in 1:length(densitiesBeta)){
  eucs[i] <-   euclidean(densitiesBeta[[1]],densitiesBeta[[i]], testNA = TRUE)
}

abs$eucs <- eucs

unif <-dbeta(ps,1,1)
unif <- unif/sum(unif)
hunif <- H(unif)
entProp <- function(X) 1 - ( H(X)/hunif )  

entProps <- numeric(length(densitiesBeta))
for (i in 1:length(densitiesBeta)){
  entProps[i] <-   entProp(densitiesBeta[[i]])
}
abs$entProps <- entProps




entropiesBetaPlot <- ggplot()+theme_tufte()+xlab("parameter values")+
  ylab("probability")+theme(plot.title.position = "plot")+ylim(0,1)+
  ggtitle("Examples of beta distributions with their entropies and weights")+
geom_line(aes(x = ps,y = densitiesBeta[[1]]), lty = 1)+annotate("text", x = .45, y = 0.007,
                                            label = "beta(1,1) \n h = 9.96, w = 0", size = 3)+
  geom_line(aes(x = ps,y = densitiesBeta[[100]]), alpha = .6,  lty = 2)+
  annotate("text", x = .87, y = 0.05, label = "beta(100,1) \n h = 4.75, w = .52", size = 3)+ylim(0,0.1)+
  geom_line(aes(x = ps,y = densitiesBeta[[940]]), alpha = .6, lty = 3 )+
  annotate("text", x = .79, y = 0.012, label = "beta(40,10)\n h = 7.83, w = .21", size = 3)+
  geom_line(aes(x = ps,y = densitiesBeta[[8410]]), alpha = .6, lty = 4)+
  annotate("text", x = .15, y = 0.018, label = "beta(10,85)\n h = 6.98, w = .3", size = 3)

entropiesBetaPlot
```



## Weight of evidence:distributions

```{r fig:entropies,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "70%",   message = FALSE, warning = FALSE, results = FALSE}
scatter3D(abs$a,abs$b,abs$entropy,
          pch=.1,cex=0.05,byt="g",alpha=0.4,theta=120,
          phi=20,xlab="a", ylab="b",zlab="entropy", 
          main="Entropies of beta distributions",
          colvar=NULL,cex.main =0.6, cex.lab = .7, cex.axis = .5, ticktype = "detailed", border = NA,
          nticks = 5)
```




## Weight of evidence: distributions


```{r fig:weights,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
weightsNo <-   ggplot(abs, aes(x = a + b, y = entProps, color = abs(a/(a+b)-.5)))+
    geom_point( alpha = .9, size = .3)+theme_tufte()+
  xlab("a+b")+ylab("Weight")+ggtitle("Weight increases with the number of observations")+
  labs(color = TeX("$|\\, \\frac{a}{a+b}   -.5 |$"),
       subtitle = "(faster if proportions are more extreme)")+
  theme(plot.title.position = "plot")+
scale_color_gradient(low="yellow1", high="dodgerblue4")


weightsProp <- ggplot(abs, aes(x = a /(a + b), y = entProps, color = a + b))+
  geom_point(size  = .4, alpha = .9)+theme_tufte()+
  xlab("a/(a+b)")+ylab("Weight")+ggtitle("Range of weights available at various proportions")+
  scale_color_gradient(low="yellow1", high="dodgerblue4")+
  labs(subtitle = "(higher if the number of observations higher)")+
  theme(plot.title.position = "plot",axis.title.y=element_blank(),
       axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

ggarrange(weightsNo,weightsProp)
```



## Weight of evidence: distributions

```{r weightsWeird,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
beta44 <-  densitiesBeta[[304]]
unif5 <- c(rep(0, n/2),rep(1 , n/2)) #uniform from .5 
unif5 <- unif5/sum(unif5)
unif6 <- c(rep(0, .6 * n),rep(1 , n * .4)) #uniform from .6 
unif6 <- unif6/sum(unif6)
A <- dnorm(ps, .4, .05)
B <- dnorm(ps, .6, .05)
C <- ifelse(ps <= .5, A, B) 
bimodal <- C / sum(C)
centered <-   dnorm(ps, .5, .05)
centered <- centered/sum(centered)
twoEven <- rep(0,1000)
twoEven[abs(ps -.4)  == min(abs(ps -.4))] <- .5
twoEven[abs(ps -.6)  == min(abs(ps -.6))] <- .5
twoUneven <- rep(0,1000)
twoUneven[abs(ps -.4)  == min(abs(ps -.4))] <- .3
twoUneven[abs(ps -.6)  == min(abs(ps -.6))] <- .7
single5 <- rep(0,1000)
single5[abs(ps -.5)  == min(abs(ps -.5))] <- 1
single7 <- rep(0,1000)
single7[abs(ps -.7)  == min(abs(ps -.7))] <- 1


distributions <- c("beta(4,4)","unif(.5,1)", "unif(.6,1)", "bimodal(.4,.6,s=.05)", "norm(.5,.05)",
                   "evenPoints(.4,.6)","unevenPoints(.4(.3),.6(.7)","single(.5)", "single(.7)")

entPropSeq <- c(entProp(beta44),entProp(unif5),entProp(unif6),
             entProp(bimodal),entProp(centered),entProp(twoEven),
             entProp(twoUneven),entProp(single5),entProp(single7))


hSeq <- c(H(beta44),H(unif5),H(unif6),
          H(bimodal),H(centered),H(twoEven),
          H(twoUneven),H(single5),H(single7))
  
  
entPropTable <- data.frame(distributions, hSeq, entPropSeq)

plotDistro <- function(distro, distroList) {
plot <-  ggplot()+theme_tufte()+xlab("parameter values")+
  ylab("probability")+theme(plot.title.position = "plot")+ylim(0,1)+
  ggtitle(paste(entPropTable$distributions[distroList]))+
  geom_line(aes(x = ps,y = distro))+annotate("text",
    x = ps[which(distro == max(distro))][1],
    y = max(distro) * 1.14,
    label = paste("h =",round(entPropTable$hSeq[distroList],3), ", w = ",
            round(entPropTable$entPropSeq[distroList],3)), size = 2)+
  ylim(c(0,1.2 * max(distro)))
return(plot)
}


multipleDistros <- ggarrange(plotDistro(beta44,1),
plotDistro(unif5,2),
plotDistro(unif6,3),
plotDistro(bimodal,4),
plotDistro(centered,5),
plotDistro(twoEven,6),
plotDistro(twoUneven,7),
plotDistro(single5,8),
plotDistro(single7,9), nrow = 9, ncol  = 1, heights  = 1)
```


```{r fig:weightsWeird,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
ggarrange(plotDistro(beta44,1),plotDistro(unif5,2), plotDistro(unif6,3),plotDistro(bimodal,4),plotDistro(centered,5),
plotDistro(twoEven,6),plotDistro(twoUneven,7),
plotDistro(single5,8),plotDistro(single7,9), ncol = 3, nrow = 3)
```





## Weight of evidence: likelihood ratio

\scriptsize

\vspace{-2mm}

 \begin{align*}
 \mathsf{LR}(E,H) & = \frac{\pr{E \vert H}}{\pr{E \vert \n H}}\\
 l(\theta) & = p(E\vert \theta)\\
 \pr{E\vert \theta} & = \pr{E \vert H} \theta + \pr{E \vert \n H}(1- \theta)
 \end{align*}
\normalsize
 
 \vspace{-6mm}
 
\pause
 
```{r fig:likelihood,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "85%",   message = FALSE, warning = FALSE, results = FALSE}


plotDistroPlain <- function(distro, title = "", mult = 1.2) {
  plot <-  ggplot()+theme_tufte()+xlab("parameter values")+
    ylab("probability")+theme(plot.title.position = "plot")+ylim(0,1)+
    ggtitle(title)+
    geom_line(aes(x = ps,y = distro))+
    ylim(c(0,mult * max(distro)))
  return(plot)
}

prior <- dbeta(ps,2,4)
prior <- prior/sum(prior)

plotPrior <- plotDistroPlain(prior, "Prior probability")

# samplePrior <- sample(ps, size = 1e4, prob = prior, replace = TRUE)
# HPDI(samplePrior)

likelihood1  <- ps * .3 + (1-ps)*.1
likelihood01  <- ps * .95 + (1-ps)*.001

posterior1 <- prior * likelihood1
posterior1 <- posterior1/sum(posterior1)

posterior01 <- prior * likelihood01
posterior01 <- posterior1/sum(posterior01)

# samplePosterior1 <- sample(ps, size = 1e4, prob = posterior1, replace = TRUE)
# HPDI(samplePosterior1)

# samplePosterior01 <- sample(ps, size = 1e4, prob = posterior01, replace = TRUE)
# HPDI(samplePosterior01)

plotLikelihood1 <- plotDistroPlain(likelihood1, "Likelihood with probability range (.1,.3), w = .006")

plotLikelihood01 <- plotDistroPlain(likelihood01, "Likelihood with probability range (.001,.95), w = .2")

plotPosterior1 <- plotDistroPlain(posterior1, "Posterior vs prior for (.1,.3)")+
  geom_line(aes(x = ps, y = prior), color = "grey", lty =2)+ylim(0,.007)+
  labs(subtitle = "HDI = (.078,.65), w .052 to .046")

plotPosterior01 <- plotDistroPlain(posterior01, "Posterior vs prior for (.001,.95)")+
  geom_line(aes(x = ps, y = prior), color = "grey", lty = 2)+ylim(0,.007)+
  labs(subtitle = "HDI = (.067,.64),, w .052 to .049")

grid.arrange(plotLikelihood1, plotLikelihood01, plotPosterior1, plotPosterior01)
```



# Belief inertia

## Belief inertia: learning from uniform

```{r fig:inertia, eval = TRUE, echo=FALSE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", message= FALSE, warning=FALSE}

n <- 1000 #parameters 

ps <- seq(from=0 , to=1 , length.out=n)

prior <- rep(1/n , n) #uniform prior

likelihood1g <- dbinom( 1 , size=1 , prob=ps)
likelihood2g <- dbinom( 2 , size=2 , prob=ps)
likelihood2g1b <- dbinom( 2 , size=3 , prob=ps)

posterior1g <- likelihood1g * prior
posterior2g <- likelihood2g * prior
posterior2g1b <- likelihood2g1b * prior


posterior1g <- posterior1g / sum(posterior1g)
posterior2g <- posterior2g / sum(posterior2g)
posterior2g1b <- posterior2g1b / sum(posterior2g1b)

upperLimit <- .003

InertiaPriorPlot <- ggplot()+geom_line(aes(x = ps, y = prior))+theme_tufte()+xlab("p")+
  ylab("probability")+theme(plot.title.position = "plot")+ggtitle("Prior")+
  scale_x_continuous()+scale_y_continuous(limits = c(0,upperLimit))


InertiaOneGPlot <- ggplot()+geom_line(aes(x = ps, y = posterior1g))+theme_tufte()+xlab("p")+
  ylab("probability")+theme(plot.title.position = "plot",
                            axis.text.y = element_blank(),
                            axis.title.y = element_blank(),
                          axis.ticks.y =element_blank()
)+ggtitle("Evidence: g")+
  scale_y_continuous(limits = c(0,upperLimit))



InertiaTwoGPlot <- ggplot()+geom_line(aes(x = ps, y = posterior2g))+theme_tufte()+xlab("p")+
  ylab("probability")+theme(plot.title.position = "plot"#, 
#                        axis.text.y = element_blank(),
#                            axis.title.y = element_blank(),
#                            axis.ticks.y = element_blank()
                  )+ggtitle("Evidence: g, g")+
scale_y_continuous(limits = c(0,upperLimit))

InertiaTwoGoneBluePlot <- ggplot()+geom_line(aes(x = ps, y = posterior2g1b))+theme_tufte()+xlab("p")+
  ylab("probability")+theme(plot.title.position = "plot",     axis.text.y = element_blank(),
  axis.title.y = element_blank(),
      axis.ticks.y = element_blank()
           )+ggtitle("Evidence: g, g, b")+
  scale_y_continuous(limits = c(0,upperLimit))
```



```{r fig:inertia2, echo=FALSE, eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
grid.arrange(InertiaPriorPlot, InertiaOneGPlot,  InertiaTwoGPlot, InertiaTwoGoneBluePlot, ncol = 2, nrow = 2)
```


## Belief inertia: Rinard's version



\scriptsize 

\begin{description}

\item[H1] All the marbles in the urn are green

\item[H2] Exactly one tenth of the marbles are green

\item[E] The marble drawn at random from the urn is green
\end{description}

\normalsize
\pause

\vspace{-3mm}

```{r rinardCalculations, eval = TRUE, echo=FALSE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", message= FALSE, warning=FALSE}

ps <- seq(from=0 , to=1 , by = 0.01)

prior <- ifelse( (ps == .1 | ps == 1), .5, 0 ) #prior information 

likelihood1g <- dbinom( 1 , size=1 , prob=ps)
likelihood2g <- dbinom( 2 , size=2 , prob=ps)
likelihood2g1b <- dbinom( 2 , size=3 , prob=ps)

posterior1g <- likelihood1g * prior
posterior2g <- likelihood2g * prior
posterior2g1b <- likelihood2g1b * prior


posterior1g <- posterior1g / sum(posterior1g)
posterior2g <- posterior2g / sum(posterior2g)
posterior2g1b <- posterior2g1b / sum(posterior2g1b)

priorPlot <- ggplot()+geom_bar(aes(x = ps, y = prior), stat = "identity")+theme_tufte()+xlab("p")+
  ylab("probability")+theme(plot.title.position = "plot")+ggtitle("Prior")+
  scale_x_continuous(breaks = c(.1,1))+scale_y_continuous(breaks = seq(0,1, by = .1))


OneGPlot <- ggplot()+geom_bar(aes(x = ps, y = posterior1g), stat = "identity")+theme_tufte()+xlab("p")+
  ylab("probability")+theme(plot.title.position = "plot"#,
                            #axis.text.y = element_blank(),
                            #axis.title.y = element_blank(),
                            #axis.ticks.y = element_blank()
                            )+ggtitle("Evidence: g")+
  scale_x_continuous(breaks = c(.1,1))+scale_y_continuous(breaks = seq(0,1, by = .25))

TwoGPlot <- ggplot()+geom_bar(aes(x = ps, y = posterior2g), stat = "identity")+theme_tufte()+xlab("p")+
  ylab("probability")+theme(plot.title.position = "plot", 
                            #axis.text.y = element_blank(),
                            #axis.title.y = element_blank(),
                            #axis.ticks.y = element_blank()
                            )+ggtitle("Evidence: g, g")+
  scale_x_continuous(breaks = c(.1,1))+scale_y_continuous(breaks = seq(0,1, by = .25))

TwoGoneBluePlot <- ggplot()+geom_bar(aes(x = ps, y = posterior2g1b), stat = "identity")+theme_tufte()+xlab("p")+
  ylab("probability")+theme(plot.title.position = "plot"
                            #,   axis.text.y = element_blank(),
                            #axis.title.y = element_blank(),
                            #axis.ticks.y = element_blank()
                            )+ggtitle("Evidence: g, g, b")+scale_x_continuous(breaks = c(.1,1))+scale_y_continuous(breaks = seq(0,1, by = .25))

rinard <- grid.arrange(priorPlot, OneGPlot,  TwoGPlot, TwoGoneBluePlot, nrow = 2)

```



```{r fig:rinard,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "80%",   message = FALSE, warning = FALSE, results = FALSE}
rinard
```



# Accuracy

## Accuracy: CPRS

### Continuous ranked probability score
\begin{align*}
I(p,w) &= \int_{-\infty}^\infty \vert \mathsf{P}(x) - \mathbf{ 1 }(x\geq V(w))\vert ^2 \, dx
\end{align*}
\noindent where $\mathsf{P}$ is the cumulative probability corresponding to a given density, and
\begin{align*}
\mathbf{ 1 }(x \geq V(w)) & = \begin{cases} 1 & \text{ if } x \geq V(w)\\
0 & \text{ o$\,$/w}
\end{cases}
\end{align*}

\pause

### The intuition

- Take the Cramer-Von-Mises measure of distance between densities, defined in terms of the area under the squared euclidean distances:
\begin{align*}
\mathcal{C}(p,q) & = \int_{0}^{1} \vert P(x) - Q(x)\vert^2 \, dx
\end{align*}
-  Use it to measure distance to an epistemically omniscient chance hypothesis, which either puts full weight on 0, if a given proposition is false, or on 1, otherwise


## Accuracy: Schoenfield's EMS

```{r calculationsEMC,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}

plotDistroPlain <- function(distro, title, mult = 1.2) {
  plot <-  ggplot()+theme_tufte()+xlab("parameter values")+
    ylab("probability")+theme(plot.title.position = "plot")+ylim(0,1)+
    ggtitle(title)+
    geom_line(aes(x = ps,y = distro))+
    ylim(c(0,mult * max(distro)))
  return(plot)
}


kld <- function(p,q) kullback_leibler_distance(p,q, testNA = TRUE, unit = "log2",
                                               epsilon = 0.00001)

n <- 1000
ps <- seq(0,1,  length.out =n)
ch1 <- c(rep(0,n-1),1)
indicator1 <- as.numeric(ps >= 1)
ch0 <- c(1, rep(0,n-1))
indicator0 <- as.numeric(ps>=0)
a <- dnorm(ps, .3, .05)
b <- dnorm(ps, .5, .05)
c <- ifelse(ps <= .4, a, b) 

bimodal <- c / sum(c)
bimodalCum <- cumsum(bimodal)
distBi1 <- (bimodalCum - indicator1)^2
distBi0 <- (bimodalCum - indicator0)^2

centered <-   dnorm(ps, .4, .05)
centered <- centered/sum(centered)
centeredCum <- cumsum(centered)
distCe1 <- (centeredCum - indicator1)^2
distCe0 <- (centeredCum - indicator0)^2

aw <- dnorm(ps, .2, .05)
bw <- dnorm(ps, .6, .05)
cw <- ifelse(ps <= .4, aw, bw) 
bimodalWide <- cw / sum(cw)
bimodalWideCum <- cumsum(bimodalWide)
distBiW1 <- (bimodalWideCum - indicator1)^2
distBiW0 <- (bimodalWideCum - indicator0)^2

#now CVM distances from truth and falsehood
#Bi wins in particular distances
dc1 <- sum(distCe1)
db1 <- sum(distBi1)
dbw1 <- sum(distBiW1)
dc0 <- sum(distCe0)
db0 <- sum(distBi0)
dbw0 <- sum(distBiW0)

#now expected values
expBi <- sum(ps * bimodal)
expCe <- sum(ps * centered)
expBiW <- sum(ps * bimodalWide)

expCVMbi <- expBi * db1 + (1-expBi) * db0
expCVMbW <- expBiW * dbw1 + (1-expBiW) * dbw0
expCVMCe <- expCe * dc1 + (1-expCe) * dc0


# now with KLD to omniscient function
kldBi1 <- kld(ch1,bimodal)
kldBi0 <- kld(ch0,bimodal)

kldBiW1 <- kld(ch1,bimodalWide)
kldBiW0 <- kld(ch0,bimodalWide)

kldCe1 <- kld(ch1,centered)
kldCe0 <- kld(ch0,centered)


expKLDbi <- expBi * kldBi1 + (1-expBi) * kldBi0
expKLDbW <- expBiW * kldBiW1 + (1-expBiW) * kldBiW0
expKLDCe <- expCe * kldCe1 + (1-expCe) * kldCe0
```


```{r figEMC,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
ggarrange(plotDistroPlain(bimodal, "Bimodal, with modes at .3 and .5"),
plotDistroPlain(centered, "Centered around .4"),
plotDistroPlain(bimodalWide, "Wide bimodal, with modes at .2 and .6"), ncol = 1)
```



## Accuracy: Schoenfield's EMS

### CRPS and KLD inaccuracies

\footnotesize

\begin{tabular}{lrrrrrr}
\toprule
distribution & CRPS1 & CRPS0 & KLD1 & KLD0 & ExpCRPS & ExpKLD\\
\midrule
bimodal & 534.7 & 334.9 & 80.0 & 33.9 & 414.8 & 52.3\\
centered & 571.2 & 371.4 & 110.8 & 53.1 & 451.3 & 76.2\\
wide bimodal & 485.4 & 285.6 & 54.1 & 19.5 & 365.5 & 33.3\\
\bottomrule
\end{tabular}



\normalsize 

\pause

###  What went wrong?

Calculating two distances/divergencies from the two extreme omniscient measures and  averaging by plugging in the (same) expected value, does not result in a proper inaccuracy score


## Accuracy: steps forward

### Key idea

-  Look at $n$ potential true probability hypotheses, each of them pointed at a single bin in our approximation \pause

- Calculate all the inaccuracies with respect to their corresponding omniscient functions 
\pause

-  Calculate the expected inaccuracies scores using whole distributions rather than their expected values 


## Accuracy Inaccuracies vs real probabilities


```{r fig:inaccuracies2,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
point <- function (value) ifelse(abs(ps - value) == min(abs(ps - value)), 1, 0)
indicator <- function(pointf) ifelse( ps >= ps[min(which(pointf != 0))], 1,0  )

cvm <- function(w,p){
  cumw <-  cumsum(w)
  cump <- cumsum(p)
  dist <- (cump - cumw )^2
  return(sum(dist))
}

inaccuracyChancy <- function(distro){
crpss <- numeric(length(ps))
klds <- numeric(length(ps))
for(i in 1:length(ps)){
chance <- point(ps[i])
crpss[i] <- cvm(chance,distro)
klds[i] <- kld(chance,distro)
}
df <- data.frame(ps,distro,crpss,klds)
return(df)
}

InaBi <- inaccuracyChancy(bimodal)
InaCe <- inaccuracyChancy(centered)
InaBiW <- inaccuracyChancy(bimodalWide)


bcplot <- plotDistroPlain(InaBi$crpss, "Bimodal: CRPS")+ylab("inaccuracy")+
            xlab("true probability")

bkplot <- plotDistroPlain(InaBi$klds, "Bimodal: KLD")+
  ylab("inaccuracy")+xlab("true probability")


ccplot <- plotDistroPlain(InaCe$crpss, "Centered: CRPS")+ylab("inaccuracy")+
  xlab("true probability")

ckplot <- plotDistroPlain(InaCe$klds, "Centered: KLD")+ylab("inaccuracy")+
  xlab("true probability")

bwcplot <- plotDistroPlain(InaBiW$crpss, "Bimodal wide: CRPS")+ylab("inaccuracy")+
  xlab("true probability")

bwkplot <- plotDistroPlain(InaBiW$klds, "Bimodal wide: KLD")+ylab("inaccuracy")+
  xlab("true probability")

library(gridExtra)
grid.arrange(bcplot, bkplot, ccplot, ckplot, bwcplot, bwkplot)
```


## Accuracy: Back to Schoenfield's EMS


### Priopriety regained 

\centering
\scriptsize 
\begin{tabular}{lrrrrrr}
& \multicolumn{3}{c}{CPRS} & \multicolumn{3}{c}{KLD} \\
\toprule
  & bimodal & centered & wide bimodal & bimodal & centered & wide bimodal\\
\midrule
bimodal & 64.6 & 78.1 & 88.3 & 8.5 & 10.6 & 11.3\\
centered & 41.6 & 28.1 & 85.9 & 9.2 & 7.6 & 15.6\\
wide bimodal & 137.6 & 171.7 & 113.9 & 11.5 & 19.2 & 8.6\\
\bottomrule
\end{tabular}

\normalsize

\pause

### So why the bimodal?

\centering

\begin{tabular}{lrrrr}
 & \multicolumn{2}{c}{CRPS} & \multicolumn{2}{c}{KLD} \\
\toprule
&H3 & H5 & H3 & H5\\
\midrule
bimodal &55.475 & 55.378 & 7.935 & 7.935\\
centered &72.281 & 72.090 & 9.836 & 9.825\\
wide bimodal & 86.230 & 86.223 & 10.871 & 10.882\\
\bottomrule
\end{tabular}





# Pooling and synergy

## Pooling and synergy: circumventing Gallow's result




```{r fig:gallow,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
expectedValue <- function (distro){
  sum ( ps * distro)
}

n <- 1000
ps <- seq(0,1,  length.out =n)

you <-  dbeta(ps,1,1)
you <- you/sum(you)
evYou <- expectedValue(you)

al <- dbeta(ps,40,10)
al <- al/sum(al)
evAl <- expectedValue(al)

bert <- dbeta(ps,70,30)
bert <- bert/sum(bert)
evBert <- expectedValue(bert)

weights <- c(.05,.6,.35)
weightsA <- c(weights[1],weights[2])/(weights[1]+weights[2])
weightsB <- c(weights[1],weights[3])/(weights[1]+weights[3])

youAl <- weightsA[1] * you + weightsA[2]*al
#expectedValue(youAl)

youBert <- weightsB[1] * you + weightsB[2]*bert
#expectedValue(youBert)

youAlBert <- weights[1]* you + weights[2] * al + weights[3] * bert
#expectedValue(youAlBert)

ggplot()+theme_tufte()+xlab("parameter values")+
  ylab("probability")+theme(plot.title.position = "plot")+ 
  geom_line(aes(x = ps, y = al), color = "grey")+       #AL
  annotate(geom = "label", label = "Al, beta(40,10), exp. = .79", x = .85, y = .0075, fill = "white", size = 4)+
  geom_line(aes(x = ps, y = bert), lty = 2, color = "grey")+     #BERT
  annotate(geom = "label", label = "Bert, beta(70,30), exp. = .7", x = .75, y = .009, fill = "white", size = 4)+
  ggtitle("Experts' opinions and the results of your weighting with (.05,.6,.35)")+
 geom_line(aes(x = ps, y = youAl), lty =3, color = "skyblue")+       #youAL
  annotate(geom = "label", label = "You and Al, exp. = .79", x = .87, y = .006, color = "skyblue", fill = "white", size = 4) +
geom_line(aes(x = ps, y = youBert), color = "skyblue", lty = 4)+       #youBert
  annotate(geom = "label", label = "You and Bert, exp. = .69", x = .65, y = .006, color = "skyblue", fill = "white", size = 4)+
geom_line(aes(x = ps, y = youAlBert), color = "skyblue", lty = 5)+       #youBert
  annotate(geom = "label", label = "You, Al and Bert, exp. = .75", x = .81, y = .0045, color = "skyblue", fill = "white", size = 4)+
  xlim(.5,1)
```



## Pooling and synergy: pooling vs  expansion


```{r fig:Dre,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
n <- 1000
ps <- seq(0,1,  length.out =n)
d1 <- dbeta(ps,98,4)
d1 <- d1/sum(d1)
d2 <- dbeta(ps,97,5)
d2 <- d2/sum(d2)

#expectedValue(d1)
#expectedValue(d2)


weightsDoctors <- c(.7,.3)
pooled <- weightsDoctors[1] * d1 + weightsDoctors[2] * d2

#expectedValue(pooled)

doctorsBetas <- dbeta(ps,98+97, 4+5)
doctorsBetas <- doctorsBetas/sum(doctorsBetas)

#expectedValue(doctorsBetas)

ggplot()+theme_tufte()+xlab("parameter values")+ xlim(0.9,1)+
  ylab("probability")+theme(plot.title.position = "plot")+ 
  geom_line(aes(x = ps, y = d1), color = "grey")+
  geom_line(aes(x = ps, y = d2), lty = 2, color = "grey")+  
  geom_line(aes(x = ps, y = doctorsBetas), color = "skyblue", lty = 3)+ #POOLED
  annotate(geom = "label", label = "beta(194,8), exp.=.955, mode=.96", x = .957, y = .028, color = "skyblue", fill = "white", size = 4) +
  geom_line(aes(x = ps, y = pooled), color = "skyblue", lty = 4)+ #POOLED
  annotate(geom = "label", label = "pooled (.7,.3), exp.=.957, mode = .966, eff. n = 85", x = .982, y = .0205, color = "skyblue", fill = "white", size = 4)+
  ggtitle("Dr Alban and Dr Dre: credal states with the result of linear pooling and expansion")+
  annotate(geom = "label", label = "Dr Alban, beta(98,4), exp. = .96, mode = .97", x = .973, y = .0225, fill = "white", size = 4)+
  annotate(geom = "label", label = "Dr Dre, beta(97,5), exp.=.95, mode = .96", x = .94, y = .019, fill = "white", size = 4)
```



## Pooling and synergy: pooling vs expansion

\centering

\begin{tabular}{lrrrr}
\toprule
  & HDI low & HDI high & HDI width & weight\\
\midrule
Dr Alban & 0.933 & 0.989 & 0.056 & 0.378\\
Dr Dre & 0.916 & 0.98 & 0.064 & 0.360\\
pooled & 0.927 & 0.986 & 0.059 & 0.369\\
expanded & 0.933 & 0.977 & 0.044 & 0.414\\
\bottomrule
\end{tabular}



## Pooling and synergy: pooling vs  expansion





```{r fig:seuss,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
d3 <- dbeta(ps,36,66)
d3 <- d3/sum(d3)


weightsDoctors <- c(.7,.3)
pooled2 <- weightsDoctors[1] * d1 + weightsDoctors[2] * d3

doctorsBetas2 <- dbeta(ps,98+36, 4+66)
doctorsBetas2 <- doctorsBetas2/sum(doctorsBetas2)

ggplot()+theme_tufte()+xlab("parameter values")+
  ylab("probability")+theme(plot.title.position = "plot")+ 
  geom_line(aes(x = ps, y = d1), color = "grey") +
  geom_line(aes(x = ps, y = d3), lty = 2, color = "grey")+
  geom_line(aes(x = ps, y = pooled2), color = "skyblue", lty = 3)+ #POOLED+  
  geom_line(aes(x = ps, y = doctorsBetas2), color = "skyblue", lty = 4)+
  annotate(geom = "label", label = " expanded, beta(134,70), exp.=.656, mode=.659",
           x = .653, y = .0112, color = "skyblue", fill = "white", size = 4)+ #POOLED
  annotate(geom = "label", label = "pooled (.7,.3), exp.=.778, modes = (.35,.969)",
           x = .35, y = .0015, color = "skyblue", fill = "white", size = 4)+
  annotate(geom = "label", label = "Dr Alban, beta(98,4), exp. = .96, mode = .97", x = .87, y = .02, fill = "white", size = 4)+
  annotate(geom = "label", label = "Dr Seuss, beta(36,66), exp.=.352, mode = .35", x = .34, y = .007, fill = "white", size = 4)+
ggtitle("Dr Alban and Dr Seuss: credal states with the result of linear pooling and expansion")
```



## Accuracy: pooling vs expansion

```{r fig:inaccuraciesSimulation,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
ps <- seq(0,1,  length.out =1000)

populationSize <- 100
n <- 20
m <- 20

inaccuraciesList <- list()

for(i in 1:100){
averageIn <- numeric(101)
newDensIn <- numeric(101)
chanceHyps <- seq(0,1, by = 0.01)

for (c in 1:101){
realChance <- chanceHyps[c]
population <- rbinom(populationSize, 1, realChance)

sample1 <- sample(population, n, replace = FALSE)
sample2 <- sample(population, m, replace = FALSE)

dens1 <- dbeta(ps,sum(sample1)+1, (n-sum(sample1))+1)
dens1 <- dens1/sum(dens1)

dens2 <- dbeta(ps,sum(sample2)+1, m - sum(sample2)+1)
dens2 <- dens2/sum(dens2)

average <- .5 * dens1 + .5 * dens2

overlaps <-seq(0,n, by = 1)
overlapProbs <- dhyper(overlaps, m = n, n = populationSize - n, k = m)

newAlpha <- numeric(n)
newBeta <- numeric(n)
for(ol in 0:n){
newAlpha[ol+1] <- sum(sample2) - ol * mean(sample1)
newAlpha[ol+1] <- newAlpha[ol+1] + sum(sample1)+1
newBeta[ol+1] <- (m - sum(sample2)) - (ol - ol * mean(sample1))
newBeta[ol+1] <- newBeta[ol+1] + (n - sum(sample1))+1
}

expAlpha <- weighted.mean(newAlpha,overlapProbs)
expBeta <- weighted.mean(newBeta,overlapProbs)

newDens <-   dbeta(ps,expAlpha, expBeta)
newDens <- newDens/sum(newDens)

chance <- point(realChance)

averageIn[c] <- kld(chance,average)
newDensIn[c] <- kld(chance,newDens)
}


inaccuraciesList[[i]] <- data.frame(chanceHyps, averageIn, newDensIn)
}


inaccuraciesDF <- do.call("rbind", inaccuraciesList)
inaccuraciesDFlong <- melt(inaccuraciesDF, id.vars = "chanceHyps")
colnames(inaccuraciesDFlong) <- c("chance","method","inaccuracy")

ggplot(inaccuraciesDFlong, aes(x = chance, y = inaccuracy, color = method, group = method, lty = method))+
  theme_tufte()+ylim(4.5,15)+ggtitle("Inaccuracies of linear averaging and expansion")+
  scale_color_manual(name = "method", labels = c("averaging", "expansion"), values = c("dodgerblue4","yellow1"))+
  theme(plot.title.position = "plot",legend.position = c(0.9, 0.9))+
  geom_jitter(size = .1, alpha = .2)+
  geom_smooth(se = TRUE, size = 1)+
 guides(lty = FALSE)

```





# Wrapping up

## Wrapping up



### PP

\footnotesize 

- Not properly responsive to evidence

- No place for incomparability and insensitivity to sweetening

- No clear aggregation methods (Gallow)

- No notion of weight of evidence

\pause

### IP

\footnotesize 

- Still not properly responsive to evidence

- No clear general pr measure exclusion mechanism

- Still gets some comparisons wrong (Rinard)

- Belief inertia

- Still no weight of evidence

- No synergy in pooling

- No proper scoring rules

## Wrapping up




### HOP

\footnotesize 

- Evidence responsiveness regained

- More flexible comparisons

- Principled notions of weight and distance

- Inertia resolved

- Proper scoring

- More flexible aggregation methods

- Synergy explained





## References
\tiny

