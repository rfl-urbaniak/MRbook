---
title: "Forensic Literature on higher order LR"
author: ""
date: "August 2023"
output:
  pdf_document:
    number_sections: true
    df_print: kable 
    keep_tex: true
    includes:
      in_header:
        
classoption: dvipsnames,enabledeprecatedfontcommands
fontsize: 10pt
documentclass: scrartcl
urlcolor: blue
bibliography: [../../references/referencesMRbook.bib]
csl: [../../references/apa-6th-edition.csl]
indent: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose of this document


- Summarize existing forensic science literature on higher order LR

- Outline the structure of the paper/chapter on higher-order legal probabilism. 


# Relevant literature summaries



# Structure of paper/chapter

As I see it, the argument of the paper should be structured around three key points:

- **First**: The debate among forensic scientists and proposals on the table

- **Second**: The higher order approach as a novel proposal, how it works, etc. 

- **Third**: Why the higher order approach is better than existing approaches

This is standard structure for any scholarly paper. Below each 
point is developed more precisely. 

## Charitable reconstruction of the debate in the literature

- The paper should begin with a **charitable reconstruction** of the debate in the forensic 
science literature. (See, e.g., the 2016 special issue of *Science and Justice*, "Special issue on measuring and reporting the precision of forensic likelihood ratios", edited by G.S. Morrison. All the papers are in a special folder called 2016ScienceJustruce-SpecIssue-LR etc.)  The Lund slides try to do that, but -- in retrospect -- they do not do succeed. 

- Here is a charitable reconstruction: 

- (i) Everybody agrees that LRs (as averages, expectations) do not convey all the underlying uncertainty. There is uncertainty originating with the sample size (call it, *data uncertainty*) and there is uncertainty about the model assumptions (call it, *model uncertainty*). So clearly, LRs do not capture data uncertainty or model uncertainty. Call these additional forms of uncertainty *meta-uncertainty*. (An interesting philosophy paper that might be good to reference on meta-uncertainty is "Meta-uncertainty and the proof paradoxes" by
Katie Steele and Mark Colyvan, Philosophical Studies, in particular sections 4 and 5.)

- (ii) Everybody agrees that meta-uncertainty should be communicated by the experts to the fact-finders besides the first-order uncertainty captured by LRs. 

- (iii) The question is, how should this meta-uncertainty be conveyed? What is the best way to convey it? This is where the disagreement starts. 

- (iv) Many proposals are on the table:  describe data collection and model assumptions (Taroni/Bozza); place confidence intervals over LRs; model possible differences in terms of robustness (Biederman); etc.

- (v) The interval approach is criticized because LRs are not parameters to be estimated.

## The higher order approach

The next section of the paper should outline the higher approach as a novel answer to the question of how to model (at least part of) the meta-uncertainty that cannot be modeled by LRs alone. Some key points:

- The **mathematics** should be clear. Are higher order probabilities well-behaved probabilities? Is the mathematics all working properly? How do we show that? (The paper by Philip Dawid "Forensic likelihood ratio: Statistical problems and pitfalls" in the 2016 special issue might be a good starting point)

- How much of the meta-uncertainty is **captured** by distribution over probabilities and how much of the meta-uncertainty is still **left out** of the formal model?

- Parallels with the debate between precise/imprecise probabilism in philosophy. (Not sure if this is really necessary though.)

-  Good to show that everything that can be done with LRs (e.g. combine them) can be done using higher order LRs and higher order Bayesian networks. So the higher order approach combines reasoning about first-order uncertainty with reaosning about meta-uncertainty. 


## Comparing higher order approach to existing approaches 

In what way is the higher order approach different and better than other existing approaches for conveying meta-uncertainty to fact-finders?

- One key argument in favor of the higher-order approach concerns how different pieces of evidence (with different meta-uncertainties) can be combined. No one of the existing approaches has anything to say about how to combine different pieces and keep track of the meta-uncertainty. For example, it is not clear how the resilience approach or the interval approach could do that correctly (explain why).

- Respond to objections against the higher order approach, e.g. higher order probabilities do not exist or make no sense mathematically. 









