---
title: "“Weight of Evidence, Evidential Completeness and Accuracy”"
author: "Rafal Urbaniak and Marcello Di Bello"
output:
  pdf_document:
    number_sections: yes
    df_print: kable
    keep_tex: yes
    toc: no
    includes:
      in_header: Rafal_latex7.sty
  html_document:
    toc: yes
    df_print: paged
classoption: dvipsnames,enabledeprecatedfontcommands
fontsize: 10pt
documentclass: scrartcl
urlcolor: blue
bibliography: ../../references/referencesMRbook.bib
csl: [../../references/apa-6th-edition.csl]
indent: yes
---



  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dagitty)
library(rethinking)
library(ggplot2)
library(ggthemes)

```




# Motivations

## Balance vs. weight

Suppose we want to represent our uncertainty about a proposition in terms of a single probability that we assign to it. It is not too difficult to inspire the intuition that this representation does not capture an important dimension of how our uncertainty connects with the evidence we have or have not obtained.  In a 1872 manuscript of \emph{The Fixation of Belief} (W3 295) C. S. Peirce gives an example meant to do exactly that.  

\begin{quote} When we have drawn a thousand times, if about half have been white, we have great confidence in this result. We now feel pretty sure that, if we were to make a large number of bets upon the color of single beans drawn from the bag, we could approximately insure ourselves in the long run by betting each time upon the white, a confidence which would be entirely wanting if, instead of sampling the bag by 1000 drawings, we had done so by only two.
\end{quote}

\noindent The objection is not too complicated. Your best estimate of the probability of $W=$`the next bean will be white' is .5 if half of the beans you have drawn randomly so far have been white, no matter whether you have drawn a thousand or only two of them. But this means that expressing your uncertainty about $W$ by locutions such as "my confidence in $W$ is .5' does not capture this intuitively important distinction. 

Similar remarks can be found in Peirce's 1878 \emph{Probability of Induction}. There, he also proposes to represent uncertainty by at least two numbers, the first depending on the inferred probability, and the second measuring the amount of knowledge obtained; as the latter, Peirce proposed to use some dispersion-related measure of error (but then suggested that an error of that estimate should also be estimated and so, so that ideally more numbers representing errors would be needed). 

Peirce himself did not call this the weight of evidence (and in fact, used the phrase rather to refer to the balance of evidence, W3 294) [CITE KASSER 2015]. However, his criticism of such an oversimplified representation of uncertainty anticipated what came to be called weight of evidence by Keynes in his 1921 \emph{A Treatise on Probability}:

\begin{quote}
As the relevant evidence at our disposal increases, the magnitude of the
probability of the argument may either increase or decrease, according as the new knowledge strengthens the unfavourable or the favourable evidence; but something seems to have increased in either case,—we have a more substantial basis upon which to rest our conclusion. I express this by saying that an accession of new evidence increases the weight of an argument. New evidence will sometimes decrease the probability of an argument but it will always increase its `weight.' (p. 71)
\end{quote}

\noindent The key point is the same [CITE LEVI 2001]: the balance of probability alone cannot characterize all important aspects of evidential appraisal. Keynes also considered measuring weight of evidence in terms of the variance of the posterior distribution of a certain parameter, but was quite attached to the idea that weight should increase with new information, even if the dispersion increase with new evidence [TP 80-82], and so he proposed only a very rough sketch of  a positive sketch. Moreover, as he was uncertain how a measure of weight should be incorporated in further decision-making, the was skeptical about the practical significance of the notion.  [TP 83]

But what is this positive sketch? On one hand, Keynes [TP 58-59] connects the notion of weight with relevance. Call evidence $E$ relevant to $X$ given $K$ just in case $\mathsf{Pr}(X\vert K \wedge E) \neq \mathsf{Pr}(X \vert K)$.^[ Keynes also uses a slightly more convoluted notion of relevance to avoid equally strong items of opposite evidence turning out to be irrelevant (this objection has also been brought up by [COHEN 1986 TWELVE]). The more complex version is that  a proposition $E_1$ is relevant to $X$ given $K$   just in case it entails a proposition $E_2$ such that $\pr{X\vert K \wedge E_2} \neq \mathsf{Pr}(X \vert K)$. [COHEN 1986 TWELVE] complaints that this still runs into difficulties. Ignore $K$, take an irrelevant proposition $Z$. It entails $Z\vee X$ and $\pr{Z \vee X\vert X \wedge E}=1$. Now, by Bayes' theorem we have $\pr{X \vert E \wedge (Z \vee X)} = \frac{\pr{X \vert E}\times \pr{Z \vee X \vert X \wedge E}}{\pr{Z \vee X \vert E}} = \frac{\pr{X \vert E}}{\pr{Z \vee X \vert E}}$. If the denominator differs from 1, the result differs from the numerator. We will ignore such difficulties, as they are not of key importance for the development of this chapter.] One postulate than can be found in the \emph{Treatise} [TP 84] is:^[RUNDE 1990 283 suggests Keynes allows for weight of evidence to decrease when new evidence increases the range of alternatives, but this is based on Keynes' claim that weight is increased when the number of alternatives is reduced, and Keynes does not directly say anything about the possibility of an increase of the number of alternatives.]

\begin{tabular}{lp{11cm}}
(Monotonicity) & If $E$ is relevant to $X$ given $K$, where $K$ is background knowledge, $V(X\vert K \wedge E) > V(X\vert K)$, where $V$ is the weight of evidence.
\end{tabular}




[RUNDE 1990, 280] suggests that Keynes at some point calls weight the completeness of information. This however, is a bit hasty, as Keynes only says that \emph{the degree of completeness of the information on which a probability is based does seem to be relevant, as well as the actual magnitude of the probabiltiy, in making practical decisions}. As later on we will argue that it is actually useful to distinguish evidential weight (how much evidence do we have?) and evidential completeness (do we have all the evidence that we would expect in a given case?), we rather prefer to extract a more modest postulate:

\begin{tabular}{lp{11cm}}
(Completeness) & If $E_1$ and $E_2$ are relevant items of evidence, and $E_2$ is (in a sense to be discussed) more complete than $E_1$,  $V(X\vert K \wedge E_2) > V(X\vert K \wedge E_1)$.
\end{tabular}

\noindent If we conceptualize $E_2$ being complete and $E_1$ being incomplete as $E_2$ being a maximal relevant conjunction of relevant claims one of which is $E_1$, (Completeness) follows from (Monotonicity).


Similar requirements seem to be inspired by the urn example. We put them in two forms, a weaker and a stronger one. 


\begin{tabular}{lp{11cm}}
(Weak increase) & In cases analogous to the urn example, the weight obtained by a larger sample is higher, if the frequencies in the samples remain the same.\\
(Strong increase) & In cases analogous to the urn example, the weight obtained by a larger sample is higher.
\end{tabular}


Now, some requirements on how weight of evidence is related to the balance of probability. For one thing, Keynes insists that new (relevant) evidence might decrease probability but will always increase weight [TP 77]. Since (Monotonicity) already captures the idea that weight will always increase, here we extract the other part of the claim:

\begin{tabular}{lp{11cm}}
(Possible decrease) & It is possible that   $V(X\vert K \wedge E) > V(X\vert K)$ while $\pr{X \vert K \wedge E} <  \pr {X\vert K}$.
\end{tabular}

Clearly, Keynes also endorsed the following two requirements of a very similar form:

\begin{tabular}{lp{11cm}}
(Possible increase) & It is possible that   $V(X\vert K \wedge E) > V(X\vert K)$ while $\pr{X \vert K \wedge E} >  \pr {X\vert K}$. \\
(Possibly no change ) & It is possible that   $V(X\vert K \wedge E) > V(X\vert K)$ while $\pr{X \vert K \wedge E} =  \pr {X\vert K}$.
\end{tabular}







Interestingly, Keynes for quite a few years did not attempt to provide anything close to a formal explication of the notion, and did not spend too much time studying the issue. Various reasons for this has been proposed the literature, a prominent one   [CITE FEDUZI 2010] being that from the decision-theoretic perspective no clear stopping rule emerged as to whether the evidence is weighty enough to make a decision. \todo{Should I talk about other theories here, or should we leave it as is without getting into interpretative details.} Later on we will see a sort of revival---some ideas later developed by Keynes has been used to explicate the notion of weight formally, and we will take a closer look at this proposal. \todo{REF section}



<!-- Runde (1990), Keynes provides three deﬁnitions of evidential weight in the TP, -->

<!-- is not referring to the sheer number of statements on the right hand side of a conditional probability P (H | E) or the sheer bulk of information that these statements -->
<!-- contain. By “relevant evidence”, Keynes is only referring to the extent that E pro- -->
<!-- vides information that is pertinent to H in particular. [Pedden3] -->



## Examples and informal desiderata  

- Go over Nance in particular,  some other sources?


- first check for completeness, then evaluate

- what do you mean: are there items of relevant evidence that you could reasonably obtain
- destroyed?

### Monotonicity of weight

Runde, Joyce, Weatherson, Peden

## Hamer's weight of evidence


## Good's weigh of evidence and the information value

One notion in the vicinity also called \emph{weight of evidence} has been introduced by Good [CITE PROBABILITY AND THE
WEIGHING OF EVIDENCE 1950]. Let $W(H:E)$ be the Good's weigh of evidence in favor of $H$ provided by $E$ (if we want to explicitly conditionalize on some background knowledge $K$, we write $W(H:E\vert K)$).  One assumption about $W$ taken by Good is as follows:\todo{pays attention to different values of different items of evidence, which is better than just counting or supersets}

\begin{tabular}{lp{11cm}}
(Function) & ``It is natural to assume that $W(H:E)$ is some function of $\pr{E\vert H}$ and of $\pr{E\vert \neg H}$, say $f[\pr{E\vert H}, \pr{E \vert \neg H}]$. I cannot see how anything can be relevant to the weight of evidence other than the probability of the evidence given guilt and the probability given innocence.'' [cite Good 1985 p 250]
\end{tabular}

The other two are:

\begin{tabular}{lp{11cm}}
(Independence) & $\pr{H\vert E} $ should depend only on the weight of evidence and on the prior: $\pr{H \vert E} = g[W(H:e), \pr{H}]$.\\
(Additivity)  & $W(H: E_1 \wedge E_2)  = W(H:E_1) + W(H:E_2 \vert E_1)$
\end{tabular}
\noindent The three conditions can be simultaneously satisfied by only one function (up to a constant factor), which leads to Good's definition of weight of evidence:^[To be fair, logarithms of the ratio of posterior odds to prior odds have been used Jeffrey in 1936, [CITE] and  the use of logarithm to ensure additivity has been suggested by Turing [CITE 1950 o 63]. Good's measure differs from Jeffrey's by taking the ratio of likelihoods rather than odds. In fact, the former ratio is identical to $\nicefrac{O(H\vert E)}{O(H)}$, the ratio of conditional odds of $H$ to the prior odds of $H$.]
\begin{align*}
W(H:E) & = \log \frac{\pr{E \vert H}}{\pr{E\vert \neg H}}
\end{align*}

The natural question that arises is the extent to which Good's weight satisfies the desiderata related to Keynes' notion of weight. First, let us think about weight increase with sample size. If in an experiment the observations $E_1, \dots, E_K$ are independent given $H$ and independent given $\neg H$, the resulting joint likelihood is  the result of the multiplication of the individual likelihoods, and so the resulting joint weight is the result of adding the individual weights. 

For example, suppose a die is selected at random from a hat containing nine fair dice and one loaded die with the chance $\nicefrac{1}{3}$ of obtaining a six. The initial uniform distribution gives you weight of evidence for the die being loaded of $log_{10}(.1)$, that is `r log10(.1)` (Good and Turing would say, it is -10 db). Now, every time you toss it and obtain a six, you gain $log_{10}(\frac{\nicefrac{1}{3}}{\nicefrac{1}{6}})= log_{10}(2)$, that is `r log10(2)`, and every time you toss it and obtain something else, the weight changes by $log_{10}(\frac{\nicefrac{2}{3}}{\nicefrac{5}{6}})= log_{10}(.8)$, that is `r log10(.8)`. Let us inspect the weights in db (that is, multiplied by 10) for all possible outcomes of up to 20 tosses (Figure \ref{fig:goodWeight}).



\begin{figure}
```{r goodWEights,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
six <- seq(0,10, by = 1)
others <- seq(0, 10, by  = 1)
options <- expand.grid(six = six, others = others)
options$weight  <- round(10 *( log10(.1) + options$six * log10(2) +
                                 options$others * log10(.8)),1)

ggplot(options, aes(x = six, y = others, fill = weight)) +
  geom_tile(color = "white", lwd = .1,
            linetype = 1)+
  geom_text(aes(label = round(weight,2)), color = "white", size = 3)+
  scale_fill_gradient(low = "black", high = "orangered")+
  theme_tufte()+
  ggtitle("Good's weights for up to 20 die tosses (db)")+
  scale_x_continuous(breaks = seq(0,10, by = 1))+
  scale_y_continuous(breaks = seq(0,10, by = 1))
```
\caption{Good's weights in dbs, rounded, for all possible outcomes of up to 20 tosses of a die randomly selected from 10 dice nine of which were fair, and one is \nicefrac{1}{3} loaded towards six. $H=$`the die is loaded'.}
\label{fig:goodWeight}
\end{figure}

Two facts are notable. (1) Weight can drop with sample size: for instance the weight for 4 others and 5 sixes is 1.2db, and it is .2db for 5 others and 5 sixes. (2) Weight can drop while the sample size increases even if the proportion of sixes remains the same. For instance, if none of the observations are sixes, the weights go from -10 to -19.7 as the sample size goes from 0 to 10. Less trivially, the observation of one six in five leads to weight of -10.9, while the observation of two sixes in ten tosses leads to weight -11.7. That is, (Monotonicity), (Completeness), (Weak increase) and (Strong increase) all fail for Good's measure.



Moreover, there is a conceptual difficulty in the neighborhood. Suppose you are trying to ascertain the bias 
$\theta$ of a coin, but you do not restrict yourself to two hypotheses as in the dice example, but rather initially take any bias to be equally likely. For each particular hypothesis 
$\theta = x$ and any set of observations $E$ you can use the binomial distribution to calculate 
$\pr{E \vert \theta = x}$. But to deploy Good's definition, you also need 
$\pr{E \vert \theta \neq x}$, which is less trivial, as now you have to integrate to calculate the expected probability of the evidence given an infinite array of possible values of $y$. Suppose you have no problem calculating such items. Now imagine you observe 10 heads in 20 tosses. The question `how weighty is the evidence' makes no sense here, as Good's weight needs a hypothesis (and its negation) to be plugged in. For this reason, in such a situation, we can at best talk about a continuum of Good's weights, one for each particular value of 
$\theta$. 




- compare to pointwise mutual information

- evaluate in light of the desiderata

<!-- https://stats.stackexchange.com/questions/16945/why-do-people-use-the-term-weight-of-evidence-and-how-does-it-differ-from-poi -->

<!-- w(e:h)=logp(e|h)p(e|h¯¯¯) -->
<!-- where e is evidence, h is hypothesis. -->

<!-- Now, I want to know what is the main difference with PMI (pointwise mutual information) -->

<!-- pmi(e,h)=logp(e,h)p(e)∗p(h) -->

<!-- h is something different in PMI and in WOE -->
<!-- Notice the term p(h) in PMI. This implies that h is a random variable of which you can compute the probability. For a Bayesian, that's no problem, but if you do not believe that hypotheses can have a probability a priori you cannot even write PMI for hypothesis and evidence. In WOE, h is a parameter of the distribution and the expressions are always defined. -->

<!-- PMI is symmetric, WOE is not -->
<!-- Trivially, pmi(e,h)=pmi(h,e). However, w(h:e)=logp(h|e)/p(h|e¯) need not be defined because of the term e¯. Even when it is, it is in general not equal to w(e:h). -->

<!-- Other than that, WOE and PMI have similarities. -->

<!-- The weight of evidence says how much the evidence speaks in favor of a hypothesis. If it is 0, it means that it neither speaks for nor against. The higher it is, the more it validates hypothesis h, and the lower it is, the more it validates h¯. -->

<!-- Mutual information quantifies how the occurrence of an event (e or h) says something about the occurrence of the other event. If it is 0, the events are independent and the occurrence of one says nothing about the other. The higher it is the more often they co-occur, and the lower it is the more they are mutually exclusive. -->

<!-- What about the cases where the hypothesis h is also a random variable and both options are valid? For example in communiction over a binary noisy channel, the hypothesis is h the emitted signal to decode and the evidence is the received signal. Say that the probability of flipping is 1/1000, so if you receive a 1, the WOE for 1 is log0.999/0.001=6.90. The PMI, on the other hand, depends on the proability of emitting a 1. You can verify that when the probability of emitting a 1 tends to 0, the PMI tends to 6.90, while it tends to 0 when the probability of emitting a 1 tends to 1. -->

<!-- This paradoxical behavior illustrates two things: -->

<!-- None of them is suitable to make a guess about the emission. If the probability of emitting a 1 drops below 1/1000, the most likely emission is 0 even when receiving a 1. However, for small probabilities of emitting a 1 both WOE and PMI are close to 6.90. -->

<!-- PMI is a gain of (Shannon's) information over the realization of the hypothesis, if the hypothesis is almost sure, then no information is gained. WOE is an update of our prior odds, which does not depend on the value of those odds. -->

## Weight and completeness

<!-- Completeness, inclusion entails weight comparison, very limited applicability -->

A question similar to "how weighty is the evidence" is "how complete is it"? These are conceptually different: the former asks about how much information 
pertinent to a given hypotheses the evidence provides, or, about the amount of evidence relevant to that hypothesis, the latter seems to 
suggest a checklist approach  on which the presence of various items of evidence 
is compared to some ideal list of what such items would be needed for the
evidence to be complete. While we think that these notions, albeit related, should be clearly distinguished, the distinction has not always been made clearly in the 
literature, and some authors pursued the consequences of thinking about weight in terms 
of completeness  [CITE FEDUZI 2010].\todo{CITE NANCE HERE?} In this section we will present the view and argue that the subjectivity of weight of evidence evaluation it leads to might be too 

One advantage of the completeness approach is that the resolution of the stopping problem is more or less automatic: the agent should make the decision if the evidence 
is complete, and should collect more evidence if it is not.^[Later on, when discussing Nance's approach to the notion, we will see a complication: obtaining further evidence might be practically unfeasible, and so it makes sense to distinguish ideal completeness from reasonable completeness and base the practical stopping rule on the former. For now, we put this complication aside.]



Following [CITE FEDUZI 343], let us use $\Omega$ as the set of all items of possible evidence relevant for estimating the probability of the hypothesis $H$. Let $K$ be the agent's knowledge, the set of items of evidence already obtained by the agent, $K \subseteq \Omega$. Then her relevant ignorance is $I = \Omega \setminus K$. 
Then, Feduzi, following [CITE RUNDE 1990], proposes to define the weight of information $E$ provides about $H$, $V(H/E)$ as follows:
\begin{align} \tag{Vdiv}  V(H/E) & = \frac{K}{K+I}.\end{align}
\noindent While literally it does not make sense to divide sets by sets, we might charitably interpreting Feduzi as using  $\Omega, K$ and $I$ the symbols ambiguously, standing for both the sets of items of evidence, and the amount of relevant information that the sets contain. The obvious difficulty is that it is not a successful explication (at least not yet), as we are not told how to get $K$ and $K+I$ as numerical values to be used in the division. But however we get them, let us see whether (Vdiv) can result in any insights when it comes to the stopping problem.


Here is an example due to Feduzi [CITE 345] Joan in her research tries to establis who is the most quoted author in the literature on decision theory under ambiguity. $\Omega$ is the set of all $n$ papers (though of as items of evidence $E_1, \dots, E_n$). $K_0$ contains the $m$ papers that Joan inspected so far ($E_1, \dots, E_m$, $m<n$. $I_0$ is the set of papers she did not look at yet, $\Omega = K_0 \cup I_0$. However, Joan is aware only of a part of $\Omega$, the papers in the field she believes exist, $S$. Thus, her objective ignorance, $I_0$, and her subjective ignorance, $I_S = S- K$, diverge, as she underestimates the amount of papers that she has not yet encountered. Joan's assessment of weight is going to be $\nicefrac{K}{K+I_s}$. 

Say Joan formulates a hypothesis, $H$: "Ellsberg is the most highly cited author in the ambiguity literature" and that she is quite confident that the papers she had not looked at yet would not significantly affect the probability of $H$. She thinks she has read enough, say $\pr{H \vert K} = .7$ and $V(H/K) = .8$. Then, she looks at another paper, somewhat increasing $K$, but that paper contains reference to many papers she has not heard of in journals that she has not heard of, thus increasing her estimation of $S$ quite a lot--- the ultimate impact of the new evidence is a drop in weight as the denominator in (Vdiv) will grow much more than the numerator. 







<!-- %One problem: highly subjective, Feduzi 2010, 339: -->
<!-- %"related to her personal assessment of the degree of completeness of the information upon %which that probability is based, the following might occur: ﬁrst, the decision maker’s %degree of conﬁdence in her forecast may undergo drastic changes during the process of %acquiring information;2 second, changes in the decision maker’s awareness of -->
<!-- %the dimension of her ignorance may produce either overconﬁdence or underconﬁdence in her %probability judgements and the forecasts made on their basis; third, different people, on %the basis of the same evidence, might hold different degrees of -->
<!-- %conﬁdence in their forecasts; and ﬁnally, different people, confronting the same decision %problem" -->



<!-- another potential difficulty: you should be able to consider the following possible four situations: FEDUZA 344 -->
<!-- 1. The decision maker knows all the available evidence relevant to some conclusion and knows that she knows all of it. -->
<!-- 2. The decision maker does not know some of the evidence relevant to some conclusion and knows that this is the case. -->
<!-- 3. The decision maker does not know some part of the evidence relevant to some conclusion, does not know that she does -->
<!-- not know this part of the evidence, but knows that there may be some part of the evidence that she does not know. -->
<!-- 4. The decision maker does not know a part of the evidence relevant to some conclusion, does not know that she does not -->
<!-- know this part of the evidence, and does not know that she might not know some relevant evidence. -->


## Skyrms and resilience?


- 
- relation to law Davidson Pargetter 1986, perhaps Nance, who else?




## Imprecision and  weight with intervals

Keynes' later works and Peden's paper

### Sharpening by richness

### Sharpening by specificity

### Sharpening by precision


## Imprecision: a second-order approach



## Information-theoretic weight of evidence

## Completeness tends to improve weight

## Weight tends to improve accuracy


Here is a question asked by [COHEN 1986 TWELVE p. 276]: is it worth while knowing the weight of an argument without knowing its probability? In our terminology, questions inspired by Cohen's are: what's the point of weight considerations if we already have the distributions? Can weights be put to use if we do not have the distributions?










# Literature to discuss


Kasser, 2016, Two Conceptions of Weight of Evidence in Peirce’s Illustrations of the Logic of Science [DOWNLOADED, COVERED]

Feduzi, 2010, On Keynes’s conception of the weight of evidence [READ]

Cohen 1986, Twelve Questions about Keynes's Concept of Weight [READ]

Pedden, William 2018, Imprecise probability and the measurement of Keynes' weight of arguments

Levi 2011, the weight of argument [DOWNLOADED]

Skyrms 1977 resiliency, propensities [DOWNLOADED]

Skyrms causal necessity, chapter on resilience [DOWNLOAD]

Synthese 186 (2) 2012, volume on Keynesian weight [CHECKED, NOT MUCH ON WEIGHT ACTUALLY, NO NEED TO READ]


Good, weight of evidence, survey

Good, PROBABILITY AND THE
WEIGHING OF EVIDENCE


David Hamer, Probability, anti-resilience, and the weight of expectation [READ]


William Peden, Imprecise Probability and the Measurement of Keynes's "Weight of Arguments"


Runde, Keynesian Uncertainty and the weight of arguments [DOWNLOADED]

Weatherson, 2002, Keynes, uncertainty and interest rates  [DOWNLOADED]

Jeffrey M. Keisler, Value of information analysis: the state of application

Edward C. F. Wilson, A Practical Guide to Value of Information Analysis

Joyce JM (2005) How probabilities reflect evidence.


