---
title: "Marcello's Comments on the Chapter about Weight"
author: ""
date: "9/1/2022"
output:
  pdf_document:
    number_sections: true
    df_print: kable 
    keep_tex: true
    includes:
      in_header:
        - Rafal_latex7.sty
classoption: dvipsnames,enabledeprecatedfontcommands
fontsize: 10pt
documentclass: scrartcl
urlcolor: blue
bibliography: [../../references/referencesMRbook.bib]
csl: [../../references/apa-6th-edition.csl]
indent: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose of this document

Marcello's comments on the chapter about weight.

# Sec 5 (weight and completeness)

Rafal writes:

\begin{quote}
So the second difficulty is that on this approach the weight of evidence becomes very sensitive not only to what the actual evidence is, but also to what an ideal evidence in a given case should be. unless as clear and epistemologically principled guidance as to how to formulate such ideal lists is available, this seems to open a gate to arbitrariness. Change of awareness of one’s own ignorance, without any major chance to the actual evidence obtained, might lead to overconfidence or under-confidence in one’s judgment. Moreover, it is not clear how disagreement about weight arising between agents not due to evidential differences, but rather due to differences in their list of ideal items of evidence should be adjudicated.
\end{quote}

I am not sure. What makes a body of evidence complete is subjective, since it depends on what one knows about a given situation. But this fact cannot be used as a criticism for a theory of weight based on completeness. If I did not know the defendant had a huge archive of documents in his office, I might think that all the evidence I have (without the documents in the archive) is complete. But when I learn about the existence of that archive and realize that the evidence lacks the documents in the archive, then my evidence is clearly incomplete. This does not makes the assessment of weight-as-completeness subjective. This is just how things should be. 

Perhaps there are different levels of analysis here:

- assess completeness of evidence based on an ideal list  that would apply universally to any case like the one under consideration (script approach)

- assess completeness based on a specific recounting of what happened that is agreed by both parties (shared narrative approach).

- assess completeness based on a specific recounting of what happened pout forward by one of the parties (partisan narrative approach).

Arbitrariness might exist in the script approach (we might disagree about the right script to apply to determine the ideal list of items of evidence), but does not exist in the narrative approach.


# Sec 8 and 9 (imprecise probabilities)

These two sections are very interesting, but we need to think about they can fit in the chapter as such. Most of the examples (and counterexamples) in these sections are about coin tossing and sample size. I think we might need to consider examples of quantitative evidence in the law, DNA evidence, multiple reference populations or different sample sizes.  To warrant a discussion of imprecise probabilities here, we need to to show that imprecise probability measures (and also Joyce's notion of weight) have a prima facie applicability to the law and then we can show that they are inadequate for various reasons. 

The bit about proper scoring rules and teh Brier score is particularly interesting. This can perhaps belong to
the section on accuracy. But it does seem a requirement of any weight measure, juyst like any probability measures, that we can connect it up to accuracy in some way. 




# Sec 10 (highere order approach)

The general idea here is clear, but I wonder if a simple example or two for legal application is helpful. 
Perhps an example with DNA evidence and sample size or something to that effect.

# Section 11 (information theorethic weight)


\begin{itemize}

\item This is the crucial section. This is the map I have now in my mind to 
follow what is going on in this section: 


\begin{enumerate}
\item[i.] Notion of information/entropy in general
\item[ii.] Entropy of distributions
\item[iii.] Difference of entropy between distributions
\item[iv.] weight of a distribution D is the difference between the entropy of the distribution D compared to the uniform distribution (which by default has maximal entropy)
\end{enumerate}

\item In particular, the move from the example with the three forks to
a distribution of parameter values (each associated with a different probability) 
is not completely clear. I can sort of see the connection, 
but it is not spelled out clearly. This is the part that says "A measure of (lack of) information contained in a whole distribution, is entropy, which is the average Shannon information:..."

\item Again, in the discussion of entropy it would be 
good to have a clear running example, possibly 
legal in nature. 

\item using the grip approximation for continuous distributions is fine, 
but what is the reason? You seem to say it is because we will compare continuous 
and discrete distribution. That seems sensible. Can you give an example?

\item KL divergence. This is the difference between the entropy associated between the two distribution and because of the properties of logarithm it is the log of the ratio. 


\end{itemize}











