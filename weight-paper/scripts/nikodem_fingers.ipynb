{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Fingers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyro \n",
    "\n",
    "from typing import Dict, List\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import beta\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sample(sample: torch.Tensor, k: int = 1000) -> torch.Tensor:\n",
    "    ''' \n",
    "    `sample` is supposed to be a sample of values, returns probabilites across k bins.\n",
    "    '''\n",
    "\n",
    "    hist = torch.histc(sample, bins=k)\n",
    "    return hist / hist.sum()\n",
    "\n",
    "\n",
    "\n",
    "def weight(posterior: torch.Tensor, base=2.) -> float:\n",
    "    '''\n",
    "    Calculates the weight of the posterior distribution.\n",
    "    The weight is defined as 1 - H(posterior) / H(uniform)\n",
    "    where H is the entropy of the distribution.\n",
    "        param: posterior: torch.Tensor - tensor of probabilities (not samples). \n",
    "    '''\n",
    "    \n",
    "    if not isinstance(base, torch.Tensor):  # Check if base is not a tensor\n",
    "        base = torch.tensor(base) \n",
    "\n",
    "    initial_length = posterior.shape[-1]\n",
    "    posterior = posterior[~torch.isnan(posterior)]\n",
    "    removed_length = initial_length - posterior.shape[-1]\n",
    "\n",
    "    if initial_length != posterior.shape[-1]:#raise warning\n",
    "        warnings.warn(f\"Removed {removed_length} nan values from posterior\")\n",
    "\n",
    "    if posterior.numel() == 0:\n",
    "        return float('nan')\n",
    "\n",
    "    grid_length = posterior.shape[-1]\n",
    "    x = torch.linspace(0, 1, grid_length)\n",
    "\n",
    "    uniform = dist.Beta(1, 1).log_prob(x).exp()\n",
    "    uniform = uniform/uniform.sum()\n",
    "\n",
    "    #uniform = normalize_sample(uniform, k = uniform.shape[-1])\n",
    "\n",
    "    assert torch.allclose(uniform.sum(), torch.tensor(1.)), f\"Sum of uniform distribution is {uniform.sum()}\"\n",
    "    assert torch.allclose(posterior.sum(), torch.tensor(1.)), f\"Sum of posterior distribution is {posterior.sum()}\"\n",
    "\n",
    "    entropy_uniform = -torch.sum(uniform * torch.log(uniform) /torch.log(base))\n",
    "\n",
    "    entropy_posterior = -torch.sum(posterior * torch.log(posterior) / torch.log(base))\n",
    "\n",
    "    return 1 - entropy_posterior.item() / entropy_uniform.item()\n",
    "\n",
    "def expected_weight(probs_of_evidence: torch.Tensor, outcome_prior: torch.Tensor,\n",
    "                    posteriors: List[torch.Tensor],  base=2) -> torch.Tensor:    \n",
    "    \"\"\"\n",
    "    Calculate the expected weight change given a prior distribution, \n",
    "    posterior distributions, and the probabilities of evidence.\n",
    "\n",
    "    Args:\n",
    "    probs_of_evidence (torch.Tensor): A tensor of probabilities representing the likelihood of the evidence.\n",
    "    outcome_prior (torch.Tensor): A tensor representing the prior distribution of outcomes.\n",
    "    posteriors (List[torch.Tensor]): A list of tensors representing the posterior distributions.\n",
    "    base (int): The base for calculating the weight (default is 2).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    weight_prior = weight(outcome_prior, base=base) \n",
    "\n",
    "    posterior_weights = torch.tensor([weight(posterior, base=base) for posterior in posteriors])\n",
    "\n",
    "    print(posterior_weights)\n",
    "    weight_changes = posterior_weights - weight_prior\n",
    "\n",
    "    weighted_weight_changes = weight_changes * probs_of_evidence \n",
    "    \n",
    "    assert probs_of_evidence.shape == weighted_weight_changes.shape, 'shape mismatch'\n",
    "\n",
    "    expected_weight = weighted_weight_changes.sum()\n",
    "\n",
    "    return {\"expected_weight\": expected_weight, \"weight_prior\": weight_prior, \n",
    "            \"posterior_weights\": posterior_weights, \n",
    "            \"weight_changes\": weight_changes, \n",
    "            \"weighted_weight_changes\": weighted_weight_changes}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Core model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guilty': tensor([0., 0., 0.,  ..., 1., 0., 0.]),\n",
       " 'isis': tensor([0., 0., 0.,  ..., 1., 0., 0.]),\n",
       " 'fingers_match_rmp': tensor([0., 0., 0.,  ..., 1., 0., 0.]),\n",
       " 'fingers_match_isis': tensor([0., 0., 0.,  ..., 1., 0., 0.]),\n",
       " 'posterior_guilty_fingers_rmp': tensor(0.9871),\n",
       " 'posterior_guilty_fingers_isis': tensor(1.)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.set_rng_seed(42)\n",
    "\n",
    "def swedish_fingers_guilt_model(\n",
    "        pr_identity: float = 0.01,               # Prior probability that the suspect is guilty\n",
    "        rmp_fingers_sweden = 2 / 20000,          # RMP for Sweden\n",
    "        pr_isis_if_not_guilty = 300 /10.6e6,                               \n",
    "        pr_fingers_match_if_isis = 2 / 5000,     # RMP for ISIS memebers\n",
    "        num_particles = 3e5                     \n",
    "    ):\n",
    "    \n",
    "    with pyro.plate(\"particles\", size=num_particles):\n",
    "   \n",
    "        guilty = pyro.sample(\"guilty\", dist.Bernoulli(pr_identity))\n",
    "\n",
    "        isis = pyro.sample(\"isis\", dist.Bernoulli(\n",
    "                                        guilty * 1 + (1 - guilty) * pr_isis_if_not_guilty\n",
    "                                        )\n",
    "                            )\n",
    "\n",
    "\n",
    "        fingers_match_rmp = pyro.sample(\"fingers_match_not_isis\", \n",
    "                                             # if guilty then 1\n",
    "                                             # if not guilty then sample with probability rmp\n",
    "                                                dist.Bernoulli(guilty * 1 + (1 - guilty) * (rmp_fingers_sweden)\n",
    "                                                               )\n",
    "                                            )\n",
    "        \n",
    "\n",
    "        fingers_match_isis = pyro.sample(\"fingers_match_isis\", \n",
    "                                         # if guilty then 1\n",
    "                                         # if not guilty then sample with probability pr_fingers_match_if_isis\n",
    "                                            dist.Bernoulli(guilty * 1 + (1 - guilty) * ((pr_fingers_match_if_isis) * isis +\n",
    "                                                              (1 - isis) * (rmp_fingers_sweden)\n",
    "                                                                    )\n",
    "                                                                )\n",
    "                                                            ) \n",
    "        \n",
    "\n",
    "\n",
    "    # Mask 1: fingers match\n",
    "    evidence_mask_fingers_rmp = (fingers_match_rmp).bool()\n",
    "    guilty_masked_fingers_rmp = pyro.deterministic(\n",
    "        \"guilty_masked_fingers_rmp\",\n",
    "        torch.where(evidence_mask_fingers_rmp, guilty, torch.tensor(float(\"nan\")))            \n",
    "        )\n",
    "\n",
    "    \n",
    "    posterior_guilty_fingers_rmp = pyro.deterministic(\n",
    "        \"posterior_guilty_fingers_rmp\", torch.nanmean(guilty_masked_fingers_rmp, axis=0))\n",
    "    \n",
    "\n",
    "    # Mask 2: fingers match, isis\n",
    "    evidence_mask_fingers_isis = (fingers_match_isis * isis).bool()\n",
    "    guilty_masked_fingers_isis = pyro.deterministic(\n",
    "        \"guilty_masked_fingers_isis\",\n",
    "        torch.where(evidence_mask_fingers_isis, guilty, torch.tensor(float(\"nan\")))            \n",
    "        )\n",
    "    \n",
    "    posterior_guilty_fingers_isis = pyro.deterministic(\n",
    "        \"posterior_guilty_fingers_isis\", torch.nanmean(guilty_masked_fingers_isis, axis=0))\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    return {\"guilty\": guilty, \"isis\": isis, 'fingers_match_rmp': fingers_match_rmp, \n",
    "            'fingers_match_isis': fingers_match_isis,\n",
    "            \"posterior_guilty_fingers_rmp\": posterior_guilty_fingers_rmp, \n",
    "            \"posterior_guilty_fingers_isis\": posterior_guilty_fingers_isis}\n",
    "     \n",
    "\n",
    "#set pyro random seed\n",
    "pyro.set_rng_seed(422323)\n",
    "swedish_fingers_guilt_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"484pt\" height=\"208pt\"\n",
       " viewBox=\"0.00 0.00 483.87 207.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 203.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-203.75 479.87,-203.75 479.87,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_particles</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"41.92,-44 41.92,-191.75 435.92,-191.75 435.92,-44 41.92,-44\"/>\n",
       "<text text-anchor=\"middle\" x=\"404.67\" y=\"-50.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">particles</text>\n",
       "</g>\n",
       "<!-- posterior_guilt_not_isis_mean -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>posterior_guilt_not_isis_mean</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"122.92\" cy=\"-18\" rx=\"122.92\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122.92\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">posterior_guilt_not_isis_mean</text>\n",
       "</g>\n",
       "<!-- posterior_guilt_isis_mean -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>posterior_guilt_isis_mean</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"369.92\" cy=\"-18\" rx=\"105.95\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"369.92\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">posterior_guilt_isis_mean</text>\n",
       "</g>\n",
       "<!-- guilty -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>guilty</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"246.92\" cy=\"-165.75\" rx=\"30.61\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"246.92\" y=\"-160.32\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">guilty</text>\n",
       "</g>\n",
       "<!-- posterior_guilt_not_isis -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>posterior_guilt_not_isis</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"147.92\" cy=\"-93.75\" rx=\"98.47\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"147.92\" y=\"-88.33\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">posterior_guilt_not_isis</text>\n",
       "</g>\n",
       "<!-- guilty&#45;&gt;posterior_guilt_not_isis -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>guilty&#45;&gt;posterior_guilt_not_isis</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.83,-151.25C214.62,-141.91 196.68,-129.23 181.15,-118.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.27,-115.46 173.09,-112.55 179.23,-121.18 183.27,-115.46\"/>\n",
       "</g>\n",
       "<!-- posterior_guilt_isis -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>posterior_guilt_isis</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"345.92\" cy=\"-93.75\" rx=\"81.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"345.92\" y=\"-88.33\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">posterior_guilt_isis</text>\n",
       "</g>\n",
       "<!-- guilty&#45;&gt;posterior_guilt_isis -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>guilty&#45;&gt;posterior_guilt_isis</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.01,-151.25C279.32,-141.84 297.41,-129.05 313.02,-118.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"314.97,-120.92 321.11,-112.29 310.93,-115.21 314.97,-120.92\"/>\n",
       "</g>\n",
       "<!-- posterior_guilt_not_isis&#45;&gt;posterior_guilt_not_isis_mean -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>posterior_guilt_not_isis&#45;&gt;posterior_guilt_not_isis_mean</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.12,-75.64C139.24,-67.14 135.68,-56.65 132.42,-47.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.78,-46.05 129.26,-37.7 129.15,-48.3 135.78,-46.05\"/>\n",
       "</g>\n",
       "<!-- posterior_guilt_isis&#45;&gt;posterior_guilt_isis_mean -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>posterior_guilt_isis&#45;&gt;posterior_guilt_isis_mean</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M351.49,-75.64C354.25,-67.14 357.67,-56.65 360.8,-47.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364.07,-48.3 363.83,-37.71 357.41,-46.13 364.07,-48.3\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x18777bade50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.render_model(swedish_fingers_guilt_model, render_deterministic = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior_guilt_not_isis tensor([1.0000e-04, 1.0000e-04, 1.0000e-04,  ..., 1.0000e-04, 1.0000e-04,\n",
      "        1.0000e-04])\n",
      "posterior_guilt_isis tensor([0.0004, 0.0004, 0.0004,  ..., 0.0004, 0.0004, 0.0004])\n",
      "posterior_guilt_not_isis_mean tensor(0.0102)\n",
      "posterior_guilt_isis_mean tensor(0.0105)\n"
     ]
    }
   ],
   "source": [
    "# extracting the posterior probabilities\n",
    "\n",
    "with pyro.poutine.trace() as tr:\n",
    "   pyro.set_rng_seed(42)\n",
    "   swedish_fingers_guilt_model(num_particles=1e6)\n",
    "\n",
    "for key in tr.trace.nodes.keys():\n",
    "        if key.startswith(\"posterior\"):\n",
    "                print(key, tr.trace.nodes[key]['value'])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior_guilt_not_isis_mean tensor([0.9898, 0.0102])\n",
      "posterior_guilt_isis_mean tensor([0.9895, 0.0105])\n",
      "tensor([1.0000e-04, 4.0000e-04])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "posterior_guilt_not_isis_mean = torch.tensor([\n",
    "    1 - tr.trace.nodes['posterior_guilt_not_isis_mean']['value'], \n",
    "    tr.trace.nodes['posterior_guilt_not_isis_mean']['value'],      \n",
    "])\n",
    "\n",
    "posterior_guilt_isis_mean = torch.tensor([\n",
    "    1 - tr.trace.nodes['posterior_guilt_isis_mean']['value'],  \n",
    "    tr.trace.nodes['posterior_guilt_isis_mean']['value'],     \n",
    "])\n",
    "\n",
    "print('posterior_guilt_not_isis_mean', posterior_guilt_not_isis_mean)\n",
    "print('posterior_guilt_isis_mean', posterior_guilt_isis_mean)\n",
    "\n",
    "\n",
    "pr_identity = 0.01              \n",
    "pr_fingers_match_if_not_isis = 2 / 20000 \n",
    "pr_fingers_match_if_isis = 2 / 5000\n",
    "\n",
    "\n",
    "prior_guilt = torch.tensor([1 - pr_identity, pr_identity])  \n",
    "\n",
    "\n",
    "probs_of_evidence = torch.tensor([\n",
    "    pr_fingers_match_if_not_isis,  \n",
    "    pr_fingers_match_if_isis         \n",
    "])\n",
    "print(probs_of_evidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9179, 0.9160])\n",
      "Expected Weights: {'expected_weight': tensor(-1.4350e-06), 'weight_prior': 0.9192068800330162, 'posterior_weights': tensor([0.9179, 0.9160]), 'weight_changes': tensor([-0.0013, -0.0033]), 'weighted_weight_changes': tensor([-1.3228e-07, -1.3027e-06])}\n"
     ]
    }
   ],
   "source": [
    "expected_weights = expected_weight(\n",
    "    probs_of_evidence, prior_guilt, \n",
    "    [posterior_guilt_not_isis_mean, posterior_guilt_isis_mean]\n",
    ")\n",
    "\n",
    "print(\"Expected Weights:\", expected_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
