---
title: "Legal Probabilism and Its Limits"
author: "Marcello Di Bello and Rafal Urbaniak"
date: '`r Sys.Date()`'
output:
  bookdown::pdf_book: 
    keep_tex: yes
    extra_dependencies: ["todonotes"]
  bookdown::gitbook:
    lib_dir: "book_assets"
  includes:
      in_header:
        - Rafal_latex4.sty
documentclass: book
classoptions: dvipsnames, usenames
site: bookdown::bookdown_site
bibliography: [bibliographyRafal.bib]
biblio-style: 
link-citations: yes
csl: apa-5th-edition.csl
---

<!-- github-repo: rstudio/bookdown-demo -->


```{r setup, include=FALSE, echo=FALSE}
library(bookdown)
library(tidyverse)
library(knitr)

options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)
```
 

\part{What is legal probabilism?}

\chapter{The emergence of legal probabilism}



This chapter will introduce legal probabilism and contain an account of early  
discussions of legal probabilism, how 
it came about, when, major contributions, etc. 
I see essentially two moments in 
the history of legal probabilism: the early days when probability 
theory was invented (Bernoulli, Laplace, Condorcet, etc.), and then 
the second half of the 20th century with the emergence 
of the New Evidence Scholarship (Lempert) 
and law and economics. But the history 
might be more complicated. 





\chapter{A skeptical perspective}



This chapter would discuss puzzles and 
hypothetical scenarios, mostly the debate 
about naked statistical evidence. This 
is a discussion of the most compelling objections that have 
been raised against legal probabilism.
Most of these objections 
trace back to Cohen, although 
other pivotal players 
are Laurence Tribe and Ronald Allen.
I think this chapter could 
also have a historical flavor or perhaps it could be more 
systematic. Not sure about 
the best presentation format. 


<!-- divide problems into easier and harder -->

\section{The difficulty about conjunction}


\section{The complexity objection}



\section{The problem of corroboration}


\section{The problem of artificial precision}


\section{Naked statistical evidence}\label{sec:naked}

\section{The problem of priors}

\section{The reference class problem}


\section{Non-probabilistic perspectives}






\part{Evidence assessment}


After the first part, the rest of the book will 
be a deep dive into what probability theory can do for us 
when it is applied to trial proceedings. 

Instead of addressing the common objections 
upfront, the strategy of the book would 
be to set the objections 
aside -- keep them on the back burner 
as it were -- and return to them once we have 
a clearer sense of legal probabilism 
and its limits.

\todo{We need to clearly set the limit of discussion of objections in the first part}



This part of the book is devoted to how probability 
theory can help---or not help---in assessing 
trial evidence. I think it is important that 
we start very simple and then we progressively 
get more complex.




\chapter{Bayes' Theorem and the usual fallacies}

This chapter shows how we can use probability theory 
and Bayes' theory to spot common probabilistic fallacies, 
prosecutor's fallacy, base rate fallacy, etc. 
This is the simple stuff. 

 I think this chapter should also show the limitation 
 of this approach. That is, we should make clear that these 
 are probabilistic fallacies. They are fallacies only insofar as the trier of facts 
 aim to determine the posterior probability of guilt. Which they might not. 
 \todo{careful here, some come up without explicit calculations}
 
 The chapter will also be accompanied 
 by case studies. 
 
 \section{Assuming independence}

\section{The prosecutor's fallacy}

\section{Base rate fallacy}

\section{Defense attorney's fallacy} 
 
 \section{Uniqueness fallacy}
 
 \section{Case studies}
 
 \subsection{Collins}
 
 \subsection{Sally Clark}
 
 
 \chapter{Complications and caveats}
 
 \todo{not sure if this isn't too early}
 
 Here we examine a number of complications that 
 emerge from the simple Bayes' theorem approach 
 described in the earlier chapter. Here are some of the common difficulties:
 
 \begin{itemize}
 
 \item How do we determine the priors?
 
 \item More generally, how do we determine the numerical 
 values of any of the probabilities involved? 
 It might work for DNA matches, but what about non0numerical evidence 
 such as eyewitnesses? 
 
 \item How do we combine different pieces of evidence?  
 
 \item How we we formulate complex hypotheses, 
 say narratives, stories or explanations? 
 
 \item How do we take into account things 
 like the coherence of one's story or 
 the explanatory power of one's hypothesis?
 (evidence-to-hypothesis reasoning 
 versus hypothesis-to-evidence reasoning).
 
 \item Ronald Allen's objections 
 and Susan Haack's objections. 
 
 \end{itemize} 
 
\section{Complex hypotheses and complex bodies of evidence}
 

\section{Source, activity and offense level hypotheses}
 

\section{Where do the numbers come from?}
 

\section{Modeling corroboration} 


 
 \section{Stories, explanations and coherence}
 
 
 
 
 
 \chapter{Likelihood Ratios and Relevance}
 
 Here we present likelihood ratios as a possible 
 answer to some of the complications. Pros and cons 
 of this approach. It addresses 
 the problems of priors to some extent, 
 but it leaves a lot of the other complications essentially unresolved. 
 The likelihood approach raises 
 complication of its own.
  
\section{Odds version of Bayes' theorem}
 
\section{Bayesian factor v. likelihood ratio}   
   
\section{Choosing competing hypotheses}


\section{The two-stain problem}


\section{Case study: cold-hit DNA match evaluation}


<!-- \subsection{Guidelines from the European Forensic Institute} -->

 
 \chapter{Bayesian Networks}
 
 Here we present Bayesian networks 
as the best answer that legal probabilists 
can offer. We illustrate Bayesian networks 
with examples and show how they can answer 
some of the complications. We try to be 
as honest as possible. We want to be a reliable and trustworthy 
source of discussion, not partisan. We also discuss 
how Bayesian networks can help address certain 
puzzles about relevance. 



 <!-- \section{Multiple pieces of evidence and complex hypotheses} -->
 
\section{Bayesian networks to the rescue}  

\section{Legal evidence idioms} 

\section{Scenario idioms}


\section{Modeling relevance}


\section{Case study: Sally Clark}

\todo{Do we really want to get into BNs for DNA evidence evaluation?}

\section{DNA evidence}




\todo{We already mention corroboration at two places, we should clean this up.}

\chapter{Corroboration}

Here we zoom into a particular topic. This should be a 
place to review the literature on corroboration and 
for Rafal to present his own probabilistic solution 
to the corroboration puzzle.


Use BNs in the exposition!


\section{Boole's formula and Cohen's challenge}

\section{Modeling substantial rise in case of agreement}

\section{Ekel\"of's corroboration measure and evidentiary mechanisms}

\section{General approach  with multiple false stories and multiple witnesses}




\chapter{Coherence}

Looks like coherence (cohesiveness and related ideas) 
plays an important role in assessing evidence at trial. 
Here it would be place to review the literature on coherence 
and for Rafal to preset his 
own probabilistic solution to the coherence puzzle, 
emphasizing legal applications.

<!-- \chapter{Completeness} -->


<!-- \section{Philosophical motivations} -->


\section{Existing probabilistic coherence measures}


\section{An array of counterexamples}

\section{Coherence of structured narrations 
with Bayesian networks}

\section{Application to legal cases}





\chapter{New legal probabilism}



\section{Desiderata}

\section{A probabilistic framework for narrations}

\section{Probabilistic explications of the desiderata}

\section{Bayesian network implementation}


<!-- \section{Comparison to existing approaches} -->








\todo{perhaps Allen, Haack \& Moss here? }


- The Dutch school and its challenges




 - Merging/aggregation/selection issues



 - Conditions on narration


 - Formal representation and programmatic deployment





\part{Trial Decisions}

We turn from assessing 
evidence to trial decisions.
The question is this, when is the evidence strong 
enough to meet the governing burden of proof?

\chapter{Standards of proof}


\section{Legal background}


\section{Probabilistic thresholds}

\section{Theoretical difficultiies}

\section{Likelihood approach}

\section{The difficulties perist}

\section{Bayesian networks and probabilistic standard of proof}


\chapter{The functions of the proof standards}

\section{Protecting defendants} 

(re Winship) 

\section{Error reduction and error distribution/allocation} 

(Laudan, Stein, Allen)

\section{Dispute resolution and public deference} 

(Nesson)

\section{Justification and answerability}

(Duff)

\section{How probability theory can help}


\chapter{Accuracy and the risk of error}

This chapter introduces different 
ways to think about the risk 
of error at trial. 

\section{Minimizing expected costs}

Thisreviews the literature 
that describes how 
expected utility can be used 
to define rules for trial decisions.

\section{Minimizing expected errors}

\section{Expected v.\ actual errors}

\section{Competing accounts 
of the risk of error}

One dimension of the risk of error 
flows from the posterior probabilities $P(Guilt | Evidence)$. 
The other dimension flows from the conditional probabilities 
$P(Conviction | Innocence)$.
This an opportunity for Marcello to present the arguments in his Mind paper, 
which however Rafal has criticized. So hopefully this chapter 
will be a very balanced account of the topic!


\section{Bayesian networks and 
the risk of error}


\chapter{Fairness in trial decisions}

This chapter discusses how decisions can be fair and to what extent probability 
theory can help us think about the fairness of decisions. 
One important notion of fairness that probability theory 
can capture is that of equal distribution of the risk of error. 
This draws on some of Marcello's argument in the Ethics paper.

\todo{talk about incompatibility of definitions, Hedden's argument against measures of fairness etc.}



\section{Procedural v.\ substantive fairness}

\section{Competing measures of substantive fairness}

\section{Bayesian networks and fairnesss}


\part{Comparisons}

\chapter{Alternative accounts}

There exist several theoretical alternatives to the probabilistic interpretation of proof standards in the scholarly literature. Some scholars, on empirical or normative grounds, resist the claim that the point of gathering and assessing evidence at trial is solely to estimate the probability of the defendant's civil or criminal liability.


\section{Baconian probability}

This is Cohen's stuff, also followed by Alex Stein. [@stein2008] argues that,  in order to warrant a verdict against the defendant, the evidence should have withstood objections and counterarguments, not merely supporting a high probability.


\section{Relative Plausibility}

[@Pennington1991, @penn1993] have proposed the \textit{story model}   according to which judges and jurors, first make sense of the evidence by constructing stories of what happened, and then select the best story on the basis of multiple criteria, such as coherence, fit with the evidence and completeness.
Along similar lines, [@Pardo2008judicial] argue that the version of the facts that best explains the evidence should prevail in a court of law. For a discussion of inference to the best explanation in legal reasoning, see  [@schwartz2019WhatRelativePlausibility, @hastie2019CaseRelativePlausibilitya, @lai2019HowPlausibleRelative, @nance2019LimitationsRelativePlausibility].

\section{Arguments}

Another approach is due to [@gordon2007] and [@prakken2009] who view the trial as a place in which  arguments and counterarguments confront one another.  The party that has the best arguments, all things considered, should prevail.  On this view, probability estimates can themselves be the target of objections and counterarguments. 

\section{Relevant alternatives}

[@gardiner2019ppa] argues that standards of proof should rule out all error possibilities that are relevant and these need not coincide with error possibilities that are probable.

\section{Normic Support}

Martin Smith approach. 

\section{Justification/foundherentism}

[@ho2008philosophy] and [@Haack2014-HAAEMS] 
hold that degrees of epistemic warrant for a claim, which depend 
on multiple factors -- such as the extent to which the evidence 
supports the claim and it is comprehensive -- cannot be equated 
to probabilities.  


\section{Completeness}

Discuss here Nance proposal. [@nance2016] argues that the evidence on which to base a trial decision should be reasonably complete---it should be all the evidence that one would reasonably expect to see from a conscientious investigation of the facts. A similar argument can be found in [@davidsonpargetter1987]. Arguably, probability-based decision thresholds can accommodate these considerations, for example, by lowering the probability of civil or criminal liability whenever the body of evidence is one-sided or incomplete  [@Kaye79gate, @Kaye1986Do, @friedman1996]. Another strategy is to give a probability-based account of the notion of completeness of the evidence and other seemingly non-probabilistic criteria   [@urbaniak2018narration].


\section{Knowledge} 

Some epistemologists  argue that a probabilistic belief, no matter how high, is not enough to warrant knowledge, and knowledge should be the standard for trial verdicts.


\chapter{Legal probabilism and ...}

\section{... Baconian probability}

\section{... relative plausibility}

\section{... the story model}

\section{ .. foundherentism}

\section{... arguments}

\section{... relevant alternatives} 

\section{... normic support}

\section{... knowledge}



<!--

\part{Trial Institutions}

Finally, this part of the book should 
assess some institutions of the trial system 
using probability theory and 
cognate theories. I am not sure 
if this is too much, but I am 
putting it here just in case. 

\todo{Are we competent to discuss this?}

\chapter{Rules of Evidence}

\chapter{Cross-examination}

 -->
 
\chapter{Conclusion}

I'd like this conclusion 
to be a very 
careful and nuanced discussion of the 
good and bad things about 
legal probabilism. What difficulties can 
in principle be overcome and what other difficulties are instead 
inherent to legal probabilism and thus inescapable?







# Preface {-}


testing again



\begin{align} 
  f\left(k\right) = \binom{n}{k} p^k\left(1-p\right)^{n-k}
  (\#eq:binom)
\end{align} 


This is a citation [@diamond90] which uses keys from the bib file listed in the preamble.

Equation \@ref(eq:binom)^[This is a footnote containing a double citation [@diamond90; @dahlmanNakedStat2020].]

Note that chapter files are found and compiled automatically, but the file names have to contain chapter numbers first. For instance, we used `01-intro.Rmd`, placed in the same folder. Observe how we included r code inline.



```{r fig-margin, fig.margin=TRUE}
plot(cars)
```

