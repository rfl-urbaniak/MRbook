\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}The problem}{2}{section.1}}
\newlabel{the-problem}{{1}{2}{The problem}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}The Conjunction Principle}{2}{subsection.1.1}}
\newlabel{the-conjunction-principle}{{1.1}{2}{The Conjunction Principle}{subsection.1.1}{}}
\@writefile{tdo}{\contentsline {todo}{False in whole generality, give a counterexample with more specific numbers. M: I changed things a bit. Maybe it's clear now. The counterexample is basically P(A)=P(B)=0.95, but P(AB)=Pr(A)*P(A|B) and since P(A|B) is below 1, then P(AB) is below 0.95.}{3}{section*.2}}
\pgfsyspdfmark {pgfid1}{22262331}{45712430}
\pgfsyspdfmark {pgfid4}{36556972}{45704562}
\pgfsyspdfmark {pgfid5}{38987980}{45491247}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Aggregating hypotheses and evidence}{3}{subsection.1.2}}
\newlabel{aggregating-hypotheses-and-evidence}{{1.2}{3}{Aggregating hypotheses and evidence}{subsection.1.2}{}}
\@writefile{tdo}{\contentsline {todo}{M: These relationships of independence are confusing. Any way to make them more plausible and stremalined? HELP!}{3}{section*.3}}
\pgfsyspdfmark {pgfid6}{6526379}{28462024}
\pgfsyspdfmark {pgfid9}{36556972}{28454156}
\pgfsyspdfmark {pgfid10}{38987980}{28240841}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Probabilistic (in)dependencies}{3}{subsection.1.3}}
\newlabel{probabilistic-independencies}{{1.3}{3}{Probabilistic (in)dependencies}{subsection.1.3}{}}
\@writefile{tdo}{\contentsline {todo}{M: Not sure how to write this. I used $\delimiter "4470470 A\wedge B \delimiter "5471471 $ to represent the conjunction in the language (as a node in the network) as distinct from the conjunction in the conditional probability (not as a node in the network). They seem two different things. Confusing. HELP!}{4}{section*.4}}
\pgfsyspdfmark {pgfid11}{26085660}{30485480}
\pgfsyspdfmark {pgfid14}{36556972}{30477612}
\pgfsyspdfmark {pgfid15}{38987980}{30264297}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Two Bayesian networks for two pieces of evidence and a composite hypothesis.}}{4}{figure.1}}
\newlabel{network-conjunction}{{1}{4}{Two Bayesian networks for two pieces of evidence and a composite hypothesis}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Rejecting the Conjunction Principle?}{5}{section.2}}
\newlabel{rejecting-the-conjunction-principle}{{2}{5}{Rejecting the Conjunction Principle?}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Risk Accumulation}{5}{subsection.2.1}}
\newlabel{risk-accumulation}{{2.1}{5}{Risk Accumulation}{subsection.2.1}{}}
\@writefile{tdo}{\contentsline {todo}{Hey, we can quote a paper that's out by Alicja!:) Also, I guess you want me to find the right refs? M: Yes, if you can}{5}{section*.5}}
\pgfsyspdfmark {pgfid18}{8719585}{43272547}
\pgfsyspdfmark {pgfid21}{36556972}{43264679}
\pgfsyspdfmark {pgfid22}{38987980}{43051364}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Atomistic and Holistic Approches}{5}{subsection.2.2}}
\newlabel{atomistic-and-holistic-approches}{{2.2}{5}{Atomistic and Holistic Approches}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Prior Probabilities}{6}{subsection.2.3}}
\newlabel{prior-probabilities}{{2.3}{6}{Prior Probabilities}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Evidential Strength}{7}{subsection.2.4}}
\newlabel{evidential-strength}{{2.4}{7}{Evidential Strength}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Aggregation succeeds, distribution fails}{8}{section.3}}
\newlabel{aggregation-succeeds-distribution-fails}{{3}{8}{Aggregation succeeds, distribution fails}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Bayes factor threshold}{8}{subsection.3.1}}
\newlabel{bayes-factor-threshold}{{3.1}{8}{Bayes factor threshold}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Aggregating evidence}{8}{subsubsection.3.1.1}}
\newlabel{aggregating-evidence}{{3.1.1}{8}{Aggregating evidence}{subsubsection.3.1.1}{}}
\@writefile{tdo}{\contentsline {todo}{M: Need to fix graph here. HELP!}{9}{section*.6}}
\pgfsyspdfmark {pgfid23}{7181739}{42033089}
\pgfsyspdfmark {pgfid26}{36556972}{42025221}
\pgfsyspdfmark {pgfid27}{38987980}{41811906}
\@writefile{tdo}{\contentsline {todo}{M: How do we prove this? I think this should be clear by plotting. In plotting, we ensure that both BFs are greater than one, then the combined BF is greater than the smallests even when A and B dependent. HELP!}{10}{section*.7}}
\pgfsyspdfmark {pgfid28}{26081390}{47285294}
\pgfsyspdfmark {pgfid31}{36556972}{47277426}
\pgfsyspdfmark {pgfid32}{38987980}{47064111}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Variable Threshold}{10}{subsubsection.3.1.2}}
\newlabel{variable-threshold}{{3.1.2}{10}{Variable Threshold}{subsubsection.3.1.2}{}}
\@writefile{tdo}{\contentsline {todo}{good question, will think about it, will need to take a look at "Bayesian Choice", also need to think about a counterexample}{10}{section*.8}}
\pgfsyspdfmark {pgfid33}{28396190}{38442620}
\pgfsyspdfmark {pgfid36}{36556972}{38434752}
\pgfsyspdfmark {pgfid37}{38987980}{38221437}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Fixed Threshold}{11}{subsubsection.3.1.3}}
\newlabel{fixed-threshold}{{3.1.3}{11}{Fixed Threshold}{subsubsection.3.1.3}{}}
\@writefile{tdo}{\contentsline {todo}{Not always true; just give a specific numerical counterexample. M: I added 'often'. Is this enough?}{11}{section*.9}}
\pgfsyspdfmark {pgfid38}{25183452}{22852673}
\pgfsyspdfmark {pgfid41}{36556972}{22844805}
\pgfsyspdfmark {pgfid42}{38987980}{22631490}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Likelihood ratio threshold}{12}{subsection.3.2}}
\newlabel{likelihood-ratio-threshold}{{3.2}{12}{Likelihood ratio threshold}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Aggregating evidence}{13}{subsubsection.3.2.1}}
\newlabel{aggregating-evidence-1}{{3.2.1}{13}{Aggregating evidence}{subsubsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Combined likelihood ratios exceeds individual Likelihood ratios. Changes in the prior probabilities $t$ and $k$ do not invalidate this result.}}{14}{figure.2}}
\newlabel{fig:jointLRMarcello}{{2}{14}{Combined likelihood ratios exceeds individual Likelihood ratios. Changes in the prior probabilities $t$ and $k$ do not invalidate this result}{figure.2}{}}
\@writefile{tdo}{\contentsline {todo}{M: Need to add simuation results to make this argument fully general and drop all the simplifying assumptions (.e.g. independence or equiprobability). HELP!}{14}{section*.12}}
\pgfsyspdfmark {pgfid43}{7181739}{24644104}
\pgfsyspdfmark {pgfid46}{36556972}{24636236}
\pgfsyspdfmark {pgfid47}{38987980}{24422921}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Variable Threshold}{14}{subsubsection.3.2.2}}
\newlabel{variable-threshold-1}{{3.2.2}{14}{Variable Threshold}{subsubsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Fixed Threshold}{15}{subsubsection.3.2.3}}
\newlabel{fixed-threshold-1}{{3.2.3}{15}{Fixed Threshold}{subsubsection.3.2.3}{}}
\@writefile{tdo}{\contentsline {todo}{M: This whole section should be generalized to the case in which A and B are not independent using the simulation data.}{16}{section*.14}}
\pgfsyspdfmark {pgfid48}{7181739}{29383326}
\pgfsyspdfmark {pgfid51}{36556972}{29375458}
\pgfsyspdfmark {pgfid52}{38987980}{29162143}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}The comparative strategy}{16}{subsection.3.3}}
\newlabel{the-comparative-strategy}{{3.3}{16}{The comparative strategy}{subsection.3.3}{}}
\newlabel{eq:cheng-multiplication}{{1}{17}{The comparative strategy}{equation.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}The Conjunction Principle Is False}{18}{section.4}}
\newlabel{the-conjunction-principle-is-false}{{4}{18}{The Conjunction Principle Is False}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Factoring Out Prior Probabilities}{18}{subsection.4.1}}
\newlabel{factoring-out-prior-probabilities}{{4.1}{18}{Factoring Out Prior Probabilities}{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The further away the posterior line from the base line, the stronger the evidence irrespective of the prior probability of the hypothesis.}}{19}{figure.3}}
\newlabel{fig:strength-prior-post}{{3}{19}{The further away the posterior line from the base line, the stronger the evidence irrespective of the prior probability of the hypothesis}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Weaker Claims Weaken Sensitivity}{20}{subsection.4.2}}
\newlabel{weaker-claims-weaken-sensitivity}{{4.2}{20}{Weaker Claims Weaken Sensitivity}{subsection.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The comparison is betwen individual support (marked by 1, for one individual hypothesis) and joint support (marked by 2, for a two-claim composite claim). Top graph: The base line for joint support ($y=x*x$) is below the base line for individual support ($y=x$). Bottom graph: the two base lines are equalized and the posterior lines adjusted accordingly. The posterior lines for individual and joint support get closer especially for high posterior probability values.}}{21}{figure.4}}
\newlabel{fig:post-indiv-joint}{{4}{21}{The comparison is betwen individual support (marked by 1, for one individual hypothesis) and joint support (marked by 2, for a two-claim composite claim). Top graph: The base line for joint support ($y=x*x$) is below the base line for individual support ($y=x$). Bottom graph: the two base lines are equalized and the posterior lines adjusted accordingly. The posterior lines for individual and joint support get closer especially for high posterior probability values}{figure.4}{}}
\@writefile{tdo}{\contentsline {todo}{M: Run simulation to show that same diagnostic test for composite claim would perform better then when applied to individual claim (worse LR). How do to do this? HELP!}{23}{section*.15}}
\pgfsyspdfmark {pgfid53}{14741893}{49644590}
\pgfsyspdfmark {pgfid56}{36556972}{49636722}
\pgfsyspdfmark {pgfid57}{38987980}{49423407}
\@writefile{tdo}{\contentsline {todo}{M: How to explain this better? Can we make this plausible? HELP!}{23}{section*.16}}
\pgfsyspdfmark {pgfid58}{24943345}{25127871}
\pgfsyspdfmark {pgfid61}{36556972}{25120003}
\pgfsyspdfmark {pgfid62}{38987980}{24906688}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Bayesian network with wholly unrelated claim $H$.}}{23}{figure.5}}
\newlabel{network-unrelated}{{5}{23}{Bayesian network with wholly unrelated claim $H$}{figure.5}{}}
\@writefile{tdo}{\contentsline {todo}{M: Is this true probabilistically? If not, what assumptions are required? HELP!}{23}{section*.17}}
\pgfsyspdfmark {pgfid64}{29867342}{11700753}
\pgfsyspdfmark {pgfid67}{36556972}{11692885}
\pgfsyspdfmark {pgfid68}{38987980}{11479570}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}But Sensitivity Depends On Prior Probabilities}{23}{subsection.4.3}}
\newlabel{but-sensitivity-depends-on-prior-probabilities}{{4.3}{23}{But Sensitivity Depends On Prior Probabilities}{subsection.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Bayesian network with $ab$ resulting from $A$ and $B$.}}{24}{figure.6}}
\newlabel{network-ab}{{6}{24}{Bayesian network with $ab$ resulting from $A$ and $B$}{figure.6}{}}
\@writefile{tdo}{\contentsline {todo}{M: Might be good to have a simulation here that makes vidid why combined specificity is in fact dependent on the priors. Maybe it is, after all, a fallacy to think that the quality/strength of the evidence should be independent of the priors. HELP!}{24}{section*.18}}
\pgfsyspdfmark {pgfid70}{11377952}{10457260}
\pgfsyspdfmark {pgfid73}{36556972}{10449392}
\pgfsyspdfmark {pgfid74}{38987980}{10236077}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Which Measure of (Combined) Evidential Support?}{25}{subsection.4.4}}
\newlabel{which-measure-of-combined-evidential-support}{{4.4}{25}{Which Measure of (Combined) Evidential Support?}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Revising the Holistic Approach}{25}{section.5}}
\newlabel{revising-the-holistic-approach}{{5}{25}{Revising the Holistic Approach}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Extra unstructured materials}{27}{section.6}}
\newlabel{extra-unstructured-materials}{{6}{27}{Extra unstructured materials}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}The likelihood strategy}{27}{subsection.6.1}}
\newlabel{the-likelihood-strategy}{{6.1}{27}{The likelihood strategy}{subsection.6.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Kaplow}{28}{subsubsection.6.1.1}}
\newlabel{kaplow}{{6.1.1}{28}{Kaplow}{subsubsection.6.1.1}{}}
\newlabel{eq:Kaplow_decision}{{2}{28}{Kaplow}{equation.6.2}{}}
\newlabel{eq:Kaplow_decision2}{{3}{28}{Kaplow}{equation.6.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Dawid}{28}{subsubsection.6.1.2}}
\newlabel{dawid}{{6.1.2}{28}{Dawid}{subsubsection.6.1.2}{}}
\newlabel{bayesodss2}{{4}{29}{Dawid}{equation.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Likelihood and DAC}{29}{subsection.6.2}}
\newlabel{likelihood-and-dac}{{6.2}{29}{Likelihood and DAC}{subsection.6.2}{}}
\newlabel{eq:total_lower}{{5}{30}{Likelihood and DAC}{equation.6.5}{}}
\newlabel{ther:increase}{{1}{31}{}{fact.1}{}}
\newlabel{eq:sumupto1}{{6}{31}{Likelihood and DAC}{equation.6.6}{}}
\newlabel{eq:aetb}{{7}{31}{Likelihood and DAC}{equation.6.7}{}}
\newlabel{eq:boiled}{{8}{32}{Likelihood and DAC}{equation.6.8}{}}
\newlabel{eq:goal}{{9}{32}{Likelihood and DAC}{equation.6.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Kaplow}{32}{subsubsection.6.2.1}}
\newlabel{kaplow-1}{{6.2.1}{32}{Kaplow}{subsubsection.6.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Dawid's likelihood strategy doesn't help}{32}{subsection.6.3}}
\newlabel{dawids-likelihood-strategy-doesnt-help}{{6.3}{32}{Dawid's likelihood strategy doesn't help}{subsection.6.3}{}}
\newlabel{eq:lambdamu}{{10}{33}{Dawid's likelihood strategy doesn't help}{equation.6.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Problem's with Kaplow's stuff}{37}{subsection.6.4}}
\newlabel{problems-with-kaplows-stuff}{{6.4}{37}{Problem's with Kaplow's stuff}{subsection.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Conclusions}{40}{subsection.6.5}}
\newlabel{conclusions}{{6.5}{40}{Conclusions}{subsection.6.5}{}}
\newlabel{references}{{6.5}{40}{References}{section*.19}{}}
\@writefile{toc}{\contentsline {section}{References}{40}{section*.19}}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{9.55988pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{16.49994pt}
\global\@namedef{scr@dte@subsubsection@lastmaxnumwidth}{23.99994pt}
