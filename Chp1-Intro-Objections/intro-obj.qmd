
---
title: "Chapter 1: Against Legal Probabilism"
format:
  pdf:
    toc: false
    number-sections: true
    colorlinks: true
---

We present the theory of legal probabilism, discuss several objections against it and outline a number of responses available to the legal probabilist.

# The burden of proof

Witnesses are called to testify in court about questions relevant to the defendant's civil or criminal liability. They can be lay people testifying about what they saw or heard. They can be experts testifying about results of laboratory testing or general scientific knowledge. As they testify, 
they are examined and cross-examined by the lawyers of the two parties. The rules of evidence and trial procedure frame how evidence is presented and place restrictions on certain forms of information, for example, hearsay evidence is often considered inadmissible. 

Within these legal constraints, the purpose of the examination and cross-examination of witnesses is to ascertain whether the defendant engaged in behaviour or committed acts that are prohibited by the applicable law.  To put it somewhat crudely, the question to be answered  is, did the defendant did it or not? Only if the overall evidence is strong enough to establish that the defendant did it, the defendant should be found liable. 

The evidence is strong enough when it meets the governing burden of proof. This burden is  different in civil or criminal cases. In civil cases, the burden of proof is 'preponderance of the evidence' (or 'balance of probabilities'); in criminal cases, the burden of proof is 'proof beyond a reasonable doubt'. The latter is meant to be more stringent than the former. These distinctions applies to countries in the common law tradition, but the concept of burden of proof seems nearly universal. 


# Probability thresholds 

According to legal probabilism, the burden of proof is a probability threshold applied to the probability of liability. This is the probability, based on the evidence presented in court, that the defendant committed the unlawful acts or engaged in the unlawful behavior they are accused of. So, according to legal probabilism, if this probability is sufficiently high, the decision should be against the defendant, and otherwise it should favor the defendant. 

Two questions arise naturally at this point. How stringent should the threshold be? How is 'probability' understood here? 
Consider each in turn.

How stringent the threshold should be---51 percent 99 percent or what?---is a function of maximizing expected benefits and minimizing expected costs. We can think of the costs as externalities associated with false positive and false negative decisions. The benefits, instead, flow from true positive and true negative decisions. Typically, since the cost of a false positive---judging the defendant liable when they are not---is greater in criminal than  civil trials, the probability threshold is set higher in criminal trials. This agrees with the fact that 'proof beyond a reasonable doubt' is more stringent than 'preponderance of the evidence'.

How is 'probability' to be understood in speaking of the probability of liability or the probability that the defendant did this and that? It cannot be a long-run frequency because the acts the defendant committed or not, are not repeatable events. It cannot be an objective chance either becuase, as a matter of fact, the defendant either committed those acts or did not. They lie somewhere in the past. Either they occurred or they did not. So the probability of liability must reflect the extent to which the evidence presented in court supports the claim that the defendant committed the unlawful acts they are accused of. The probability of liability must be evidence-relative. It must be an epistemic probability of some kind.

The metaphor of a scale can be helpful. Evidence may tip the scale in one direction or the other. Evidence can point against the defendant, making it more probable that that the accusation theory is true. Or it can point in favor of the defendant, making it less probable that the accusation theory is true. The overall balance of the scale, based on the total evidence, is the probability that the accusation theory is true.

The probabilistic picture of the burden of proof is not uncontroversial, as we shall soon seen. But it has some plausibility, especially in civil trials. So it is worth exploring it more closely. 

In civil trials, the defendant's liability is established by the balance of probabilities---the burden of proof governing civil trials---provided the defendant's liability, based on the evidence presented, is greater than than .5. That is, if $L$ stands for 'the defendant is liable' and $E$ stans for the total evidence presented via examination and cross-examination, the burden of proof is formulated as follows:

\begin{quote}
find against the defendant if $P(L \vert E)>.5$ 
\end{quote}

\noindent
The word 'liability' is somewhat unspecific. The defendant is accused of having committed actions or behaviors that, according to the applicable law, count as impermissible. For example, driving and and driking alchool, committed in close temporal succession one after the other, make one liable of driving under the influence. To represent liability at this more fine-grained level, let $H_A$ denote the theory or hypothesis against the defendant, the accusation theory, and $\neg H_A$ its negation. The accusation theory should have some degree of specificity, for example, it should  say when, where and how the defendant drove under the influence. How specific the accusation theory should be is a question we will investigate later. 

So, if $E$ is the total evidence presented in court and $H_A$ is the accusation theory, 
the burden of proof in civil cases can be formulated as follows: 

\begin{quote}
find against the defendant if $P(H_A \vert E)> .5$ or if $P(H_A \vert E)> P(\neg H_A \vert E)$ 
\end{quote}

\noindent
The two formulations are equivalent because, if 
$P(H_A \vert E)>.5$, then $P(\neg H_A \vert E)<.5$ and thus also $P(H_A \vert E)> P(\neg H_A \vert E)$. The converse also holds. Since the probability of a proposition and its negation must add up to one, if $P(H_A \vert E)> P(\neg H_A \vert E)$, then $P(H_A \vert E)>.5$.

So, legal probabilism is committed to at least one of the following tenets:

- the probability of liability can be assessed with some degree of precision

- the probability of liability is a good, theorethically adequate measure of the uncertanity 
about the disputed factual issue

\noindent
Both these tenets can be challenged. Legal probabilists could give up the first, while still mantaining the second tenet. 
We will show that both these tenets are questionable. 


# Challenge I: Where do the numbers come from? 

The metaphor of a scale tilting on one side or othe other is good only up to a point. How do we move past the metaphor? So let us first examine how the probability of a defedant's libiality can be assessed in a more principled and systematic manner. 


The probabilily of liability, assessed on the basis of the evidence presented, is usually referred to as the posterior probability of liability. It is determined starting from a prior or initial value, assessed prior to considering the evidence. The prior probability is equated to $P(L)$, while the posterior probability, given evidence $E$, is equated to  $P(L \vert E)$.  The relation between prior and posterior is set by the formula of Bayes' theorem:

$$P(L \vert E)=\frac{P(E \vert  L)}{P(E)}P(L)=\frac{P(E \vert  L)}{P(L)P(E\vert L)+P(\neg L)P(E\vert \neg L)}P(L)$$

The generic $L$ could be replaced by the more specific accuasation theory $H_A$, but to keep the notation easier to read, we will stick to $L$. 

Here legal probabilism faces the first major challange: \textit{Where do the numbers come from?} This challenge comes in many forms. Let us start with assessing **prior probabilities**. 

The prior probability $P(L)$ must be set somewhere, but where? Should the prior be $1/n$, where $n$ is the number of individuals who could have committed the unlawful acts in question? Setting $P(L)=1/n$ makes sense in a criminal case in which the identity of the perpertrator is disputed. Absent information for distinguishing $n$ possible perpetrators---prior to considering the trial evidence $E$---it is natural to set the prior probability $P(L)$ to $1/n$ since any of them could be the perpetrator.  But $1/n$ does not make sense in other contexts, criminal or civil, in which the identity of the person who committed the acts isn't disputed. What is disputed, rather, is how the acts exactly unfolded and so whether they amount to illegal conduct after all. In such cases, the prior could be $l/s$, where $s$ is the number of possible ways the events could have unfolded and $l$ is the number of legally prohibited ways, where of course $l<s$. But while it is clear how to count $n$ possible suspects,  it is less clear how to count the $s$ or $l$ possible ways the events could have unfolded.

A common response to the problem of setting priors is to run a **sensitivity analysis**: try out different values of the prior probability of $L$ and see thow they impact the posterior probability.  If the posterior probability varies widely depending on the priors, the evidence $E$ is weak; if it remains stable, the evidence is strong. The  behavior of the posterior probability in light of setting different priors is a function of setting the other probabilities involved, specifically  $P(E \vert L)$ and $P(E \vert \neg L)$. Setting these other 
probabilities isn't an easy task either (on this point shortly). But note that the approach based on sensitivity analysis no longer equates the burden of proof with a simple probability threshold. The stability of the posterior probability, in light of variations in the priors, has become an additional factor to consider. 

Another response is to forget about setting the priors for $L$, and only focus on the ratio of the other two probabilities, $\frac{P(E \vert L)}{P(E \vert \neg L)}$, often called the **likelihood ratio**. This ratio measures how strongly the evidence supports the liability claim $L$. The greater the ratio (for values above one), the stronger the support $E$ lends in favor of $L$. So, what numbers should be assigned to $P(E \vert L)$ and $P(E \vert \neg L)$, sometimes called **likelihood probabilitie**s? The answer is far from clear. But note that, instead of assigng probabilitis between 0 and 1, to both numerator and denominator, it is enough to assign a ratio, without specifying the full probabilities. So, in what follows, we will keep track of how much can be accomplished using ratios only, call this the **ratio apoproach**.

The task of assessing $P(E \vert L)$ and $P(E \vert \neg L)$ can appear daunting, especially because the statements $L$ and $E$ are complex propositions. So, as a first step, it can be helpful to break down $L$ into smaller level statements, say, whether the defendant visited the crime scene or left a blood stain at the scene. It can also be helpful to break down $E$ into smaller pieces: fingerprint evidence, witness testimonies, genetic matches, expert reports, etc. Once the statements are broken down this way, assigning probabilities to them becomes more manageable. 

For example, let $M$ stand for 'the defendant's genetic profile matches the crime traces' and $S$ stand for 'the defendant is the source of the crime trace'. The original formula reduces to the more manageable:

$$P(S \vert M)=\frac{P(M \vert  S)}{P(M)}P(S)=\frac{P(M \vert  S)}{P(C)P(M\vert S)+P(\neg C)P(M\vert \neg S)}P(S),$$

where the general level statement $L$ is replaced by $C$ and the overall evidence $E$ by the match evidence $M$. As we will see later, 
 $P(M \vert S)$ can be set to one and $P(M \vert \neg S)$ to the genotype probability, the expected frequency of finding the matching genotype in a reference population. The details do not matter now. The point is that these numbers can be assigned in a defensible manner.  Finally, after setting $P(S)=1/n$, where $n$ is the number of possible contributors, the posterior probability $P(S \vert M)$ is obtained by easy calculations.  
 
 Using only ratios---together with breaking down $L$ and $E$ into smaller level statements---makes the task even easier. It would be enough to assign a ratio to $\frac{P(M \vert S)}{P(M \vert \neg S)}$. This is a task forensic scientists engage with often when they testify in court. 

The strategy of focusing on smaller level statements makes it possible to assign the numbers we need.  But it also pushes the problem elsewhere. Granted, probabilities can be assigned to smaller level statements such as $M$ and $S$, but what about general level statements such as $L$? The objective of a trial is not just to ascertain whether the defendant is a source of the traces found at the scene, but whether the defendant is ultimately liable. The same question recurs working with ratios only. Granted, a number can be assigned to small level ratio such as $\frac{P(M \vert S)}{P(M \vert \neg S)}$, but what about the general level ratio $\frac{P(E \vert L)}{P(E \vert \neg L)}$?

 Legal probabilists often rely on **Bayesian networks** to map out complex cases involving multiple propositions and multiple pieces of evidence. These networks serve to draw the connections between smaller level propositions, such as $S$ and $M$, and general level ones, such as $L$. We will see how they work and how they are built in later chapters. A rough sketch will suffice for now. Consider a stylized criminal case in which the items of evidence and disputed propositions are graphically represented as follows: $W \leftarrow L \rightarrow S \rightarrow M$,  \textbf{DRAW BAYES NET HERE}  where the letters $L, S$ and $M$ are interpreted as before. In addition, let $W$ stand for an incriminating eyewitness testimony, say the testimony that they saw the defendant run away from from the scene. 

  This network represents a case in which match evidence ($M$) supports the claim that the defendant left traces at the  scene ($S$). In turn, this latter claim supports the ultimate, general level claim $L$ that the defedant is liable. The witness testimony ($W$) supports $L$ directly. Given this set up, the probability of $L$ given both $M$ and $W$ is what we are interested in, $P(L \vert M \& W)$. What number should we attach to it?

Even such simple Bayesian network will need several conditional probabilities to get the calculations going.  Besides $P(M \vert S)$ and $P(M \vert \neg S)$, it will need the conditional probabilities $P(S \vert L)$ and $P(S\vert \neg L)$. That is, if the defendant is liable (or not liable), how probable is it that they would be leaving traces at the  scene? The network will also need the conditional probabilities $P(W \vert L)$ and $P(W \vert \neg L)$. That is, if the defendant is liable (or not liable), how probable is it that they would be seen running away from the scene? These probabilities must be entered in the probability tables associated with the network. Presumably, $P(S \vert L)$ must be greater than $P(S \vert \neg L)$ and $P(W \vert L)$ greater than $P(W\vert \neg G)$. But besides these inequalities, what else?  

All in all, Bayesian networks do not solve the problem of how to assign the numbers. If anything, they make the problem more apparent. It is difficult to find all the numbers required  by the probability tables of a Bayesian network even in  simple networks, with just few nodes making up the network. When Bayesian networks consist of several propositions and items of evidence, the problem is even starker.  So, then, the required numbers are often inserted as educated guesses because the probability tables cannot be left blank.


Legal probabilists could respond in different ways. Here are some:

- \textit{Localize:} Focus on those domains, propositions or forms of evidence for which the required numbers are available, for example, match genetic evidence or other forms of scientific evidence. Legal probabilism need not aspire to model the evidence of an entire legal case, but only evidence amenable to probabilistic quantification. 

- \textit{Ratios:} Use ratios, not full probabilities values. Ratios are easier to assign and often sufficient to arrive at an overall evaluation of a case and the supporting evidence. 

- \textit{Intervals:} Instead of precise numbers, rely on intervals or ranges of probabilities. This is known as imprecise legal probabilism. There are Bayesian networks that can work with imprecise probabilities. Imprecise probabilism is a generalization of sensitivity analysis: test how the probability of the ultimate proposition $L$ varies in light of ranges of values for other probabilities, including but not limited to prior probabilities. 


- \textit{Collect the data:}  If the numbers are missing, then we do not currently have a good way to quantify uncertainty. This isn't a problem for legal probabilism; it is a problem for any procedure that attempts to ascertain  disputed matters of fact. Legal probabilism has the merit to tell us what is missing. If the numbers we need are missing, that is a good reason to figure out what they are by collecting relevant data.



- \textit{Qualitative:} While precise numbers can be helpful, they can also be a distraction. Even without delivering precise numbers, legal probabilism is still valuable. It forces us to focus on the logic of reasoning under uncertainty. Probability theory imposes coherence constraints on our evidence-based beliefs about uncertain events. Similarly, legal probabilism imposes coherence constraints on evidence-based beliefs about civil and criminal liability. Legal probabilism is not primarily concerned with the task of arriving at precise probabilities. They can still be useful for illustrative purposes, but should not be taken as a basis for making decisions. 

It is worth exploiring each of these responses in more detail. 


## Localize

The localization strategy is the most defensible, but limited in scope. There is no doubt that great progress has been maded in the quantification of certain forms scientific evidence, such as DNA matches. Experts often testify using probabilities. Hardly anyone would object that the probabilities associated with DNA matches or other forms of scientific evidence are of some use. But a larger question would remain. How should difderent forms of evidence, some more easily quantifiable with probabilities than others, be aggregated? The localization strategy leaves this question unaddressed. 


## Ratios

See later discussion about comparative thresholds.

## Intervals

Non starter: problem of belief inertia; relying on most conservative assessment might undervalue evidence.  Use higher-order approach instead. 



## Collect data

Return to our simple criminal case and the Bayesian network $W \leftarrow L \rightarrow S \rightarrow M$.  First, we need the conditional probabilities $P(S \vert L)$ and $P(S \vert \neg L)$, focusing on the  nodes in the subgraph $L \rightarrow S$. That is, if the defendant is liable (or not liable), how probable is it that they would be leaving traces at the  scene?  Tracking how often perpetrators manage or not to remove traces they left at crime scene would give a number to the conditional probability $P(S \vert L)$, often a number close to one. The assumption is that, if someone committed the criminal act ($L$), it is quite likely they visited the scene at some point and left a trace ($S$).  The closer to one this probability, the harder it is to remove the type of trace found. If the trace is invisible, it would be hard for a perpetrator to remove it. So the probability in question will depend on the type of trace that was found.

What about $P(S \vert \neg L)$?  That is, if the defendant is not liable, how probable is it that they would still be leaving traces at the  scene? 
 Here we would need to track how often traces that have nothing to do with the crime are left at the scene. Some traces mght be nearly inconsistent with innocent or causal contact, while others much less so. This will depend on the specific trace under consideration. To fix ideas, imagine the following toy model. Suppose three types of traces could be left at the crime scene---$T1$, $T2$ and $T3$---from very common ones to traces left almost exclusively in committing criminal acts. So, finding a common $T1$ type trace would not be strongly indicative of liability, while finding a $T3$ type trace would be strongy indicative of liability. In other words, it is less likely to find $T3$ than $T2$ or $T1$ if no crime was committed. So,$P(T3 \vert \neg L) < P(T2 \vert \neg L) <P(T1 \vert \neg L)$. Conversely, it is likely to find $T3$ if a crime was committed, but it is also likley to find $T1$ since it so common anyway, and less common to find $T2$. So, the data nedded would consist of: different types of traces and how common they are in association with crimes and how common they are in ordinary contexts. 

Second, consider the conditional probabilities $P(W \vert L)$ and $P(W \vert \neg L)$, focusing on the  nodes in the subgraph $L \rightarrow W$. 
That is, if the defendant is liable (or not liable), how probable is it that they would be seeing running away from the scene? Here we would need to collect data about the reliability of eyewitnesses in identification tasks. If a witness claims to have seen the defendant at the crime scene, how often would the witness be wrong? The numbers needed here are rates of true positive identifications, $P(W \vert L)$, and rates of false positive identifications, $P(W \vert \neg L)$. To find out these numbers, we could run experiments---as some have done---under a variety of conditions, such as distance, lighting, stress levels, duration of exposure, cross-racial settings, etc. 

As these brief remarks suggest, nothing in principle bars us from collecting relevant data and enter the required numbers in the conditional probability tables. The bigger obstable might be feasibility. There simply are too many variables to consider to collect *all* the relevant data. For return now to the eyewitness identification case. Suppose we run experiments about false identifications, using distance, lighting, and stress level as variables. The numbers obtained from the study are then used to set  the conditional probabilities $P(W \vert L)$ and $P(W \vert \neg L)$. But then, it turns out at trial that the witness had a financial stake in the dispute, and wears glasses. How should this information be added to the assessment of the probabilities? Since no other experimental study can be run during trial, the risk is that variables whose impact has not been numerically quantified in prior experiments would be neglected. This is sometimes called the problem of **soft variables**.



## Qualitative

Instead of numbers, many believe that the legal probabilitis help to reveal the logical structure of the reasoning, not so much, quantiyfing the probability of liability with exact numbers. Once the logical structure is in place, it reveales how the different sources of uncertainty add up or cancel out.

Suppose the following inference structure applies to a case: $L\rightarrow S \rightarrow M$, where $\L$ is the ultimate proposition and $M$ is known, the match evidence. So, the inference from $M$ to the intermediate step $S$ suffers from some uncertainty and the inference from $M$ to $L$ suffers some additional uncertainty. So, overall, the inference from $M$ to $L$ suffers from the aggregate uncertainty from $M$ to $S$ to $L$. Is there a qualitative way to model this aggregation of uncertainty using Bayesian networks? This pattern can then be generalized along a linear chain of inferences that count several intermediate steps. We start with $S_1$, then go along a chain of inferences from $S_k$ to to teh next step $S_k+1$ and end up with the conclusion $C$. Each step is subject to some uncertainty. Knowin the uncertainties associated with each step, what is the overall uncertainty associated with the inference from $S_1$ all the way to $C$?  

\textbf{Rafal and Nikodem, any suggestions about how this could go?}

Suppose we know the uncertainty of the inference from $M$ to $S$, namely in terms of $P(M \vert S)$ and $P(M\vert \neg S)$. We also know the uncertainty of the inference from $S$ to $L$, namely in terms of $P(S \vert L)$ and $P(S \vert \neg L)$. Then, what is the aggregate uncertainity of the inference from $M$ to $L$ via $S$? Is uncertainty aggregation compositional? **This discussion needs to be completed**



# Comparative thresholds

Part of the problem of setting up prior probabilities is having to sift through a large space of possibilities. The hypothesis $L$ and its negation---or $H_A$ and its negation---include the whole space of posibilities, and $\neg L$ or $\neg H_A$ are hard to envision.  A more manageable task is to  start with a limited space of alternative hypotheses, assign priors to them and then adjust the probabilities in light of the evidence available. In the simplest case, only two competing hyptheses are compared against one another. 

Which brings us to a competitor or legal probabilism, the theory of relative plausibility. The starting point of relative plausiblility is that at trial the two parties put forward competing explanations of the evidence. These competing explanations are then tested against the evidence. Think of the two competing explanations as the accusation theory $H_A$ and the defense theory $H_D$. Instead of assessing the probability of $L$ or $H_A$ in light of the evidence $E$, the theory of relative plausibility submits that the point of legal fact-find is to assess the plausibility of $H_A$ *relative to* $H_D$ in light of evidence $E$. Plausibility is a multidimensional notion, comprising considerations of fit and consistency with the evidence, predictive power, logical coherence, coverage of the evidence, etc. The more plausible explanation is one that prevails along a weighted combination of these criteria. So the judgment of liability should follow the explanation that prevails. 

To articulate the idea of plausibility more precisely woud bring us too far afield. But one aspect of relative plausibility is clear: 
instead of focusing on the acusation $H_A$ and ssessing its probability given the evidence $E$, focus on comparing the accusation theory against its alternative $H_D$, not the wholesale negation of the accusation theory. This comparative idea can be adopted by legal probabilism.

So what if $\neg H_a$ is replaced by a more specific alternative to $H_A$, namely $H_D$, the theory put foward by the defense? While $H_D$ entails $\neg H_A$, because $H_D$ and $H_A$ must be incompatible, the converse does not hold. $\neg H_A$ does not entail $H_D$ becuase $H_D$ is just one particular way in which $H_A$ can fail to hold. So comparing $H_A$ and $H_D$ tend to be computionally less burdensom than assessing $H_A$ (which essentially means, comparing $H_A$ and its full scale negation $\neg H_A$).

So, the burden of proof in civil cases can now 
be formulated as follows (call it the **comparative formulation**): 

\begin{quote}
find against the defendant if $P(H_A \vert E)> P(H_D \vert E)$. 
\end{quote}

\noindent
In other words, to establish the defendant's liability by the balance of probabilities, the accusation theory $H_A$ should be more probable than the defense theory. Crucially, the condition $P(H_A \ vert E)> P(H_D \vert E)$ is not equivalent to $P(H_A \ vert E)> .5$ seen earlier. It could be that both $H_A$ and $H_D$ have probability below .5, even though $H_A$ is more probable than $H_D$. So, following this comparative formulation, a defendant could be found liable even though the probability of liability is below .5. This result seems counterintuitive, and perhaps it is a reason to favor the earlier, non-comparative formulation of the burden of proof. A related reason to be cautious of the comparative formulation is that the resultig decision rule depends on the choice of $H_A$ and $H_D$. It is possible that, given the same stock of evidence $E$, in one case the probability of $H_A$ exceeds that of $H_D$, while in another case, given a different framing of the two theories, the probability of $H_D$ execeeds that of $H_A$.  This result signals a worrisome level of sujbectivity in the decision rule.

Interestingly, however, the non-comparative formulation of the burden of proof suffers from similar problems. Any probability assessment is always relative to a probability model and comprises a sample space and a distribution over all possible outcomes (or events, or propositions). It is entirely possible that what counts as intuitively the same event $A$ is assigned very probabilities by two models, so it is entirely possible that $P_{M1}(A) > 0.5 > P_{M2}(A)$.  So depending on the probability model, the probability $A$ may or may meet the 0.5 probaility. threshold. So, for example, suppose that in $M1$, the defense hypothesis $H_D$ just is $\neg H_A$ and we have $P_{M1}(H_A) > 0.5 > P_{M1}(\neg H_a) = P_{M1}(H_D)$ .  But suppose, instead, that in $M2$, the defense hypothesis $H_D$ is just one way to negate $H_A$ and we have $P_{M2}(H_A) > P_{M2}(H_D)$, but both are below 0.5. There is a third hypothesis $H_{D}^{*}$.
Sop what are we supposed to conclude? Is $H_A$ above the 0.5 probabiliyt thrshold or not? It depends on the model. As the comparative approach suffers from hypothesis-depedence, the non-comparative approach suffers from model-depedence. These  ight well be manifestation of a common phenomenon.




# Challenge II: Learning isn't updating 

The discussion about comparative thresholds and model- or hypothesis-dependence brings us to another objection to legal probabilism. In a slogan: learnign isn't (just) updating.   Ronald Allen complains that Bayesian updating isn't an adequate model of what goes on in the courtroom when evidence is presented. The decision-makers do not start from priors over propositions and update them based on the pieces of evidence presented. What happens is more complicated and cannot be modeled by Bayesian updating. This is an important point. Certainly part of what goes in the court is updating. The jurors might think that if evidence $E$ is presented, then $H_A$ should become  less likely. When $E$ is actually presented, they lower their crededence in $H_A$. This is updating, certainly part of what is going in the courtroom. But much more seems to also going on. What else? New alternative hypotheses or explanations are discovered or brought to light. When this happen, teh space of possibilities of sample space should be reconsidered. Bayesian updating breaks down.


Legal probabilism can respond in two different ways:

- They can grant that Bayesian updating is limitaed to a narrow part of what can be broadly called *evidence evaluation*. Bayesian updating only models a form of *retrospective coherence*. Once all the possible hypothesies and space of possibilities is fixed, Bayesian updating checks that the probability assignments are coherent in light of the evidence that was actually presented. But those probability assignments were already entered from the beginning (or from the end) once the sample space and the probabiliyt model had been defined, so that all $P(A \vert E)$ were defined.


- They can extent the framewok beyond mere updating. There is updatign within the model (standard Bayesin updating) and there is updating of the model (space of possibilities) outside the model. The latter seems an integral part of reasoning with evidence. 







\textit{See the chapter on cross-examination and arguments should address this challange.} 





# Challenge: not just high probability 

Even if the numerical challenge can be addressed in one of the ways just outlined, other difficulties linger for legal probabilism.  Why ascertain the probability of liability? Is this the right metric to focus on? Intuitively, if the probability of liability were low---assuming this probability can be established somewhow---that would be a good reason to pause and not find the defendant liable. There is little doubt about that. But this intuition only shows that a high enough probability of liability is a \textit{necessary} condition for a finding of liability. Is it also a sufficient condition? That is less obvious. In fact, we can think of cases in which---intuitively---the probability of liability is high enough, yet the supporting evidence is weak, insufficient to sustain a judgment against the defendant.

A civil suit is brought against someone to recover a certain amount of money. This is a case of civil theft and the governing standard is preponderance or balance of probabilities. The evidence is that a rumor suggests  the defendant embezzeled money from the plaintiff. 
The defendant was working in the plaitiff's company as an administrator and in this capacity embezzeled USD 50,000 of the company's funds. That the money is gone is unquestionable. It is also unquestionable that only two people had accessed to the money; one of them is the defendant. Without any more specific evidence about what happened, the starting point is equipoise between $H_A$ and its negation, where $H_A$ is the accusation theory that the defendant embezzeled the money.  That is, $P(H_A)=P(\neg H_A)$. As the rumor $R$ is added as evidence, the balance tilts towards $H_A$, if only so slightly. So, $P(H_A \vert R)>P(\neg H_A \vert R)$. But it would be ridiculous---on such tenous evidence---to conclude that the defendant should be liable of embezzelment. A case like this should not even be litigated in court.

The rumor seems to be insufficient evidence for a number of reasons. First, its reliability and trustworthiness was not tested or scrutinized. 
Second, the rumor did not provide a more precise account of how, when, and why the defendant embezzeled the money. The rumor is certainly a relevant piece of information, but what about other evidence? 


Consider a variation of the case. Instead of just a rumor, the key item evidence is the recording of a phone conversation in which the speaker says 'I will provide you with the banking details for trasferring USD 50,000 tomorrow'. The phone conversation took place a few days before the money disappeared from the company's bank account. \textbf{Need to work on this example}

A voice recognition expert testifies that the voice profile in the call matches the defendant and based of a databse of 100 voice profiles, the matchign profile occur with 20 percent frequency.  So $P( M \vert V)=1$
and $P(P(M \vert \neg V))=0.2$. The voice recognition evidence is stronger than the rumor, but should we trust the expert? Is 100 instances a sufficiently large sample? Is the 1 percet figure trustworthy?


The more from these two examples is this. Besides high probability---or in civil cases, a greater tahn 50 percent probability---other dimensions (should) guide decision-making and they might not be reducible to the probability of liability. Some of 
the other dimensions are:

- How certain are we about the probability of liability? (Higher-order uncertainty) 

- How good (specific, coherent, plausible, explanatory powerful) is the accusation theory presented?

- Did the defense challenged the other party's story? Did the story survive the challenges?

- Is any evidence missing? Is the evidence presented representative of both sides or was the evidence collected in a biased or skewed manner?

A more sophisticated version of legal probabilism, then, should be able to 
do at least two things: first, formally model these additional dimension using the language of probability (or determine to what extent they fall outside the scope of probability theory and cognate theories); and second, show why relying on these additional dimensions in decision-making does foster important values, such as the accuracy and fairness of trial decisions.


\textbf{NEED TO EXPLAIN EACH POINT MORE CLEARLY}



## Challenge 2: Evidence is evaluated holistically. 

\textit{The chapter on story coherence should address this challange.} 




## Challenge 4: Trials are adversarial 

Trials are often adversarial. Evidence is examined and cross-examined. How can this adversarial process be modeled probabilistically?
\textit{The chapter on cross-examination and arguments should address this challange.} 


## Challenge 5: No evidence that probability reduces errors 
It is clear that people make probabilistic mistakes in reasoning, but does this show that mistaken convictions are caused by these probabilistic mistakes? There is no evidence of that. In what way does probability actually improve the accuracy of legal decisions?
\textit{Discussion about accuracy and fairness should address this challange}

# Structure 

So we can envision  four central chapters: 

Chapter: Higher-order probability See existing chapter and paper on higher-order legal probabilism.

Chapter: Narratives, specificity, coherence etc. See Rafal's paper 
on coherence. 

Chapter: Cross-examination and arguments See Marcello's paper on cross-examination and Bayesian networks, and also paper on awareness growth and Bayesian networks.

Chapter: Gaps in Evidence 
See existing paper on gaps in the evidence.



\vspace{10mm}
\noindent
This more sophisticated version of 
legal probabilism should answer some of existing challenges to 
simple legal probabilism. 
