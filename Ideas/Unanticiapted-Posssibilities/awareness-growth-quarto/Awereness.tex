% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
  \setmainfont[]{Times New Roman}
  \setsansfont[]{Times New Roman}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

%\documentclass{article}

% todonotes package                          #####################

\usepackage[textsize=footnotesize]{todonotes}


%language                                    #####################

%\usepackage{times}
%\usepackage{t1enc}                               Trouble maker
%\usepackage[utf8x]{inputenc}
%\usepackage[polish]{babel}
%\usepackage{polski}


% math                                       #####################

%AMS
\usepackage{amsfonts}
\usepackage{amssymb}
%\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathtools}


% quote environment                        #######################  Unfortunately it destroys the font, only an issue in a mathmode

%\usepackage[T1]{fontenc} % Required for correct quotes with ""

%\renewenvironment{quote}
%{\list{}{\leftmargin=1em\rightmargin=1em}\item[]``}
%{''\endlist}



% page geometry                              #####################

\usepackage{setspace}

\usepackage{geometry}
 \geometry{a4paper,left=35mm,top=20mm,}

\setlength{\parindent}{10pt}
\setlength{\parskip}{1pt}

\usepackage{float}
\restylefloat{figure}

% abbreviations                              #####################

\newcommand{\ra}{\rangle}
\newcommand{\la}{\langle}
\newcommand{\n}{\neg}
\newcommand{\et}{\wedge}
\newcommand{\jt}{\rightarrow}
\newcommand{\ko}[1]{\forall  #1\,}
\newcommand{\ro}{\leftrightarrow}
\newcommand{\exi}[1]{\exists\, {_{#1}}}
\newcommand{\pr}[1]{\mathsf{P}(#1)}
\newcommand{\cost}{\mathsf{cost}}
\newcommand{\benefit}{\mathsf{benefit}}
\newcommand{\ut}{\mathsf{ut}}

\newcommand{\odds}{\mathsf{Odds}}
\newcommand{\ind}{\mathsf{Ind}}
\newcommand{\nf}[2]{\nicefrac{#1\,}{#2}}
\newcommand{\R}[1]{\texttt{#1}}
\newcommand{\prr}[1]{\mbox{$\mathtt{P}_{prior}(#1)$}}
\newcommand{\prp}[1]{\mbox{$\mathtt{P}_{posterior}(#1)$}}

\newcommand{\s}[1]{\mbox{$\mathsf{#1}$}}


\newtheorem{q}{\color{blue}Question}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}



% bibliography                                #####################

\usepackage[authoryear]{natbib}

%\bibliographystyle{apalike}





\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Awareness Growth with Bayesian Networks},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Awareness Growth with Bayesian Networks}
\author{}
\date{2024-01-16}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[sharp corners, enhanced, interior hidden, breakable, frame hidden, boxrule=0pt, borderline west={3pt}{0pt}{shadecolor}]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}
\doublespace

\emph{Wordcount (including footnotes)}: 8,250

\begin{abstract}
We examine different counterexamples to Reverse Bayesianism, a popular approach to the problem of awareness growth. We agree with the general skepticism toward Reverse Bayesianism, but submit that in a relatively wide range of cases the problem of awareness growth  can be tackled algorithmically once subject-matter structural assumptions are made explicit. These assumptions play an essential role in determining how probabilities should be updated. Bayesian networks are useful for the representation of such structural assumptions, so we use them to illustrate how awareness growth can be modeled in the Bayesian framework. 
\end{abstract}

\doublespace

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Learning is modeled in the Bayesian framework by the rule of
conditionalization. This rule posits that the agent's new degree of
belief in a proposition \(H\) after a learning experience \(E\) should
be the same as the agent's old degree of belief in \(H\) conditional on
\(E\). That is, {[}\ppr{E}{H}=\pr{H \vert E},{]} where \(\pr{}\)
represents the agent's old degree of belief (before the learning
experience \(E\)) and \(\ppr{E}{}\) represents the agent's new degree of
belief (after the learning experience \(E\)).

Both \(E\) and \(H\) belong to the agent's algebra of propositions. This
algebra models the agent's awareness state, the propositions taken to be
live possibilities. Conditionalization never modifies the algebra and
thus makes it impossible for an agent to learn something they have never
thought about. Even before learning about \(E\), the agent must already
have assigned a degree of belief to any proposition conditional on
\(E\). This picture commits the agent to the specification of their
`total possible future experience' (\textbf{howson1976?}), as though
learning was confined to an `initial prison' (\textbf{lakatos1968?}).

But, arguably, the learning process is more complex than what
conditionalization allows. Not only do we learn that some propositions
under consideration are true or false, but we may also learn new
propositions that we did not consider before. Or we may consider new
propositions---without necessarily learning that they are true or
false---and this change in awareness may in turn change what we already
believe. How should this more complex learning process be modeled by
Bayesianism? This is the problem of awareness growth.\footnote{The
  algebra of propositions need not be so narrowly construed that it only
  contains propositions that are presently under consideration. The
  algebra may also contain propositions which, though outside the
  agent's present consideration, are still the object, perhaps
  implicitly, of certain dispositions to believe.
  (\textbf{roussos2021?}) notes that, for the sake of clarity, the
  problem of awareness growth should only address propositions which
  agents are \emph{truly} unaware of (say new scientific theories), not
  propositions that were temporarily forgotten or set aside. This is a
  helpful clarification to keep in mind, although the recent literature
  on the topic does not make a sharp a distinction between true
  unawareness and temporary unawareness.}

The problem of awareness growth have been discussed under different
names for quite some time, at least since the eighties. It arises in
different contexts, such as the construction of new scientific theories
(\textbf{glymour1980?}; \textbf{eerman1992?}; \textbf{chihara1987?}),
language changes and paradigm shifts (\textbf{williamson2003?}), and
theories of induction (\textbf{zabell1992?}).

A proposal that has attracted considerable scholarly attention in recent
years is Reverse Bayesianism (\textbf{karniViero2015?};
\textbf{wenmackersRomeijn2016?}; \textbf{bradley2017?}). The idea is to
model awareness growth as a change in the algebra while ensuring that
the proportions of probabilities of the propositions shared between the
old and new algebra remain the same in a sense to be specified.

Let \(\mathcal{F}\) be the initial algebra of propositions and let
\(\mathcal{F}^+\) be the algebra after the agent's awareness state has
grown. Denote by \(X\) and \(X^+\) the subsets of these algebras that
contain only basic propositions (that is, those without connectives).
\textbf{Reverse Bayesianism} posits that the ratio of probabilities for
any basic propositions \(A\) and \(B\) that belong to both \(X\) and
\(X^+\) remain constant through the process of awareness growth:
{[}\frac{\pr{A}}{\pr{B}} = \frac{\ppr{+}{A}}{\ppr{+}{B}},{]} where
\(\pr{}\) represents the agent's degree of belief before awareness
growth and \(\ppr{+}{}\) represents the agent's degree of belief after
awareness growth.

Reverse Bayesianism is an elegant theory that manages to cope with a
seemingly intractable problem. As the awareness state of an an agent
grows, the agent would prefer not to throw away completely the epistemic
work they have done previously. The agent may desire to retain as much
of their old degrees of beliefs as possible. Reverse Bayesianism
provides a simple recipe to do that. It also coheres with the
conservative spirit of Bayesian conditionalization which preserves the
old probability distribution conditional on what is learned.

Unfortunately, Reverse Bayesianism does not deliver the intuitive
results in all cases. There is no shortage of counterexamples against it
in the recent philosophical literature (\textbf{steeleStefansson2021?};
\textbf{mathani2020?}). In addition, attempts to extent traditional
arguments in defense of Bayesian conditionalization to Reverse
Bayesianism seem to hold little promise (\textbf{Pettigrew2022?}). If
the consensus in the literature is that Reverse Bayesianism is not the
right theory of awareness growth, what theory (if any) should replace
it?

Here we offer a diagnosis of what is wrong with Reverse Bayesianism and
outline an alternative proposal. The problem of awareness growth---we
hold---cannot be tackled in an algorithmic manner until subject-matter
structural assumptions are made explicit. As they tend to vary on a
case-by-case basis, no general formal plug-and-play theory of awareness
growth can be provided. This does not mean, however, we should give up
on probabilistic epistemology altogether. Thanks to their ability to
express probabilistic dependencies, Bayesian networks can help to model
awareness growth in the Bayesian framework and capture whatever formal
properties of awareness growth there are to be captured. We illustrate
this claim as we examine different counterexamples to Reverse
Bayesianism.

The plan for the paper is as follows. To set the stage for the
discussion, Section \ref{sec:counterexamples} begins with two
counter-exmaples to Reverse Bayesianism by
(\textbf{steeleStefansson2021?}). One example targets awareness
expansion and the other awareness refinement (more on the distinction
soon). Section \ref{sec:expansion-networks} models cases of awareness
expansion using Bayesian networks. Section \ref{sec:mathani} further
illustrates the fruitfulness of this approach by looking at two
counter-examples to Reverse Bayesianism by (\textbf{mathani2020?}).
Section \ref{sec:structural-both} turns to awareness refinement.
Finally, Section \ref{sec:general} outlines a general theory of
awareness growth with Bayesian networks.



\end{document}
